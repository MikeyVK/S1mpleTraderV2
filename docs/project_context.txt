--- START FILE: GEMINI.md ---
# S1mpleTrader V2 - AI Assistent Instructies

Hallo! Ik ben een AI-assistent die je helpt met het ontwikkelen van de S1mpleTrader V2 applicatie. Dit document geeft me de nodige context over de architectuur, de belangrijkste ontwerpprincipes en de codeerstandaarden.

## 1. Visie & Kernprincipes

Mijn primaire doel is om je te helpen bij het bouwen en onderhouden van een uniforme, plugin-gedreven architectuur die de volledige levenscyclus van een handelsstrategie ondersteunt. Ik houd me aan de volgende vier kernprincipes:

* **Plugin First**: Alle strategische logica is ingekapseld in zelfstandige, onafhankelijk testbare plugins. Dit is de kern van het systeem.
* **Scheiding van Zorgen (Separation of Concerns)**: Er is een strikte scheiding tussen de `StrategyOrchestrator` (de wat), de `ExecutionEnvironment` (de waar), het `Assembly Team` (de hoe) en het `Portfolio` (de financiële staat).
* **Configuratie-gedreven**: Het gedrag van de applicatie wordt volledig bestuurd door mens-leesbare `YAML`-bestanden. De code is de motor, de configuratie is de bestuurder.
* **Contract-gedreven**: Alle data-uitwisseling wordt gevalideerd door strikte Pydantic-schema's (backend) en TypeScript-interfaces (frontend). Dit zorgt voor voorspelbaarheid en type-veiligheid.

## 2. Architectuur Overzicht

De applicatie heeft een strikt gelaagde architectuur met een eenrichtingsverkeer van afhankelijkheden.

+-------------------------------------------------------------+
|  Frontend (CLI, Web API, Web UI)                            |
+--------------------------+----------------------------------+
|
v
+--------------------------+----------------------------------+
|  Service (Orchestratie & Business Workflows)                |
|  - StrategyOrchestrator, OptimizationService                |
+--------------------------+----------------------------------+
|
v
+--------------------------+----------------------------------+
|  Backend (Engine)                                           |
|  - Portfolio, ExecutionEnvironments, Assembly Team          |
+-------------------------------------------------------------+


* **Backend (`/backend`)**: De "engine". Bevat alle kernlogica en is ontworpen als een onafhankelijke library.
* **Service (`/services`)**: De "lijm". Orkestreert backend-componenten tot complete business workflows. Hier leeft de `StrategyOrchestrator`.
* **Frontend (`/frontends`)**: De gebruikersinterface (Web UI, API, CLI).

## 3. De 6-Fasen Quant Workflow

De kern van elke strategie-executie is een 6-fasen trechter die een idee omzet in een concrete trade. Ik moet deze flow begrijpen en respecteren bij het schrijven van code.

1.  **Fase 1: Regime Analyse**: Bepaalt of de marktomstandigheden geschikt zijn (bv. trending).
2.  **Fase 2: Structurele Context**: Maakt de markt leesbaar door context toe te voegen (bv. marktstructuur, trends).
3.  **Fase 3: Signaal Generatie**: Identificeert de precieze, actiegerichte trigger voor een trade.
4.  **Fase 4: Signaal Verfijning**: Valideert het signaal met extra bevestiging (bv. volume).
5.  **Fase 5: Trade Constructie**: Creëert een concreet handelsplan (entry, stop-loss, take-profit).
6.  **Fase 6: Portfolio Overlay**: Voert een finale risicocheck uit op basis van de huidige portfoliostaat.

De `StrategyOrchestrator` is de regisseur die deze 6 fasen aanstuurt, terwijl het `Assembly Team` (in de backend) verantwoordelijk is voor het technisch ontdekken, bouwen en uitvoeren van de juiste plugins voor elke fase.

## 4. Anatomie van een Plugin

Plugins zijn de fundamentele bouwstenen. Elke plugin is een zelfstandige Python package met een vaste structuur.

* `plugins/[plugin_naam]/`:
    * `plugin_manifest.yaml`: De "ID-kaart" die de plugin vindbaar maakt. Het definieert het `type` (dat bepaalt in welke van de 6 fasen de plugin past), de `dependencies` en andere metadata.
    * `worker.py`: Bevat de Python-klasse met de daadwerkelijke businesslogica.
    * `schema.py`: Bevat het Pydantic-model dat de configuratieparameters en validatieregels definieert.
    * `state.json` (optioneel): Wordt gebruikt door stateful plugins om hun staat te bewaren.

## 5. Codeerstandaarden & Best Practices

Ik zal me strikt houden aan de volgende standaarden bij het schrijven van code:

1.  **Code Stijl**:
    * Alle Python-code moet **PEP 8 compliant** zijn.
    * **Volledige Type Hinting** is verplicht.
    * Commentaar en docstrings zijn in het **Engels**.
    * Gebruik **Google Style Python Docstrings** voor alle functies en klassen.

2.  **Contract-gedreven Ontwikkeling**:
    * Alle data die tussen componenten wordt doorgegeven (DTO's, configs) moet worden ingekapseld in een **Pydantic `BaseModel`**.

3.  **Logging**:
    * De primaire output voor analyse is een gestructureerd **`run.log.json`**-bestand.
    * Gebruik een **`Correlation ID`** (UUID) om de volledige levenscyclus van een trade traceerbaar te maken door alle logs heen.

4.  **Testen**:
    * Code zonder tests is incompleet. Elke plugin is **verplicht** om een `tests/test_worker.py` te hebben.

5.  **Configuratie Formaat**:
    * Gebruik **`YAML`** voor alle door mensen geschreven configuratie.
    * Gebruik **`JSON`** voor machine-naar-machine data-uitwisseling (bv. API's, state-bestanden).

## 6. Snelle Referentie: Kernterminologie

* **Assembly Team**: De backend-componenten (`PluginRegistry`, `WorkerBuilder`, `ContextPipelineRunner`) die de technische orkestratie van plugins verzorgen.
* **Run**: Een `YAML`-bestand (`run_schema.yaml`) dat een complete strategie-configuratie beschrijft.
* **DTO (Data Transfer Object)**: Een Pydantic-model (`Signal`, `Trade`) dat als strikt contract dient voor data-uitwisseling.
* **ExecutionEnvironment**: De backend-laag die de "wereld" definieert waarin een strategie draait (`Backtest`, `Paper`, `Live`).
* **StrategyOrchestrator**: De "regisseur" in de Service-laag die de 6-fasen trechter uitvoert voor één enkele run.

Door deze principes en structuren te volgen, help ik je om een consistente, robuuste en onderhoudbare codebase te bouwen. Laten we beginnen!

--- END FILE: GEMINI.md ---

--- START FILE: requirements.txt ---
# requirements.txt

# --- Data & Analysis ---
# Kernbibliotheken voor dataverwerking en analyse.
pandas
pandas-stubs
numpy
scipy
pyarrow
openpyxl

# --- Configuration ---
# Voor het inlezen van YAML-configuratiebestanden.
PyYAML

# --- Web & API Server ---
# Benodigdheden voor de web-interface en de API.
fastapi
uvicorn[standard]
python-multipart
Jinja2

# --- User Interface (CLI) ---
# Tools voor de command-line interface.
tqdm
rich
prompt-toolkit

# --- Code Quality & Contracts ---
# Voor het afdwingen van code-stijl en datavalidatie.
pylint
pydantic

# --- Testing ---
# Framework en tools voor het schrijven en uitvoeren van tests.
pytest
pytest-mock

# --- Visualization ---
# Voor het genereren van grafieken en visuele rapportages.
plotly

# --- Documentation Generation ---
# Tools voor het genereren van de projectdocumentatie.
sphinx
sphinx-rtd-theme
--- END FILE: requirements.txt ---

--- START FILE: run_backtest_cli.py ---
# run_backtest_cli.py
"""
Entrypoint: For automated (headless) runs
"""

--- END FILE: run_backtest_cli.py ---

--- START FILE: run_supervisor.py ---
# run_supervisor.py
"""
Entrypoint: Starts the live trading supervisor
"""

--- END FILE: run_supervisor.py ---

--- START FILE: run_web.py ---
# run_web.py
"""
Entrypoint: Starts the Web UI and API
"""

--- END FILE: run_web.py ---

--- START FILE: __init__.py ---

--- END FILE: __init__.py ---

--- START FILE: .pytest_cache/README.md ---
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

--- END FILE: .pytest_cache/README.md ---

--- START FILE: backend/__init__.py ---
# backend/__init__.py
"""
Exposes the public API of the Backend package.
"""
__all__ = [
    # from .core
    "StrategyEngine",
    "Portfolio",
    "BaseStrategyWorker",
    "ContextRecorder",
    # from .dtos
    "Signal",
    "EntrySignal",
    "RiskDefinedSignal",
    "TradePlan",
    "RoutedTradePlan",
    "CriticalEvent",
    "ExecutionDirective",
    "EngineCycleResult",
    "ClosedTrade",
    "TradingContext",
    "BacktestResult",
    # from .environments
    "BacktestEnvironment",
#    "LiveEnvironment",
#    "PaperEnvironment",
    # from .assembly
    "ContextBuilder",
    "DependencyValidator",
    "PluginRegistry",
    "WorkerBuilder",
]

from .core import (
    StrategyEngine,
    Portfolio,
    BaseStrategyWorker,
    ContextRecorder,
)
from .dtos import (
    Signal,
    EntrySignal,
    RiskDefinedSignal,
    TradePlan,
    RoutedTradePlan,
    CriticalEvent,
    ExecutionDirective,
    EngineCycleResult,
    ClosedTrade,
    TradingContext,
    BacktestResult,
)
from .environments import (
    BacktestEnvironment,
#    LiveEnvironment,
#    PaperEnvironment,
)
from .assembly import (
    ContextBuilder,
    DependencyValidator,
    PluginRegistry,
    WorkerBuilder,
)

--- END FILE: backend/__init__.py ---

--- START FILE: backend/assembly/context_builder.py ---
# backend/assembly/context_builder.py
"""
Contains the ContextBuilder, responsible for executing a sequence of
context-providing plugins to enrich a DataFrame.

@layer: Backend (Assembly)
@dependencies: [pandas]
@responsibilities:
    - Sequentially applies a list of instantiated context workers to a DataFrame.
    - Ensures the original DataFrame is not modified (works on a copy).
    - Returns the final, enriched DataFrame.
"""
from typing import List

import pandas as pd

from backend.core.interfaces import ContextWorker

class ContextBuilder:
    """Executes a pipeline of context workers to enrich a DataFrame."""

    def build(self,
              initial_df: pd.DataFrame,
              context_pipeline: List[ContextWorker]
        ) -> pd.DataFrame:
        """
        Applies a list of context workers sequentially to a DataFrame.

        This method takes a starting DataFrame and a list of worker objects
        (which are expected to have a 'process' method). It creates a copy of
        the DataFrame and then passes it through each worker in order, with the
        output of one worker becoming the input for the next.

        Args:
            initial_df (pd.DataFrame): The raw OHLCV DataFrame.
            context_pipeline (List[object]): An ordered list of instantiated
                                             context worker objects.

        Returns:
            pd.DataFrame: The final, enriched DataFrame after all workers
                          have been executed.
        """
        # Werk altijd op een kopie om onverwachte bijeffecten te voorkomen.
        enriched_df = initial_df.copy()

        for worker in context_pipeline:
            # We gaan ervan uit dat elke 'worker' een .process(df) methode heeft.
            # De test die we hebben geschreven, valideert deze aanname.
            enriched_df = worker.process(enriched_df)

        return enriched_df

--- END FILE: backend/assembly/context_builder.py ---

--- START FILE: backend/assembly/dependency_validator.py ---
# backend/assembly/dependency_validator.py
"""
Contains the DependencyValidator, responsible for ensuring the integrity
of a context pipeline before execution.

@layer: Backend (Assembly)
@dependencies: [.plugin_registry]
@responsibilities:
    - Validates that the data dependencies of each plugin in a sequence are met
      by the outputs of the preceding plugins.
"""
from typing import List
from backend.assembly.plugin_registry import PluginRegistry

class DependencyValidator:
    """Validates the dataflow integrity of a context worker pipeline."""

    def __init__(self, plugin_registry: PluginRegistry):
        """Initializes the DependencyValidator.

        Args:
            plugin_registry (PluginRegistry): The registry to fetch manifests from.
        """
        self._registry = plugin_registry

    def validate(self, context_pipeline: List[str]) -> bool:
        """
        Validates a sequential pipeline of context workers.

        It checks if the `dependencies` of each worker are satisfied by the
        initial `DataFrame` columns or the `provides` of the workers that
        run before it.

        Args:
            context_pipeline (List[str]): An ordered list of context worker names.

        Returns:
            True if the pipeline is valid.

        Raises:
            ValueError: If a dependency is not met, with a descriptive error.
        """
        # Start met de basiskolommen die altijd aanwezig zijn in de ruwe DataFrame.
        available_columns = {"open", "high", "low", "close", "volume"}

        for plugin_name in context_pipeline:
            plugin_data = self._registry.get_plugin_data(plugin_name)
            if not plugin_data:
                raise ValueError(f"Plugin '{plugin_name}' not found in registry.")

            manifest, _ = plugin_data

            # Controleer de dependencies van de huidige plugin.
            if manifest.dependencies:
                for dep in manifest.dependencies:
                    if dep not in available_columns:
                        raise ValueError(
                            f"Dependency '{dep}' for plugin '{plugin_name}' not met. "
                            f"Available columns: {sorted(list(available_columns))}"
                        )

            # Voeg de output van deze plugin toe aan de set van beschikbare kolommen.
            if manifest.provides:
                available_columns.update(manifest.provides)

        return True

--- END FILE: backend/assembly/dependency_validator.py ---

--- START FILE: backend/assembly/engine_builder.py ---
# backend/assembly/engine_builder.py
"""
Contains the EngineBuilder, a specialist for assembling a StrategyEngine.
"""
from typing import Any, Dict, List

from backend.assembly.worker_builder import WorkerBuilder
from backend.config.schemas.run_schema import RunBlueprint, WorkerDefinition
from backend.core.enums import PipelinePhase
from backend.core.strategy_engine import StrategyEngine
from backend.core.interfaces.worker import ContextWorker

class EngineBuilder:
    """Assembles a StrategyEngine with all its required workers."""

    def __init__(self, worker_builder: WorkerBuilder):
        self._worker_builder = worker_builder

    def build_context_pipeline(
        self, run_conf: RunBlueprint
    ) -> List[ContextWorker]:
        """Builds the initial pipeline of context workers."""
        context_plugin_names: List[str] = run_conf.taskboard.root.get(
            PipelinePhase.STRUCTURAL_CONTEXT, []
        )

        built_workers = [
            self._worker_builder.build(
                name=name,
                user_params=run_conf.workforce.get(name, WorkerDefinition()).params
            ) for name in context_plugin_names if name
        ]
        # Filter out any workers that failed to build
        return [worker for worker in built_workers if worker is not None]

    def build_engine(self, run_conf: RunBlueprint) -> StrategyEngine:
        """Builds and returns a configured StrategyEngine."""
        active_workers: Dict[str, Any] = {}
        for phase, plugin_names in run_conf.taskboard.root.items():
            if phase != PipelinePhase.STRUCTURAL_CONTEXT:
                worker_list = [
                    self._worker_builder.build(
                        name=name,
                        user_params=run_conf.workforce.get(name, WorkerDefinition()).params
                    ) for name in plugin_names if name
                ]
                active_workers[phase.value] = [w for w in worker_list if w is not None]

        return StrategyEngine(active_workers=active_workers)

--- END FILE: backend/assembly/engine_builder.py ---

--- START FILE: backend/assembly/plugin_registry.py ---
# backend/assembly/plugin_registry.py
"""
Contains the PluginRegistry, responsible for discovering, validating, and indexing
all available plugins within the ecosystem.

@layer: Backend (Assembly)
@dependencies: [Pydantic, PyYAML, backend.config.schemas]
@responsibilities:
    - Scans plugin directories for manifests.
    - Validates manifest schemas against the PluginManifest contract.
    - Builds and maintains the central in-memory plugin registry.
"""

from pathlib import Path
from typing import Dict, Optional, Tuple

import yaml

from pydantic import ValidationError
from backend.config.schemas.platform_schema import PlatformConfig
from backend.config.schemas.plugin_manifest_schema import PluginManifest
from backend.utils.app_logger import LogEnricher

class PluginRegistry:
    """
    Discovers all valid plugins and holds their manifest data in an
    in-memory dictionary for fast retrieval by other components.
    """

    def __init__(self, platform_config: PlatformConfig, logger: LogEnricher):
        """
        Initializes the registry by scanning and validating all plugins.

        Args:
            platform_config (PlatformConfig): The validated platform configuration object.
            logger (LogEnricher): The logger instance.
        """
        self._logger = logger
        self._plugins_root_path = Path(platform_config.plugins_root_path)
        self._registry: Dict[str, Tuple[PluginManifest, Path]] = {}

        self._scan_and_register_plugins()

    def _scan_and_register_plugins(self):
        """
        Scans the plugin directory, validates each manifest, and populates the registry.
        """
        self._logger.info(f"Scanning for plugins in '{self._plugins_root_path}'...")

        if not self._plugins_root_path.is_dir():
            self._logger.error(f"Plugin root path '{self._plugins_root_path}' not found.")
            return

        for manifest_path in self._plugins_root_path.rglob("plugin_manifest.yaml"):
            try:
                with open(manifest_path, 'r', encoding='utf-8') as f:
                    manifest_data = yaml.safe_load(f)

                # Valideer de data tegen ons Pydantic-contract
                manifest = PluginManifest(**manifest_data)

                # Controleer op dubbele namen
                if manifest.name in self._registry:
                    self._logger.warning(
                        f"Duplicate plugin name '{manifest.name}' found at '{manifest_path}'. "
                        "Skipping."
                    )
                    continue

                # Voeg de gevalideerde manifest toe aan de registry
                plugin_directory = manifest_path.parent
                self._registry[manifest.name] = (manifest, plugin_directory)

            except yaml.YAMLError as e:
                self._logger.warning(f"Could not parse manifest at '{manifest_path}': {e}")
            except ValidationError as e:
                self._logger.warning(f"Invalid manifest at '{manifest_path}':\n{e}")

        self._logger.info(
            f"Scan complete. Found and registered {len(self._registry)} valid plugins."
        )

    def get_plugin_data(self, plugin_name: str) -> Optional[Tuple[PluginManifest, Path]]:
        """
        Retrieves the validated manifest for a single plugin by its unique name.

        Args:
            plugin_name (str): The unique name of the plugin.

        Returns:
            Optional[PluginManifest]: The Pydantic model of the manifest, or None if not found.
        """
        return self._registry.get(plugin_name)

    def get_all_manifests(self) -> Dict[str, PluginManifest]:
        """
        Returns the entire registry of validated plugin manifests.

        Returns:
            Dict[str, PluginManifest]: A dictionary of all registered plugins.
        """
        return {name: data[0] for name, data in self._registry.items()}

--- END FILE: backend/assembly/plugin_registry.py ---

--- START FILE: backend/assembly/worker_builder.py ---
# backend/assembly/worker_builder.py
"""
Contains the WorkerBuilder, responsible for instantiating a single plugin worker
based on its manifest and user-provided configuration.

@layer: Backend (Assembly)
@dependencies:
    - .plugin_registry: To get the manifest (the "blueprint") for a worker.
    - backend.utils.dynamic_loader: To dynamically import plugin code.
    - backend.utils.app_logger: To create and inject a specific logger for the worker.
@responsibilities:
    - Dynamically loads a worker's code and its Pydantic schema.
    - Validates user-provided parameters against the plugin's schema.
    - Injects dependencies (like a logger) into the worker instance.
    - Returns a fully instantiated and validated worker object.
"""
from typing import Any, Dict, Optional, cast

from pydantic import ValidationError

from backend.assembly.plugin_registry import PluginRegistry
from backend.utils.dynamic_loader import load_class_from_module
from backend.utils.app_logger import LogEnricher


class WorkerBuilder:
    """Constructs a single, validated plugin worker instance."""

    def __init__(self, plugin_registry: PluginRegistry, logger: LogEnricher):
        """Initializes the WorkerBuilder.

        Args:
            plugin_registry (PluginRegistry): The registry containing all discovered plugins.
            logger (LogEnricher): The main logger, used to create child loggers.
        """
        self._registry = plugin_registry
        self._logger = logger

    def build(self, name: str, user_params: Dict[str, Any]) -> Optional[Any]:
        """Builds, validates, and instantiates a single worker.

        This method orchestrates the entire lifecycle of creating a worker, from
        finding its definition to validating user input and injecting dependencies.

        Args:
            name (str): The unique name of the worker to build.
            user_params (Dict[str, Any]): The parameter dictionary from the
                                           run_blueprint's 'workforce' section.

        Returns:
            An instantiated and validated worker object if successful, otherwise None.
        """
        # 1. Vraag Manifest en Pad op
        plugin_data = self._registry.get_plugin_data(name)
        if not plugin_data:
            self._logger.error(f"Cannot build worker: plugin '{name}' not found in registry.")
            return None

        manifest, plugin_path = plugin_data

        try:
            # Converteer het file path (bv. "plugins\\signal_generators\\fvg")
            # naar een Python module path (bv. "plugins.signal_generators.fvg")
            plugin_module_path = ".".join(plugin_path.parts)

            # 2. Dynamisch Laden met expliciete paden
            schema_module_path = f"{plugin_module_path}.{manifest.schema_path.replace('.py', '')}"
            worker_module_path = f"{plugin_module_path}.worker"

            schema_class = load_class_from_module(schema_module_path, manifest.params_class)
            worker_class = load_class_from_module(worker_module_path, manifest.entry_class)

            # 3. Valideer Parameters
            validated_params = schema_class(**user_params)

            # 4. Creëer & Injecteer Logger
            # Haal de onderliggende standaard logger op om een child te maken.
            indent_val = self._logger.extra.get('indent', 0) if self._logger.extra else 0
            current_indent = cast(int, indent_val)
            child_logger = self._logger.logger.getChild(name)
            worker_logger = LogEnricher(
                child_logger,
                indent=current_indent + 1
            )

            # 5. Instantieer de Worker
            worker_instance = worker_class(
                name=name,
                params=validated_params,
                logger=worker_logger
            )

            self._logger.info(f"Successfully built worker '{name}'.")
            return worker_instance

        except (ImportError, AttributeError) as e:
            self._logger.error(
                f"Failed to load code for worker '{name}': {e}"
            )
        except ValidationError as e:
            self._logger.error(
                f"Invalid parameters for worker '{name}':\n{e}"
            )

        return None

--- END FILE: backend/assembly/worker_builder.py ---

--- START FILE: backend/assembly/__init__.py ---
# backend/assembly/__init__.py
"""
Exposes the public API of the Assembly sub-package.
"""
__all__ = [
    "ContextBuilder",
    "DependencyValidator",
    "PluginRegistry",
    "WorkerBuilder",
]

from .context_builder import ContextBuilder
from .dependency_validator import DependencyValidator
from .plugin_registry import PluginRegistry
from .worker_builder import WorkerBuilder

--- END FILE: backend/assembly/__init__.py ---

--- START FILE: backend/config/__init__.py ---

--- END FILE: backend/config/__init__.py ---

--- START FILE: backend/config/schemas/app_schema.py ---
# backend/config/schemas/app_schema.py
"""
Contains the final, composed Pydantic model for a complete application run.

@layer: Backend (Config)
@dependencies: [Pydantic, .platform_schema, .run_schema]
@responsibilities:
    - Composes platform-level and run-level configurations into a single,
      unified, and immutable AppConfig object.
"""
from pydantic import BaseModel
from .platform_schema import PlatformConfig
from .run_schema import RunBlueprint

class AppConfig(BaseModel):
    """
    The final, composed configuration object for a run. It explicitly
    combines platform-wide settings (PlatformConfig) with the blueprint for a
    specific run (RunBlueprint), creating a single source of truth.
    """
    platform: PlatformConfig
    run: RunBlueprint

--- END FILE: backend/config/schemas/app_schema.py ---

--- START FILE: backend/config/schemas/platform_schema.py ---
# backend/config/schemas/platform_schema.py
"""
Contains Pydantic models that define the structure of the platform.yaml file.
This is the foundational contract for the entire application's configuration.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the schema for global, platform-wide settings.
"""

# --- Sub-models ---

from typing import Dict, List, Literal
from pydantic import BaseModel, Field
from backend.core.enums import LogLevel

class PlatformDataConfig(BaseModel):
    """Defines the structure for the 'data' section."""
    source_dir: str = "source_data"

class PortfolioConfig(BaseModel):
    """Defines the structure for the 'portfolio' section."""
    initial_capital: float = 10000.0
    fees_pct: float = 0.001

class LoggingConfig(BaseModel):
    """Defines the structure for the 'logging' section."""
    profile: Literal['developer', 'analysis'] = 'analysis'
    profiles: Dict[str, List[LogLevel]] # Gebruikt de LogLevel Enum

# --- Main model ---

class PlatformConfig(BaseModel):
    """
    The main Pydantic model that validates the entire platform.yaml file.
    It defines only the highest-level, essential configurations.
    """
    language: Literal['en', 'nl'] = 'nl'
    plugins_root_path: str = "plugins" # De enige verantwoordelijkheid t.o.v. plugins

    data: PlatformDataConfig = Field(default_factory=PlatformDataConfig)
    portfolio: PortfolioConfig = Field(default_factory=PortfolioConfig)

--- END FILE: backend/config/schemas/platform_schema.py ---

--- START FILE: backend/config/schemas/plugin_manifest_schema.py ---
# backend/config/schemas/plugin_manifest_schema.py
"""
Contains the Pydantic model that defines the structure of a plugin_manifest.yaml file.
This schema acts as the contract for what makes a plugin discoverable and valid.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the validated structure for a plugin's metadata.
    - Enforces the presence of critical fields for the PluginRegistry.
"""

from typing import List, Optional
from pydantic import BaseModel, Field
from backend.core.enums import PipelinePhase

class PluginManifest(BaseModel):
    """
    Validates the structure and content of a plugin's manifest.yaml file.
    This is the "ID card" of any plugin in the S1mpleTrader V2 ecosystem.
    """
    # === Core Identity (Verplicht) ===
    name: str
    version: str
    description: str
    type: PipelinePhase

    # === Code Contract (Verplicht) ===
    entry_class: str
    schema_path: str
    params_class: str

    # === Optionele Features ===
    # Data-contract: welke kolommen verwacht de plugin in de DataFrame?
    dependencies: Optional[List[str]] = None

    # Visualisatie-contract: welke Pydantic-klasse definieert de context en het render-recept?
    context_schema_class: Optional[str] = None

    provides: List[str] = Field(default_factory=list)

--- END FILE: backend/config/schemas/plugin_manifest_schema.py ---

--- START FILE: backend/config/schemas/run_schema.py ---
# backend/config/schemas/run_schema.py
"""
Contains Pydantic models that define the structure of a run_schema.yaml file.
This schema defines how a user composes a strategy from available plugins.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the schema for a single strategy configuration.
    - Validates the assignment of plugins to taskboard phases.
    - Validates the parameter definitions for the used plugins.
"""

from typing import List, Dict, Any
from pydantic import BaseModel, Field, RootModel
from backend.core.enums import PipelinePhase

class RunDataConfig(BaseModel):
    """Defines the data settings specific to this run."""
    trading_pair: str
    timeframe: str

class TaskboardConfig(RootModel[Dict[PipelinePhase, List[str]]]):
    """
    Defines which plugins are assigned to each phase.
    This is a flexible dictionary where keys must be valid PipelinePhase members.
    By inheriting from RootModel, this class instance acts directly as a dictionary.
    """

class WorkerDefinition(BaseModel):
    """
    Defines the user-provided parameters for a single plugin.
    The system will validate this 'params' dict against the plugin's own schema.py.
    """
    params: Dict[str, Any] = Field(default_factory=dict)

class RunBlueprint(BaseModel):
    """
    The main Pydantic model that validates a complete run_blueprint.yaml file.
    """
    data: RunDataConfig
    taskboard: TaskboardConfig
    workforce: Dict[str, WorkerDefinition] = Field(default_factory=dict)

--- END FILE: backend/config/schemas/run_schema.py ---

--- START FILE: backend/config/schemas/__init__.py ---

--- END FILE: backend/config/schemas/__init__.py ---

--- START FILE: backend/core/base_worker.py ---
# backend/core/base_worker.py
"""
Contains optional, concrete base classes for Strategy Workers to simplify
plugin development by automating DTO nesting and providing direct access
to key identifiers like the correlation_id.

@layer: Backend (Core)
@dependencies: [abc, typing, uuid]
@responsibilities:
    - Provide a generic BaseStrategyWorker that handles DTO nesting.
    - Provide specific, inheritable base classes for each worker category
      to minimize boilerplate code in plugins.
    - Automate the propagation of the correlation_id.
"""
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import TYPE_CHECKING, Any, List, Dict, Generic, Optional, TypeVar
from uuid import UUID

if TYPE_CHECKING:
    from backend.dtos import (
        EntrySignal,
        RiskDefinedSignal,
        RoutedTradePlan,
        Signal,
        TradePlan,
        TradingContext,
        CriticalEvent,
    )


# --- Generieke Type Variabelen (volgens PEP 484 conventie) ---
InputDTO_T = TypeVar("InputDTO_T")  # pylint: disable=invalid-name
OutputDTO_T = TypeVar("OutputDTO_T")  # pylint: disable=invalid-name


class BaseStrategyWorker(ABC, Generic[InputDTO_T, OutputDTO_T]):
    """
    A generic base class that automates DTO creation and `correlation_id` handling.

    This class should typically not be inherited from directly. Use the
    specific, category-based classes below (e.g., BaseEntryPlanner) instead,
    as they pre-configure the DTO types and field names, resulting in
    minimal boilerplate for the plugin developer.
    """

    def __init__(self, params: Any):
        self.params = params

    def proces(
        self, input_dto: InputDTO_T, context: "TradingContext"
    ) -> Optional[OutputDTO_T]:
        """
        Public method called by the StrategyEngine. It extracts the correlation_id,
        calls the plugin's specific logic, and wraps the result in the
        correct output DTO.
        """
        # Haal de gepromote correlation_id direct van de input DTO
        correlation_id = getattr(input_dto, "correlation_id", None)
        if not isinstance(correlation_id, UUID):
            return None  # Veiligheid: stop als er geen ID is in de keten

        # Roep de kernlogica van de plugin aan
        new_data = self._process_internal(input_dto, correlation_id, context)

        if new_data is None:
            return None

        output_dto_class = self._get_output_dto_class()
        source_field_name = self._get_source_field_name()

        # Bouw de argumenten voor de constructor van de nieuwe DTO
        constructor_args: Dict[str, Any] = {
            "correlation_id": correlation_id,
            source_field_name: input_dto,
            **new_data,
        }

        return output_dto_class(**constructor_args)

    @abstractmethod
    def _process_internal(
        self,
        input_dto: InputDTO_T,
        correlation_id: UUID,
        context: "TradingContext",
    ) -> Optional[Dict[str, Any]]:
        """
        Plugin-specific logic must be implemented here by the developer.

        Args:
            input_dto: The DTO from the previous pipeline stage.
            correlation_id: The unique ID of the signal chain, provided for convenience.
            context: The full trading context.

        Returns:
            A dictionary with the new fields for the output DTO,
            or None if no output should be generated.
        """
        raise NotImplementedError

    @abstractmethod
    def _get_output_dto_class(self) -> type[OutputDTO_T]:
        """Must specify the output DTO type."""
        raise NotImplementedError

    @abstractmethod
    def _get_source_field_name(self) -> str:
        """Must specify the field name for the nested source DTO."""
        raise NotImplementedError


# --- Categorie-Specifieke Basisklassen ---

class BaseSignalGenerator(ABC):
    """Base class for SignalGenerator plugins (Fase 3)."""
    def __init__(self, params: Any):
        self.params = params

    @abstractmethod
    def process(self, context: "TradingContext") -> List["Signal"]:
        """
        Generates a list of raw Signal DTOs based on the market context.

        Args:
            context: The full trading context, including the enriched DataFrame.

        Returns:
            A list of Signal DTOs, or an empty list if no opportunities are found.
        """
        raise NotImplementedError

class BaseSignalRefiner(BaseStrategyWorker["Signal", "Signal"]):
    """Base class for SignalRefiner plugins (Fase 4)."""

    def execute(
        self, input_dto: "Signal", context: "TradingContext"
    ) -> Optional["Signal"]:
        """
        Overrides the base execute method for the specific case of a refiner,
        which acts as a filter (1-to-1 or 1-to-0).
        """
        is_valid = self._process(input_dto, input_dto.correlation_id, context)
        return input_dto if is_valid else None

    @abstractmethod
    def _process(  # type: ignore
        self,
        input_dto: "Signal",
        correlation_id: UUID,
        context: "TradingContext",
    ) -> bool:
        """Return True to keep the signal, False to discard it."""
        raise NotImplementedError


class BaseEntryPlanner(BaseStrategyWorker["Signal", "EntrySignal"]):
    """Base class for EntryPlanner plugins (Fase 5)."""

    def _get_output_dto_class(self) -> type["EntrySignal"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import EntrySignal

        return EntrySignal

    def _get_source_field_name(self) -> str:
        return "signal"


class BaseExitPlanner(BaseStrategyWorker["EntrySignal", "RiskDefinedSignal"]):
    """Base class for ExitPlanner plugins (Fase 6)."""

    def _get_output_dto_class(self) -> type["RiskDefinedSignal"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import RiskDefinedSignal

        return RiskDefinedSignal

    def _get_source_field_name(self) -> str:
        return "entry_signal"


class BaseSizePlanner(BaseStrategyWorker["RiskDefinedSignal", "TradePlan"]):
    """Base class for SizePlanner plugins (Fase 7)."""

    def _get_output_dto_class(self) -> type["TradePlan"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import TradePlan

        return TradePlan

    def _get_source_field_name(self) -> str:
        return "risk_defined_signal"


class BaseOrderRouter(BaseStrategyWorker["TradePlan", "RoutedTradePlan"]):
    """Base class for OrderRouter plugins (Fase 8)."""

    def _get_output_dto_class(self) -> type["RoutedTradePlan"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import RoutedTradePlan

        return RoutedTradePlan

    def _get_source_field_name(self) -> str:
        return "trade_plan"

class BaseCriticalEventDetector(ABC):
    """Base class for CriticalEventDetector plugins (Fase 9)."""
    def __init__(self, params: Any):
        self.params = params

    @abstractmethod
    def process(
        self, routed_trade_plans: List["RoutedTradePlan"], context: "TradingContext"
    ) -> List["CriticalEvent"]:
        """
        Detects and returns a list of critical events based on the final context.

        Args:
            routed_trade_plans: The list of proposed trades for the current cycle.
            context: The full trading context.

        Returns:
            A list of CriticalEvent DTOs, or an empty list if no events are detected.
        """
        raise NotImplementedError

--- END FILE: backend/core/base_worker.py ---

--- START FILE: backend/core/constants.py ---
# backend/core/constants.py
"""
Application-wide constants
"""

--- END FILE: backend/core/constants.py ---

--- START FILE: backend/core/context_recorder.py ---
# backend/core/context_recorder.py
"""
Contains the ContextRecorder, a class that acts as a central in-memory database
for storing contextual data produced by various strategy components during a run.

@layer: Backend (Core)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Provides a single, unified interface for plugins to log contextual data.
    - Stores data in a structured way, indexed by timestamp and plugin name.
    - Serializes Pydantic models into JSON-compatible dictionaries for storage.
"""
import uuid
from typing import Any, Dict
import pandas as pd
from pydantic import BaseModel

class ContextRecorder:
    """A central, in-memory database for recording contextual data from specialists."""

    def __init__(self):
        """Initializes the ContextRecorder with an empty data log."""
        self._data_log: Dict[pd.Timestamp, Dict[str, Any]] = {}

    def add_data(
        self,
        correlation_id: uuid.UUID,
        timestamp: pd.Timestamp,
        specialist_name: str,
        context_object: BaseModel
    ):
        """
        Records a Pydantic context object from a specialist at a specific timestamp.

        The object is immediately serialized to a JSON-compatible dictionary to ensure
        immutability and prevent downstream side effects.

        Args:
            correlation_id (uuid.UUID): The unique ID of the trade lifecycle.
            timestamp (pd.Timestamp): The timestamp of the event to log.
            specialist_name (str): The name of the component logging the data.
            context_object (BaseModel): The Pydantic model with the context data.
        """
        if timestamp not in self._data_log:
            self._data_log[timestamp] = {}

        # Gebruik model_dump() om direct een dictionary te krijgen
        serializable_context = context_object.model_dump()

        # We voegen de correlation_id toe aan de gelogde data voor traceability
        serializable_context['correlation_id'] = str(correlation_id)

        self._data_log[timestamp][specialist_name] = serializable_context

    def get_all_data(self) -> Dict[pd.Timestamp, Dict[str, Any]]:
        """
        Returns the complete, raw data log.

        Returns:
            The nested dictionary containing all recorded context data.
        """
        return self._data_log

--- END FILE: backend/core/context_recorder.py ---

--- START FILE: backend/core/directive_flattener.py ---
# backend/core/directive_flattener.py
"""
Contains a utility class to flatten a deeply nested RoutedTradePlan DTO
into a simple, flat ExecutionDirective.

@layer: Backend (Core)
@dependencies: [backend.dtos, pydantic]
@responsibilities:
    - Decouples the StrategyEngine's complex data structure from the simple
      contract required by the ExecutionHandler.
    - Dynamically unnests DTOs to create a flat data structure.
"""
from typing import Any, Dict, cast
from backend.dtos.routed_trade_plan import RoutedTradePlan
from backend.dtos.execution_directive import ExecutionDirective

class DirectiveFlattener:
    """
    A utility responsible for dynamically flattening the nested trade plan
    structure into a final, flat execution directive.
    """

    def _flatten_recursively(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Recursively unnests Pydantic models within a dictionary.
        """
        flat_dict: Dict[str, Any] = {}
        for key, value in data.items():
            # --- DE FIX: Controleer op 'dict' in plaats van 'BaseModel' ---
            if isinstance(value, dict):
                # We willen de geneste container-keys (zoals 'signal', 'trade_plan') niet meenemen.
                # We pakken alleen de inhoud ervan uit.
                flat_dict.update(self._flatten_recursively(cast(Dict[str, Any], value)))
            else:
                flat_dict[key] = value
        return flat_dict

    def flatten(self, routed_trade_plan: RoutedTradePlan) -> ExecutionDirective:
        """
        Transforms a deeply nested RoutedTradePlan into a flat ExecutionDirective
        using a dynamic, recursive approach.

        Args:
            routed_trade_plan (RoutedTradePlan): The complete, nested output
                                                 from the OrderRouter (Fase 8).

        Returns:
            ExecutionDirective: A flat DTO containing all necessary data for execution.
        """
        # 1. Converteer het toplevel DTO naar een dictionary.
        nested_dict = routed_trade_plan.model_dump()

        # 2. Roep de recursieve functie aan om de dictionary plat te slaan.
        flat_data = self._flatten_recursively(nested_dict)

        # 3. Rename 'timestamp' from Signal to 'entry_time' for the directive
        if 'timestamp' in flat_data:
            flat_data['entry_time'] = flat_data.pop('timestamp')

        # 4. Creëer de uiteindelijke, platte DTO. Pydantic negeert
        #    automatisch alle overbodige velden (zoals de geneste objecten zelf).
        return ExecutionDirective(**flat_data)

--- END FILE: backend/core/directive_flattener.py ---

--- START FILE: backend/core/enums.py ---
# backend/core/enums.py
"""
Contains application-wide enumerations to provide type-safety and a single
source of truth for specific sets of values.

@layer: Core
"""
from enum import Enum

class LogLevel(str, Enum):
    """Defines all valid logging levels, including custom ones."""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"
    SETUP = "SETUP"
    MATCH = "MATCH"
    FILTER = "FILTER"
    POLICY = "POLICY"
    RESULT = "RESULT"
    TRADE = "TRADE"

class PipelinePhase(str, Enum):
    """Defines the valid phases of the 6-phase strategy funnel."""
    REGIME_FILTER = "regime_filter"
    STRUCTURAL_CONTEXT = "structural_context"
    SIGNAL_GENERATOR = "signal_generator"
    SIGNAL_REFINER = "signal_refiner"
    ENTRY_PLANNER = "entry_planner"
    EXIT_PLANNER = "exit_planner"
    SIZE_PLANNER = "size_planner"
    ORDER_ROUTER = "order_router"
    CRITICAL_EVENT_DETECTOR = "critical_event_detector"

--- END FILE: backend/core/enums.py ---

--- START FILE: backend/core/execution.py ---
"""Contains the concrete implementation of an execution handler for backtests.

This module provides the `BacktestExecutionHandler`, which is a concrete
implementation of the `ExecutionHandler` interface. It is responsible for
simulating the execution of trading directives within a backtesting environment.

@layer: Backend (Core)
@dependencies: [backend.core.interfaces, backend.dtos, backend.utils]
@responsibilities:
    - Implement the `ExecutionHandler` interface for simulated backtests.
    - Receive `ExecutionDirective` objects and translate them into trade actions.
    - Interact with a `Tradable` component (e.g., Portfolio) to open trades.
    - Log all execution activities.
"""
from typing import List

# --- CORRECTIE: Importeer de GECENTRALISEERDE interface ---
from backend.core.interfaces.execution import ExecutionHandler
from backend.core.interfaces.portfolio import Tradable
from backend.dtos import ExecutionDirective
from backend.utils.app_logger import LogEnricher

class BacktestExecutionHandler(ExecutionHandler):
    """
    Handles the execution of directives within a simulated backtest environment.
    """
    def __init__(self, tradable: Tradable, logger: LogEnricher):
        self._tradable = tradable
        self._logger = logger

    def execute_plan(self, directives: List[ExecutionDirective]):
        """
        Processes a list of execution directives by calling the appropriate
        methods on the tradable entity (Portfolio).
        """
        for directive in directives:
            # Hier kun je in de toekomst logica toevoegen voor verschillende directive types
            # De huidige implementatie geeft de directive direct door.
            self._tradable.open_trade(directive)

--- END FILE: backend/core/execution.py ---

--- START FILE: backend/core/performance_analyzer.py ---
# backend/core/performance_analyzer.py
"""
Docstring for performance_analyzer.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class PerformanceAnalyzer:
    """Docstring for PerformanceAnalyzer."""
    pass

--- END FILE: backend/core/performance_analyzer.py ---

--- START FILE: backend/core/portfolio.py ---
# backend/core/portfolio.py
"""
Contains the Portfolio class, which manages the financial state of a backtest.

@layer: Backend
@dependencies:
    - backend.core.interfaces.portfolio: Implements the Tradable protocol.
    - backend.dtos: Uses ExecutionDirective and ClosedTrade DTOs.
@responsibilities:
    - Manages the account balance based on a starting capital.
    - Executes fully-formed ExecutionDirective objects without strategic validation.
    - Holds the state for multiple active trades.
    - Maintains a list of all closed trades as ClosedTrade DTOs.
@inputs:
    - `initial_capital` (float) and `fees_pct` (float) on initialization.
    - `ExecutionDirective` DTOs to be executed.
@outputs:
    - A list of `ClosedTrade` DTOs.
"""
from typing import Any, Dict, List
from uuid import UUID
import pandas as pd

from backend.core.interfaces.portfolio import Tradable
from backend.dtos.execution_directive import ExecutionDirective
from backend.dtos.closed_trade import ClosedTrade
from backend.utils.app_logger import LogEnricher
from backend.core.context_recorder import ContextRecorder


class Portfolio(Tradable):
    """
    Manages account capital, active trades, and a list of closed trades.

    This class acts as a stateful ledger. Its primary responsibility is to
    maintain the financial state of the simulation by executing pre-calculated
    ExecutionDirective objects and updating the balance. It is a concrete implementation
    of the Tradable protocol, capable of managing multiple concurrent trades.
    """

    def __init__(self,
                 initial_capital: float,
                 fees_pct: float,
                 logger: LogEnricher,
                 context_recorder: ContextRecorder):
        """
        Initializes the Portfolio.
        """
        self._initial_capital: float = initial_capital
        self._balance: float = initial_capital
        self._fees_pct: float = fees_pct
        self.logger = logger
        self.context_recorder = context_recorder

        self._closed_trades: List[ClosedTrade] = []
        self._active_trades: Dict[UUID, Dict[str, Any]] = {}

    @property
    def initial_capital(self) -> float:
        """Returns the starting capital of the portfolio."""
        return self._initial_capital

    @property
    def balance(self) -> float:
        """Returns the current account balance."""
        return self._balance

    @property
    def closed_trades(self) -> List[ClosedTrade]:
        """Returns the list of all closed trades."""
        return self._closed_trades

    @property
    def active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """A dictionary of all currently open trades, keyed by correlation_id."""
        return self._active_trades

    @property
    def active_trade_count(self) -> int:
        """Returns the number of active trades."""
        return len(self._active_trades)

    def get_active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """Returns the dictionary of active trades."""
        return self.active_trades

    def open_trade(self, execution_directive: ExecutionDirective):
        """
        Opens a new trade based on a pre-calculated ExecutionDirective object.
        """
        for trade in self._active_trades.values():
            if trade['asset'] == execution_directive.asset:
                self.logger.error(
                    "Attempted to open a trade on an asset with an existing position.",
                    values={'asset': execution_directive.asset}
                )
                return

        if execution_directive.position_value_quote > self._balance:
            self.logger.error(
                "Insufficient capital to open trade.",
                values={'required': execution_directive.position_value_quote,
                        'available': self._balance}
            )
            return

        # Sla ALLE benodigde data op, inclusief correlation_id en signal_type
        self._active_trades[execution_directive.correlation_id] = {
            "correlation_id": execution_directive.correlation_id,
            "signal_type": execution_directive.signal_type,
            "entry_time": execution_directive.entry_time,
            "asset": execution_directive.asset,
            "direction": execution_directive.direction,
            "entry_price": execution_directive.entry_price,
            "sl_price": execution_directive.sl_price,
            "tp_price": execution_directive.tp_price,
            "position_size_asset": execution_directive.position_size_asset,
            "position_value_eur": execution_directive.position_value_quote,
        }

        self.logger.trade(
            'portfolio.open_trade',
            values={
                'direction': execution_directive.direction.upper(),
                'price': f"{execution_directive.entry_price:,.2f}",
                'sl': f"{execution_directive.sl_price:,.2f}",
                'tp': f"{execution_directive.tp_price:,.2f}"if execution_directive.tp_price else "N/A"
            }
        )

    def process_candle(self, candle: pd.Series):
        """
        Processes the latest market data candle to check for SL/TP hits
        for all active trades.
        """
        if not self._active_trades:
            return

        # FIX: Controleer of de index van de candle (candle.name) een geldig Timestamp-object is
        if not isinstance(candle.name, pd.Timestamp):
            # Log een waarschuwing of negeer de candle
            return

        exit_timestamp = candle.name # Nu weten we zeker dat het een Timestamp is

        trade_ids_to_check = list(self._active_trades.keys())

        for correlation_id in trade_ids_to_check:
            trade = self._active_trades.get(correlation_id)
            if not trade:
                continue

            exit_price = None

            # TODO: In a multi-asset scenario, the candle should contain the asset
            # it belongs to, to match against the trade's asset.

            if trade['direction'] == 'long':
                if candle['low'] <= trade['sl_price']:
                    exit_price = trade['sl_price']
                elif trade['tp_price'] and candle['high'] >= trade['tp_price']:
                    exit_price = trade['tp_price']

            elif trade['direction'] == 'short':
                if candle['high'] >= trade['sl_price']:
                    exit_price = trade['sl_price']
                elif trade['tp_price'] and candle['low'] <= trade['tp_price']:
                    exit_price = trade['tp_price']

            if exit_price:
                self._close_trade(correlation_id, exit_timestamp, exit_price)

    def _close_trade(self, correlation_id: UUID, exit_timestamp: pd.Timestamp, exit_price: float):
        """
        Closes an active trade, calculates PnL, updates the balance, and archives
        the transaction.
        """
        trade_to_close = self._active_trades.pop(correlation_id, None)
        if not trade_to_close:
            return

        price_delta = exit_price - trade_to_close['entry_price']
        if trade_to_close['direction'] == 'short':
            price_delta *= -1

        gross_pnl = price_delta * trade_to_close['position_size_asset']
        fees = trade_to_close['position_value_eur'] * self._fees_pct * 2
        net_pnl = gross_pnl - fees

        self._balance += net_pnl

        # FIX: Voeg de ontbrekende correlation_id en signal_type velden toe
        closed_trade = ClosedTrade(
            correlation_id=trade_to_close['correlation_id'],
            signal_type=trade_to_close['signal_type'],
            entry_time=trade_to_close['entry_time'],
            exit_time=exit_timestamp,
            asset=trade_to_close['asset'],
            direction=trade_to_close['direction'],
            entry_price=trade_to_close['entry_price'],
            exit_price=exit_price,
            sl_price=trade_to_close['sl_price'],
            tp_price=trade_to_close['tp_price'],
            position_value_quote=trade_to_close['position_value_eur'],
            position_size_asset=trade_to_close['position_size_asset'],
            pnl_quote=net_pnl,
        )
        self._closed_trades.append(closed_trade)

        self.logger.trade(
            'portfolio.close_trade',
            values={
                'direction': closed_trade.direction.upper(),
                'price': f"{closed_trade.exit_price:,.2f}",
                'pnl': f"{closed_trade.pnl_quote:,.2f}",
                'result': "WIN" if closed_trade.pnl_quote > 0 else "LOSS"
            }
        )

--- END FILE: backend/core/portfolio.py ---

--- START FILE: backend/core/strategy_engine.py ---
# backend/core/strategy_engine.py
"""
Contains the StrategyEngine, the core component for executing the
signal-driven phases (3-9) of the trading strategy pipeline.

@layer: Backend (Core)
@dependencies:
    - backend.core.interfaces: For adhering to the Environment contract.
    - backend.dtos: For processing the DTO chain.
    - .directive_flattener: To flatten the final trade plan.
@responsibilities:
    - Orchestrates the event-driven loop, timed by the Environment's Clock.
    - Manages the DTO dataflow from Signal generation to final RoutedTradePlan.
    - Flattens approved plans into ExecutionDirectives.
    - Detects critical system-wide events.
    - Bundles all results into a final EngineCycleResult for each tick.
"""
from typing import Dict, List, Any, Generator

from backend.core.interfaces import (
    Clock, BaseStrategyEngine, SignalGenerator, SignalRefiner, EntryPlanner,
    ExitPlanner, SizePlanner, OrderRouter, CriticalEventDetector
)
from backend.dtos import (
    TradingContext, Signal, RoutedTradePlan, EngineCycleResult, CriticalEvent
)
from .directive_flattener import DirectiveFlattener


class StrategyEngine(BaseStrategyEngine):
    """
    The engine that orchestrates the signal-driven workflow (Fase 3-9).
    """

    def __init__(self, active_workers: Dict[str, Any]):
        """Initializes the StrategyEngine with a pre-built set of workers."""
        super().__init__(active_workers=active_workers)

        self._signal_generators: List[SignalGenerator] = active_workers.get('signal_generator', [])
        self._signal_refiners: List[SignalRefiner] = active_workers.get('signal_refiner', [])
        self._entry_planner: EntryPlanner | None = active_workers.get('entry_planner')
        self._exit_planner: ExitPlanner | None = active_workers.get('exit_planner')
        self._size_planner: SizePlanner | None = active_workers.get('size_planner')
        self._order_routers: List[OrderRouter] = active_workers.get('order_router', [])
        self._critical_event_detectors: List[CriticalEventDetector] = active_workers.get(
            'critical_event_detector', []
        )
        self._flattener = DirectiveFlattener()

    def run(self,
            trading_context: TradingContext,
            clock: Clock) -> Generator[EngineCycleResult, None, None]:
        """
        Starts the main event loop and yields a complete result for each cycle.
        """
        for _timestamp, _row in clock.tick():
            final_routed_plans: List[RoutedTradePlan] = []

            raw_signals: List[Signal] = []
            for generator in self._signal_generators:
                raw_signals.extend(generator.process(context=trading_context))

            for signal in raw_signals:
                routed_plan = self._process_single_signal(signal, trading_context)
                if routed_plan:
                    final_routed_plans.append(routed_plan)

            directives = [self._flattener.flatten(plan) for plan in final_routed_plans]

            events: List[CriticalEvent] = []
            for detector in self._critical_event_detectors:
                events.extend(detector.process(final_routed_plans, trading_context))

            yield EngineCycleResult(
                execution_directives=directives,
                critical_events=events
            )

    def _process_single_signal(
        self, signal: Signal, context: TradingContext
    ) -> RoutedTradePlan | None:
        """Leidt één enkel signaal door de trechter van Fase 4 tot 8."""

        approved_signal: Signal | None = signal
        for refiner in self._signal_refiners:
            if not (approved_signal := refiner.process(approved_signal, context)):
                return None

        if not self._entry_planner:
            return None
        if not (entry_signal := self._entry_planner.process(approved_signal, context)):
            return None

        if not self._exit_planner:
            return None
        if not (risk_defined_signal := self._exit_planner.process(entry_signal, context)):
            return None

        if not self._size_planner:
            return None
        if not (trade_plan := self._size_planner.process(risk_defined_signal, context)):
            return None

        final_routed_plan: RoutedTradePlan | None = None
        for router in self._order_routers:
            if final_routed_plan := router.process(trade_plan, context):
                break

        return final_routed_plan

--- END FILE: backend/core/strategy_engine.py ---

--- START FILE: backend/core/__init__.py ---
# backend/core/__init__.py
"""
Exposes the public API of the Core sub-package, making key components
available for other layers of the application, such as the Service layer
and test suites.

This centralization allows for cleaner imports, as consumers can import
directly from `backend.core` without needing to know the internal
file structure.

@layer: Backend (Core)
"""
__all__ = [
    "StrategyEngine",
    "Portfolio",
    "BaseStrategyWorker",
    "ContextRecorder",
    "BacktestExecutionHandler"
]

from .strategy_engine import StrategyEngine
from .portfolio import Portfolio
from .base_worker import BaseStrategyWorker
from .context_recorder import ContextRecorder
from .execution import BacktestExecutionHandler

--- END FILE: backend/core/__init__.py ---

--- START FILE: backend/core/interfaces/engine.py ---
# backend/core/interfaces/engine.py
"""
Contains the behavioral contracts (ABCs) for the core strategy execution engine.

@layer: Backend (Core Interfaces)
@dependencies: [abc, typing, backend.dtos]
@responsibilities:
    - Defines the abstract contract for any component that can execute the
      signal-driven portion of a strategy.
"""
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, Generator, TYPE_CHECKING

if TYPE_CHECKING:
    from backend.core.interfaces import Clock
    from backend.dtos import TradingContext, EngineCycleResult

class BaseStrategyEngine(ABC):
    """
    Abstract contract for a Strategy Engine.

    This interface defines the "motor" that drives the core trading logic.
    It is designed to be a pure, high-performance generator of TradePlans,
    completely decoupled from the environment in which it operates.
    """
    def __init__(self, active_workers: Dict[str, Any]):
        """Initializes the engine with its pre-built "toolbox" of workers."""
        ...

    @abstractmethod
    def run(self,
            trading_context: 'TradingContext',
            clock: 'Clock') -> Generator['EngineCycleResult', None, None]:
        """
        Starts the main event loop and yields approved TradePlans.

        Args:
            trading_context (TradingContext): The shared context object.
            clock (Clock): The clock that controls the flow of time.

        Yields:
            TradePlan: A fully validated and approved trade plan, ready for execution.
        """
        ...

--- END FILE: backend/core/interfaces/engine.py ---

--- START FILE: backend/core/interfaces/environment.py ---
# backend/core/interfaces/environment.py
"""
Contains the behavioral contracts (ABCs) for the Execution Environment
and its sub-components.

@layer: Backend (Core Interfaces)
@dependencies: [abc, typing, pandas, backend.dtos]
@responsibilities:
    - Defines the abstract contracts for the operational "world".
"""
from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Generator, Tuple, TYPE_CHECKING
import pandas as pd

# --- CORRECTIE: Importeer de ExecutionHandler interface HIER ---
if TYPE_CHECKING:
    from backend.core.interfaces.execution import ExecutionHandler

class DataSource(ABC):
    """Abstract contract for any component that provides market data."""
    @abstractmethod
    def get_data(self) -> pd.DataFrame:
        """Returns the complete historical dataset for the environment."""
        ...

class Clock(ABC):
    """Abstract contract for any component that controls the flow of time."""
    @abstractmethod
    def tick(self) -> Generator[Tuple[pd.Timestamp, pd.Series], None, None]:
        """Yields the next moment in time (timestamp and data row)."""
        ...

class BaseEnvironment(ABC):
    """
    Abstract contract for an Execution Environment.
    This interface defines the "world" in which a strategy operates.
    """
    @property
    @abstractmethod
    def source(self) -> DataSource:
        """The data source for this environment."""
        ...

    @property
    @abstractmethod
    def clock(self) -> Clock:
        """The clock that controls time in this environment."""
        ...

    @property
    @abstractmethod
    def handler(self) -> "ExecutionHandler":
        """The execution handler for this environment."""
        ...

--- END FILE: backend/core/interfaces/environment.py ---

--- START FILE: backend/core/interfaces/execution.py ---
"""Defines the abstract contract for all execution handlers.

This module contains the `ExecutionHandler` Abstract Base Class (ABC), which
enforces a standard interface for any component that executes trading
directives.

@layer: Backend (Core Interfaces)
@dependencies: [abc, backend.dtos]
@responsibilities:
    - Define the `ExecutionHandler` abstract base class.
    - Specify the `execute_plan` method as the required contract for all execution environments.
"""
from abc import ABC, abstractmethod
from typing import List
from backend.dtos import ExecutionDirective

class ExecutionHandler(ABC):
    """
    Abstract Base Class that defines the contract for any component capable
    of executing trade directives.
    """

    @abstractmethod
    def execute_plan(self, directives: List[ExecutionDirective]) -> None:
        """
        Processes a list of execution directives.

        Args:
            directives (List[ExecutionDirective]): The directives to be executed.
        """
        raise NotImplementedError

--- END FILE: backend/core/interfaces/execution.py ---

--- START FILE: backend/core/interfaces/portfolio.py ---
# backend/core/interfaces/portfolio.py
"""
Contains the abstract contract (Protocol) for any component that can manage
and execute trades within the S1mpleTrader ecosystem.

@layer: Backend (Core Interfaces)
"""
from typing import Protocol, List, Dict, Any, runtime_checkable
from uuid import UUID
import pandas as pd

from backend.dtos.execution_directive import ExecutionDirective
from backend.dtos.closed_trade import ClosedTrade

@runtime_checkable
class Tradable(Protocol):
    """
    An interface for any object that can manage a financial state, open
    positions, and a history of closed trades. This contract ensures that
    high-level components like an ExecutionHandler can interact with any
    portfolio implementation in a consistent way.
    """

    @property
    def initial_capital(self) -> float:
        """The starting capital of the portfolio."""
        ...

    @property
    def balance(self) -> float:
        """The current, real-time balance of the portfolio."""
        ...

    @property
    def active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """A dictionary of all currently open trades."""
        ...

    @property
    def closed_trades(self) -> List[ClosedTrade]:
        """A list of all closed trades."""
        ...

    def open_trade(self, execution_directive: ExecutionDirective) -> None:
        """
        Receives a complete trade plan and processes it to open a new
        position, updating the internal state.
        """
        ...

    def process_candle(self, candle: pd.Series) -> None:
        """
        Processes the latest market data candle to check if any active
        trades should be closed based on their SL/TP levels.
        """
        ...

--- END FILE: backend/core/interfaces/portfolio.py ---

--- START FILE: backend/core/interfaces/worker.py ---
# backend/core/interfaces/worker.py
"""
Contains the behavioral contracts (Protocols) for all plugin worker types.

These interfaces are the "constitution" for the S1mpleTrader plugin
ecosystem, ensuring that any component created by a developer will correctly
integrate with the StrategyEngine.

@layer: Backend (Core Interfaces)
@dependencies: [typing, pandas, backend.dtos]
@responsibilities:
    - Defines the structural contracts for all types of plugin workers.
    - Enforces the logical data flow of the 9-fase strategy pipeline.
"""
from __future__ import annotations

from typing import (Any, List, Optional, Protocol, TYPE_CHECKING, runtime_checkable)
import pandas as pd

# Use TYPE_CHECKING to prevent circular imports at runtime
# while still providing type hints for static analysis.
if TYPE_CHECKING:
    from backend.dtos import (Signal, EntrySignal, RiskDefinedSignal,
                              TradePlan, RoutedTradePlan, CriticalEvent,
                              TradingContext)

# --- Base Contracts ---

@runtime_checkable
class BaseWorker(Protocol):
    """The base behavioral contract for any plugin worker."""

    def process(self, *args: Any, **kwargs: Any) -> Any:
        """The main entry point method for the worker's logic."""
        ...

@runtime_checkable
class ContextWorker(BaseWorker, Protocol):
    """
    A contract for a data enrichment worker (Fase 1 & 2).

    ContextWorkers are responsible for adding analytical data (e.g., indicators,
    market regime classifications) to the main DataFrame.
    """

    def process(self, df: pd.DataFrame, context: 'TradingContext') -> pd.DataFrame:
        ...

@runtime_checkable
class StrategyWorker(BaseWorker, Protocol):
    """A base contract for any worker operating within the main DTO pipeline."""
    ...

# --- Specific Strategy Worker Contracts (The Pipeline) ---

@runtime_checkable
class SignalGenerator(StrategyWorker, Protocol):
    """Fase 3: A contract for a worker that generates trading opportunities."""

    def process(self, context: 'TradingContext') -> List['Signal']:
        ...

@runtime_checkable
class SignalRefiner(StrategyWorker, Protocol):
    """Fase 4: A contract for a worker that filters raw signals."""

    def process(self, signal: 'Signal', context: 'TradingContext') -> Optional['Signal']:
        ...

@runtime_checkable
class EntryPlanner(StrategyWorker, Protocol):
    """Fase 5: A contract for a worker that defines the entry tactic."""

    def process(self, signal: 'Signal', context: 'TradingContext') -> Optional['EntrySignal']:
        ...

@runtime_checkable
class ExitPlanner(StrategyWorker, Protocol):
    """Fase 6: A contract for a worker that defines risk parameters (SL/TP)."""

    def process(self, entry_signal: 'EntrySignal',
                context: 'TradingContext') -> Optional['RiskDefinedSignal']:
        ...

@runtime_checkable
class SizePlanner(StrategyWorker, Protocol):
    """Fase 7: A contract for a worker that calculates position size."""

    def process(self, risk_defined_signal: 'RiskDefinedSignal',
                context: 'TradingContext') -> Optional['TradePlan']:
        ...

@runtime_checkable
class OrderRouter(StrategyWorker, Protocol):
    """Fase 8: A contract for a worker that translates a TradePlan into execution tactics."""

    def process(self, trade_plan: 'TradePlan',
                context: 'TradingContext') -> Optional['RoutedTradePlan']:
        ...

@runtime_checkable
class CriticalEventDetector(StrategyWorker, Protocol):
    """
    Fase 9: A contract for a worker that scans the final context to detect systemic events.
    """
    def process(self, routed_trade_plans: List['RoutedTradePlan'],
                context: 'TradingContext') -> List['CriticalEvent']:
        ...

--- END FILE: backend/core/interfaces/worker.py ---

--- START FILE: backend/core/interfaces/__init__.py ---
# backend/core/interfaces/__init__.py
"""Exposes all interface contracts from a single, clean namespace."""

from .worker import *
from .environment import *
from .engine import *
from .portfolio import *

--- END FILE: backend/core/interfaces/__init__.py ---

--- START FILE: backend/data/loader.py ---
# backend/data/loader.py
"""
Handles loading raw data from CSV files and performing initial cleaning.

@layer: Backend (Data)
@dependencies: [pathlib, pandas, backend.utils.app_logger]
@responsibilities:
    - Loads raw OHLCV data from a specific CSV file.
    - Performs initial data cleaning, sets the timestamp index, and handles NA values.
"""
from pathlib import Path
import pandas as pd
from backend.utils.app_logger import LogEnricher

class DataLoader:
    """Loads and performs initial preparation of OHLCV data from a CSV file."""

    def __init__(self, file_path: str, logger: LogEnricher):
        """Initializes the DataLoader."""
        self.file_path = Path(file_path)
        self.logger = logger
        if not self.file_path.is_file():
            raise FileNotFoundError(f"Data file not found at path: {self.file_path}")

    def load(self) -> pd.DataFrame:
        """Loads data from the CSV, sets the index, and cleans the data."""
        self.logger.info('loader.loading_from', values={'filename': self.file_path.name})

        df: pd.DataFrame = pd.read_csv(self.file_path) # pyright: ignore[reportUnknownMemberType]

        # Converteer timestamp naar datetime objecten, stel in als index en sorteer.
        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')
        df = df.set_index('timestamp').sort_index()

        # Verwijder rijen met ontbrekende waarden om de datakwaliteit te garanderen.
        df = df.dropna() # pyright: ignore[reportUnknownMemberType]

        self.logger.info('loader.load_success')
        return df

--- END FILE: backend/data/loader.py ---

--- START FILE: backend/data/__init__.py ---

--- END FILE: backend/data/__init__.py ---

--- START FILE: backend/dtos/backtest_result.py ---
# backend/dtos/backtest_result.py
"""
Contains the data class for storing the complete result of a single backtest run.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas]
@responsibilities:
    - Defines the standardized data structure for holding all results from a
      single backtest run, ready for analysis and presentation.
"""
from typing import Dict, Any
from pydantic import BaseModel, ConfigDict
import pandas as pd

class BacktestResult(BaseModel):
    """A container for all results of a single backtest run.

    This object acts as a standardized Data Transfer Object (DTO) that holds
    all the essential, aggregated outputs from a backtest analysis, produced
    by the PerformanceAnalyzer.

    Attributes:
        trades_df (pd.DataFrame): A DataFrame containing all ClosedTrade objects.
        equity_curve (pd.Series): A Series representing the portfolio's equity over time.
        drawdown_curve (pd.Series): A Series representing the portfolio's drawdown.
        metrics (Dict[str, Any]): A dictionary of calculated performance metrics.
        initial_capital (float): The starting capital for the run.
    """
    trades_df: pd.DataFrame
    equity_curve: pd.Series
    drawdown_curve: pd.Series
    metrics: Dict[str, Any]
    initial_capital: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/backtest_result.py ---

--- START FILE: backend/dtos/closed_trade.py ---
# backend/dtos/closed_trade.py
"""
Contains the data class for a closed trade, representing a completed transaction.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a trade that has been fully
      executed and resulted in a profit or loss.
"""
import uuid
from typing import Optional
from pydantic import BaseModel, ConfigDict
import pandas as pd

class ClosedTrade(BaseModel):
    """Represents the final, recorded result of a single completed trade.

    This DTO is created by the Portfolio after a position is closed. It serves
    as the definitive, historical record for performance analysis and reporting.
    It contains all information from the original TradePlan, enriched with the
    actual exit details and the resulting profit or loss.

    Attributes:
        correlation_id (uuid.UUID): The unique ID linking this record to its
                                    full context log. Inherited from the TradePlan.
        entry_time (pd.Timestamp): The timestamp when the trade was opened.
        exit_time (pd.Timestamp): The timestamp when the trade was closed.
        asset (str): The asset that was traded.
        direction (str): The direction of the trade ('long' or 'short').
        signal_type (str): The name of the logic that generated the original signal.
        entry_price (float): The actual entry price.
        exit_price (float): The actual exit price.
        sl_price (float): The original stop-loss price from the TradePlan.
        tp_price (Optional[float]): The original take-profit price, if any.
        position_value_quote (float): The initial value of the position.
        position_size_asset (float): The size of the position.
        pnl_quote (float): The net profit or loss of the trade, after fees.
    """
    correlation_id: uuid.UUID
    entry_time: pd.Timestamp
    exit_time: pd.Timestamp
    asset: str
    direction: str
    signal_type: str
    entry_price: float
    exit_price: float
    sl_price: float
    tp_price: Optional[float] = None
    position_value_quote: float
    position_size_asset: float
    pnl_quote: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/closed_trade.py ---

--- START FILE: backend/dtos/critical_event.py ---
# backend/dtos/critical_event.py
"""
Contains the DTO for a critical event notification.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a critical event detected
      by the StrategyEngine.
"""
import uuid
import pandas as pd
from pydantic import BaseModel, ConfigDict, Field

class CriticalEvent(BaseModel):
    """
    Represents a minimal, agnostic notification of a critical event.

    This DTO acts as an "alarm bell" generated by a CriticalEventDetector
    plugin (Fase 9). It signals that a significant systemic event has
    occurred. The detailed context that led to this event is stored
    separately in the ContextRecorder. The RunService interprets this
    event and decides on the appropriate action (e.g., halting trading).

    Attributes:
        correlation_id (uuid.UUID): A unique ID for this specific event.
        event_type (str): A string identifier for the event type (e.g., "MAX_DRAWDOWN_BREACHED").
        timestamp (pd.Timestamp): The timestamp of the candle on which the event was detected.
    """
    correlation_id: uuid.UUID = Field(default_factory=uuid.uuid4)
    event_type: str
    timestamp: pd.Timestamp

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/critical_event.py ---

--- START FILE: backend/dtos/engine_cycle_result.py ---
# backend/dtos/engine_cycle_result.py
"""
Contains the DTO that represents the complete output of a single StrategyEngine cycle.

@layer: Backend (DTO)
@dependencies: [pydantic, .execution_directive, .critical_event]
@responsibilities:
    - Bundles all outcomes of a single engine tick into one object.
    - Decouples new trade instructions from systemic event notifications.
"""
from typing import List
from pydantic import BaseModel, ConfigDict
from .execution_directive import ExecutionDirective
from .critical_event import CriticalEvent

class EngineCycleResult(BaseModel):
    """
    Represents the complete output of a single processing cycle (tick)
    of the StrategyEngine. It decouples trade proposals from critical events.

    This object is yielded by the StrategyEngine on every tick and allows the
    consuming service (e.g., BacktestService) to intelligently decide on the
    next course of action.

    Attributes:
        execution_directives (List[ExecutionDirective]): A list of new trades to be executed.
        critical_events (List[CriticalEvent]): A list of detected systemic events.
    """
    execution_directives: List[ExecutionDirective]
    critical_events: List[CriticalEvent]

    model_config = ConfigDict(arbitrary_types_allowed=True)

--- END FILE: backend/dtos/engine_cycle_result.py ---

--- START FILE: backend/dtos/entry_signal.py ---
# backend/dtos/entry_signal.py
"""
Contains the data class for a signal enriched with an entry tactic.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the data structure for a signal that has been enriched with
      a concrete entry tactic by an EntryPlanner.
"""
import uuid
from pydantic import BaseModel, ConfigDict
from .signal import Signal

class EntrySignal(BaseModel):
    """Represents a signal with a concrete entry tactic.

    This DTO is created by an EntryPlanner (Fase 5a). It enriches a raw
    Signal DTO with a calculated entry price and a descriptive entry method.
    It serves as the input for the ExitPlanner (Fase 5b).

    Attributes:
        correlation_id (uuid.UUID): The unique ID inherited from the source Signal.
        signal: the original Signal DTO.
        entry_price (float): The calculated entry price for the trade.
    """
    correlation_id: uuid.UUID
    signal: Signal
    entry_price: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/entry_signal.py ---

--- START FILE: backend/dtos/execution_directive.py ---
# backend/dtos/execution_directive.py
"""
Contains the DTO for a final, flattened execution instruction.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the flat, universal contract for an instruction sent to the
      ExecutionHandler.
"""
import uuid
from typing import Literal, Optional, Dict, Any
from pydantic import BaseModel, ConfigDict
import pandas as pd

class ExecutionDirective(BaseModel):
    """
    A flat, final, and universal instruction for the ExecutionHandler.

    This DTO is a flattened representation of a RoutedTradePlan and contains
    all necessary information to execute, manage, and track a trade. It serves
    as the definitive, simple contract between the StrategyEngine's output and
    the execution layer.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        signal_type (str): The name of the logic that generated the original signal.
        asset (str): The asset to be traded.
        direction (Literal['long', 'short']): The direction of the trade.
        entry_price (float): The calculated entry price for the trade.
        sl_price (float): The absolute stop-loss price.
        tp_price (Optional[float]): The absolute take-profit price, if any.
        position_value_quote (float): The total value of the position in the quote currency.
        position_size_asset (float): The size of the position in the base asset.
        order_type (Literal['market', 'limit']): The fundamental order type.
        limit_price (Optional[float]): The price for a limit order.
        time_in_force (Literal['GTC', 'IOC', 'FOK']): How long the order remains valid.
        post_only (bool): Flag to ensure the order is a "maker" order.
        execution_strategy (Optional[Literal['twap']]): Label for an algorithmic strategy.
        strategy_params (Optional[Dict[str, Any]]): Parameters for the algorithmic strategy.
        preferred_exchange (Optional[str]): A hint for the ExecutionHandler.
        entry_time (pd.Timestamp): From the original signal.
    """
    # Traceability & Identity
    correlation_id: uuid.UUID
    signal_type: str

    # Core Trade Parameters
    asset: str
    direction: Literal['long', 'short']
    entry_price: float
    sl_price: float
    tp_price: Optional[float]

    # Sizing
    position_value_quote: float
    position_size_asset: float

    # Tactical Execution Instructions
    order_type: Literal['market', 'limit']
    limit_price: Optional[float] = None
    time_in_force: Literal['GTC', 'IOC', 'FOK'] = 'GTC'
    post_only: bool = False
    execution_strategy: Optional[Literal['twap']] = None
    strategy_params: Optional[Dict[str, Any]] = None
    preferred_exchange: Optional[str] = None

    # Timestamps
    entry_time: pd.Timestamp

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/execution_directive.py ---

--- START FILE: backend/dtos/risk_defined_signal.py ---
# backend/dtos/risk_defined_signal.py
"""
Contains the data class for a signal enriched with exit prices (risk definition).

@layer: Backend (DTO)
@dependencies: [pydantic, uuid]
@responsibilities:
    - Defines the data structure for a signal that has been enriched with
      absolute stop-loss and take-profit prices by an ExitPlanner.
"""
import uuid
from typing import Optional
from pydantic import BaseModel, ConfigDict
from .entry_signal import EntrySignal

class RiskDefinedSignal(BaseModel):
    """Represents a signal with its risk parameters fully defined.

    This DTO is created by an ExitPlanner (Fase 5b). It enriches an
    EntrySignal with the absolute stop-loss and (optional) take-profit prices.
    It serves as the direct input for the SizePlanner (Fase 5c), providing all
    necessary information to calculate position size based on risk.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        entry_signal: the original EntrySignal DTO.
        sl_price (float): The absolute stop-loss price, defining the risk boundary.
        tp_price (Optional[float]): The absolute take-profit price, if any.
    """
    correlation_id: uuid.UUID
    entry_signal: EntrySignal
    sl_price: float
    tp_price: Optional[float] = None

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/risk_defined_signal.py ---

--- START FILE: backend/dtos/routed_trade_plan.py ---
# backend/dtos/routed_trade_plan.py
"""
Contains the DTO that represents a TradePlan decorated with execution tactics.

@layer: Backend (DTO)
@dependencies: [pydantic, uuid, backend.dtos.trade_plan]
@responsibilities:
    - Defines the universal blueprint for how an order should be executed.
"""
import uuid
from typing import Literal, Optional, Dict, Any
from pydantic import BaseModel, ConfigDict

from .trade_plan import TradePlan

class RoutedTradePlan(BaseModel):
    """
    The universal blueprint for how an order should be executed.

    This DTO is the output of an OrderRouter plugin (Fase 8). It takes the
    complete strategic intent (the TradePlan) and enriches it with concrete,
    technical execution instructions for the ExecutionHandler. It serves as the
    definitive contract between the strategy layer and the execution layer.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        trade_plan (TradePlan): The nested strategic plan to be executed.
        order_type (Literal['market', 'limit']): The fundamental order type.
        limit_price (Optional[float]): The price for a limit order.
        time_in_force (Literal['GTC', 'IOC', 'FOK']): How long the order remains valid.
        post_only (bool): Flag to ensure the order is a "maker" order.
        execution_strategy (Optional[Literal['twap']]): Label for an algorithmic strategy.
        strategy_params (Optional[Dict[str, Any]]): Parameters for the algorithmic strategy.
        preferred_exchange (Optional[str]): A hint for the ExecutionHandler.
    """
    correlation_id: uuid.UUID
    trade_plan: TradePlan

    # --- Tactical Execution Instructions ---
    order_type: Literal['market', 'limit']
    limit_price: Optional[float] = None
    time_in_force: Literal['GTC', 'IOC', 'FOK'] = 'GTC'
    post_only: bool = False
    execution_strategy: Optional[Literal['twap']] = None
    strategy_params: Optional[Dict[str, Any]] = None
    preferred_exchange: Optional[str] = None

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/routed_trade_plan.py ---

--- START FILE: backend/dtos/signal.py ---
# backend/dtos/signal.py
"""
Contains the data class for a raw, unfiltered signal event.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a raw signal event, generated
      by a SignalGenerator plugin.
"""
import uuid
from typing import Literal
from pydantic import BaseModel, Field, ConfigDict
import pandas as pd

class Signal(BaseModel):
    """Represents a pure, unrefined signal event from a specific strategy logic.

    This DTO signifies that a pattern or condition was met at a specific time.
    It contains only the essential "what, where, and when" information, plus a
    unique identifier for traceability. This is the first DTO in the
    SignalOrchestrator's pipeline.

    Attributes:
        correlation_id (uuid.UUID): The unique ID that links this signal and all
                                    subsequent objects (Trade, ClosedTrade) to its
                                    full context log in the ContextRecorder.
                                    Generated by the SignalGenerator.
        timestamp (pd.Timestamp): The timestamp of the candle where the signal occurred.
        asset (str): The asset for which the signal was generated (e.g., 'BTC/EUR').
        direction (str): The directional bias of the signal ('long' or 'short').
        signal_type (str): The name of the logic that generated the signal (e.g.,
                           'golden_cross', 'fvg_entry_detector'). This defines the
                           identity of the signal.
    """
    correlation_id: uuid.UUID = Field(default_factory=uuid.uuid4)
    timestamp: pd.Timestamp
    asset: str
    direction: Literal['long', 'short']
    signal_type: str

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/signal.py ---

--- START FILE: backend/dtos/trade_plan.py ---
# backend/dtos/trade_plan.py
"""
Contains the data class for a complete, executable trade plan.

@layer: Backend (DTO)
@dependencies: [pydantic, uuid, .risk_defined_signal]
@responsibilities:
    - Defines the standardized data structure for a fully planned trade, ready
      for the OrderRouter.
"""
import uuid
from pydantic import BaseModel, ConfigDict
from .risk_defined_signal import RiskDefinedSignal

class TradePlan(BaseModel):
    """
    Represents a complete strategic plan for a single trade.

    This DTO is created by a SizePlanner (Fase 7). It enriches a
    RiskDefinedSignal with the final position size and value. It contains
    all necessary strategic information before being passed to the
    OrderRouter (Fase 8) to be translated into tactical execution instructions.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        risk_defined_signal (RiskDefinedSignal): The nested DTO from the previous phase.
        position_value_quote (float): The total value of the position in the quote currency.
        position_size_asset (float): The size of the position in the base asset.
    """
    correlation_id: uuid.UUID
    risk_defined_signal: RiskDefinedSignal
    position_value_quote: float
    position_size_asset: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/trade_plan.py ---

--- START FILE: backend/dtos/trading_context.py ---
# backend/dtos/trading_context.py
"""
Contains the data class for the TradingContext.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, backend.core.interfaces]
@responsibilities:
    - Defines a standardized data structure to hold all shared, contextual
      information available during a single run.
"""
from __future__ import annotations
from typing import Dict, Any, TYPE_CHECKING
from pydantic import BaseModel, ConfigDict
import pandas as pd

from backend.core.context_recorder import ContextRecorder

# Gebruik TYPE_CHECKING om de circulaire import tijdens runtime te voorkomen
if TYPE_CHECKING:
    from backend.core.interfaces import Tradable


class TradingContext(BaseModel):
    """
    A container for all shared data available during a single run.
    This object is the single source of truth for the state of the world
    at the time a plugin is executed.

    Attributes:
        enriched_df (pd.DataFrame): The fully enriched DataFrame, containing all
                                    indicator and context columns.
        portfolio (Tradable): A reference to the active portfolio object.
        context_recorder (ContextRecorder): The recorder for logging detailed context.
        structural_context_registry (Dict[str, Any]): A registry for complex,
                                                      non-tabular context data.
    """
    enriched_df: pd.DataFrame
    # --- DE FIX: Gebruik een forward reference (string) voor Tradable ---
    portfolio: "Tradable"
    context_recorder: ContextRecorder
    structural_context_registry: Dict[str, Any] = {}

    def register_structural_data(self, source_plugin: str, data: Any):
        """Allows a plugin to register a complex data structure."""
        self.structural_context_registry[source_plugin] = data

    def get_structural_data(self, source_plugin: str) -> Any | None:
        """Allows a later plugin to retrieve a complex data structure."""
        return self.structural_context_registry.get(source_plugin)

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/trading_context.py ---

--- START FILE: backend/dtos/__init__.py ---
# backend/dtos/__init__.py
"""
Exposes the public API of the DTOs sub-package.

This file centralizes all DTO imports, allowing other parts of the
application to import any DTO directly from `backend.dtos` without
needing to know the specific internal file structure.

@layer: Backend (DTO)
"""
__all__ = [
    "Signal",
    "EntrySignal",
    "RiskDefinedSignal",
    "TradePlan",
    "RoutedTradePlan",
    "CriticalEvent",
    "ExecutionDirective",
    "EngineCycleResult",
    "ClosedTrade",
    "TradingContext",
    "BacktestResult",
]

from .signal import Signal
from .entry_signal import EntrySignal
from .risk_defined_signal import RiskDefinedSignal
from .trade_plan import TradePlan
from .routed_trade_plan import RoutedTradePlan
from .critical_event import CriticalEvent
from .execution_directive import ExecutionDirective
from .engine_cycle_result import EngineCycleResult
from .closed_trade import ClosedTrade
from .backtest_result import BacktestResult
from .trading_context import TradingContext

--- END FILE: backend/dtos/__init__.py ---

--- START FILE: backend/environments/backtest_environment.py ---
# backend/environments/backtest_environment.py
"""
Contains the BacktestEnvironment and its specialized sub-components, providing
a complete, isolated world for running historical strategy tests.

@layer: Backend (Environment)
@dependencies: [pandas, backend.core.interfaces, backend.data.loader]
@responsibilities:
    - Implements the BaseEnvironment interface for backtesting.
    - Orchestrates the creation of CSV-based data sources, simulated clocks,
      and backtest execution handlers.
"""
import logging
from pathlib import Path
from typing import Generator, Tuple

import pandas as pd

from backend.config.schemas.app_schema import AppConfig
# --- CORRECTIE: Importeer de JUISTE, GECENTRALISEERDE interfaces ---
from backend.core.interfaces import BaseEnvironment, Clock, DataSource, Tradable
from backend.core.interfaces.execution import ExecutionHandler
from backend.data.loader import DataLoader
from backend.utils.app_logger import LogEnricher
# --- CORRECTIE: Importeer de CONCRETE handler ---
from backend.core.execution import BacktestExecutionHandler


# --- Sub-component Implementations ---
class CSVDataSource(DataSource):
    """A data source that loads market data from a CSV file."""

    def __init__(self, source_dir: str, trading_pair: str, timeframe: str, logger: LogEnricher):
        self._logger = logger
        base_path = Path(source_dir)
        pair_filename = trading_pair.replace('/', '_')
        filename = f"{pair_filename}_{timeframe}.csv"
        file_path = base_path / filename

        self._data_loader = DataLoader(str(file_path), self._logger)
        self._data: pd.DataFrame = pd.DataFrame()

    def get_data(self) -> pd.DataFrame:
        """Loads data if not already loaded, then returns it."""
        if self._data.empty:
            self._data = self._data_loader.load()
        return self._data

class SimulatedClock(Clock):
    """A clock that simulates the passage of time by iterating over a DataFrame."""

    def __init__(self, df: pd.DataFrame):
        self._df = df

    def tick(self) -> Generator[Tuple[pd.Timestamp, pd.Series], None, None]:
        """Yields each row of the DataFrame as a moment in time."""
        for timestamp, row in self._df.iterrows():
            assert isinstance(timestamp, pd.Timestamp)
            yield timestamp, row

# --- Main Environment Class ---
class BacktestEnvironment(BaseEnvironment):
    """
    The concrete implementation of a BaseEnvironment for running backtests.
    """
    def __init__(self, app_config: AppConfig, tradable: Tradable):
        """Initializes the environment and constructs its sub-components."""
        self._logger = LogEnricher(logging.getLogger(__name__))

        self._source = CSVDataSource(
            source_dir=app_config.platform.data.source_dir,
            trading_pair=app_config.run.data.trading_pair,
            timeframe=app_config.run.data.timeframe,
            logger=self._logger
        )
        self._clock = SimulatedClock(self._source.get_data())
        self._handler = BacktestExecutionHandler(tradable, self._logger)

    @property
    def source(self) -> DataSource:
        return self._source

    @property
    def clock(self) -> Clock:
        return self._clock

    @property
    def handler(self) -> ExecutionHandler:
        return self._handler

--- END FILE: backend/environments/backtest_environment.py ---

--- START FILE: backend/environments/live_environment.py ---
# backend/environments/live_environment.py
"""
Docstring for live_environment.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class LiveTradeEnvironment:
    """Docstring for LiveTradeEnvironment."""

--- END FILE: backend/environments/live_environment.py ---

--- START FILE: backend/environments/paper_environment.py ---
# backend/environments/paper_environment.py
"""
Docstring for paper_environment.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class PaperTradeEnvironment:
    """Docstring for PaperTradeEnvironment."""
    pass

--- END FILE: backend/environments/paper_environment.py ---

--- START FILE: backend/environments/__init__.py ---
# backend/environments/__init__.py
"""
Exposes the public API of the Environments sub-package.
"""
__all__ = [
    "BacktestEnvironment",
#    "LiveEnvironment",
#    "PaperEnvironment",
]

from .backtest_environment import BacktestEnvironment
#from .live_environment import LiveEnvironment
#from .paper_environment import PaperEnvironment

--- END FILE: backend/environments/__init__.py ---

--- START FILE: backend/utils/app_logger.py ---
# utils/app_logger.py
"""
Configures and provides the application's logging system.

This module is the single source of truth for all logging-related setup.
It is designed to be configured once at the application's entry point.

@layer: Utility
@dependencies:
    - Translator: The `LogFormatter` receives a `Translator` instance to translate log message keys.
    - Constants: Uses `core.constants` for log level definitions and default profile names.
@responsibilities:
    - Defines the custom `LogFormatter` to handle translation and indentation of log messages.
    - Defines the `LogEnricher` adapter, which is the standard logger interface for the application.
    - Defines the `LogProfiler` to filter logs based on the configured profile.
    - Provides the central `configure_logging` function to bootstrap the logging system.
@inputs:
    - The application `config` dictionary.
    - A `Translator` instance.
@outputs:
    - A fully configured root logger (side-effect).
"""

# 1. Standard Library Imports
import logging
import sys
from typing import Any, Dict, List, Literal, MutableMapping, Optional, Tuple

# 3. Our Application Imports
from backend.utils.translator import Translator
from backend.core.enums import LogLevel
from backend.config.schemas.platform_schema import LoggingConfig

class LogFormatter(logging.Formatter):
    """A custom log formatter that handles translation, value formatting, and indentation.

    This formatter intercepts the log record, translates the message key if
    applicable, formats the translated string with any provided values, and
    applies an indentation level based on the record's context.
    """

    def __init__(self,
                 fmt: Optional[str] = None,
                 datefmt: Optional[str] = None,
                 style: Literal['%', '{', '$'] = '%',
                 translator: Optional[Translator] = None):
        """Initializes the LogFormatter.

        Args:
            fmt (str, optional): The format string for the log. Defaults to None.
            datefmt (str, optional): The format string for dates. Defaults to None.
            style (str, optional): The formatting style. Defaults to '%'.
            translator (Translator, optional): The translator instance for
                                               translating log keys. Defaults to None.
        """
        super().__init__(fmt, datefmt, style)
        self.translator = translator

    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record by translating, populating, and indenting it.

        Args:
            record (logging.LogRecord): The log record to format.

        Returns:
            The fully formatted log message string.
        """
        key = record.msg
        translated_template = key
        values_dict = getattr(record, 'values', {})

        # Step 1: Translate the message key, if it's a valid key.
        if self.translator and isinstance(key, str) and '.' in key and ' ' not in key:
            translated_template = self.translator.get(key, default=key)

        # Step 2: Format the template with any provided values.
        final_message = translated_template
        if values_dict:
            try:
                final_message = translated_template.format(**values_dict)
            except (KeyError, TypeError):
                final_message = f"{translated_template} [FORMATTING ERROR]"

        record.msg = final_message
        record.args = ()

        # Step 3: Apply our custom indentation directly to the message content.
        indent_level = getattr(record, 'indent', 0)
        indented_message = "  " * indent_level + final_message

        # Place the fully prepared (and indented) message back into the record.
        record.msg = indented_message

        # Step 4: Let the original Formatter handle the primary layout (e.g., [INFO   ]).
        return super().format(record)

class LogEnricher(logging.LoggerAdapter[logging.Logger]):
    """A logger adapter that enriches log records with indentation and context.

    This adapter provides the standard logging interface for the application. Its
    main purpose is to shuttle contextual data (like 'indent' or 'values') into
    the 'extra' payload of a log record, which can then be used by the
    `LogFormatter`. It also provides convenience methods for custom log levels.
    """

    def __init__(self, logger: logging.Logger, indent: int = 0):
        """Initializes the LogEnricher adapter.

        Args:
            logger: The logger instance to wrap.
            indent: The indentation level for messages from this logger.
        """
        super().__init__(logger, {'indent': indent})

    def process(
        self, msg: Any, kwargs: MutableMapping[str, Any]
    ) -> Tuple[Any, MutableMapping[str, Any]]:
        """Merges the adapter's contextual information into the kwargs.

        Args:
            msg: The log message.
            kwargs: Keyword arguments to the logging call.

        Returns:
            A tuple containing the message and the modified keyword arguments.
        """
        # Ensure 'extra' dictionary exists and merge adapter's context into it.
        kwargs["extra"] = kwargs.get("extra", {})
        kwargs["extra"].update(self.extra)

        # Move 'values' from kwargs into the 'extra' dict for the formatter.
        if 'values' in kwargs:
            kwargs['extra']['values'] = kwargs.pop('values')

        return msg, kwargs

    # --- Convenience methods for custom levels ---
    def setup(self, key: str, **values: Any) -> None:
        """Logs a message with the SETUP level."""
        self.log(CUSTOM_LEVELS[LogLevel.SETUP], key, values=values)

    def match(self, key: str, **values: Any) -> None:
        """Logs a message with the MATCH level."""
        self.log(CUSTOM_LEVELS[LogLevel.MATCH], key, values=values)

    def filter(self, key: str, **values: Any) -> None:
        """Logs a message with the FILTER level."""
        self.log(CUSTOM_LEVELS[LogLevel.FILTER], key, values=values)

    def policy(self, key: str, **values: Any) -> None:
        """Logs a message with the POLICY level."""
        self.log(CUSTOM_LEVELS[LogLevel.POLICY], key, values=values)

    def result(self, key: str, **values: Any) -> None:
        """Logs a message with the RESULT level."""
        self.log(CUSTOM_LEVELS[LogLevel.RESULT], key, values=values)

    def trade(self, key: str, **values: Any) -> None:
        """Logs a message with the TRADE level."""
        self.log(CUSTOM_LEVELS[LogLevel.TRADE], key, values=values)

class LogProfiler(logging.Filter):
    """A logging filter that allows messages based on the active profile."""

    def __init__(self, profile: str, profile_definitions: Dict[str, List[LogLevel]]):
        """Initializes the filter.

        Args:
            profile: The name of the active logging profile.
            profile_definitions: A dictionary defining all available profiles
                                 and their allowed log level names.
        """
        super().__init__()
        allowed_levels_for_profile = profile_definitions.get(profile, [])
        self.allowed_levels = {level.value for level in allowed_levels_for_profile}

    def filter(self, record: logging.LogRecord) -> bool:
        """Determines if a log record should be processed.

        Args:
            record: The log record to check.

        Returns:
            True if the record's level name is in the allowed set for the
            active profile, False otherwise.
        """
        return record.levelname in self.allowed_levels

# Define and register custom log levels. This mapping is an implementation
# detail of the logger and is therefore defined here, not in core.constants.
CUSTOM_LEVELS = {
    LogLevel.SETUP: 15,
    LogLevel.MATCH: 22,
    LogLevel.FILTER: 23,
    LogLevel.POLICY: 24,
    LogLevel.RESULT: 25,
    LogLevel.TRADE: 26,
}

def configure_logging(logging_config: LoggingConfig, translator: Translator):
    """Configures the central, root logger for the entire application.

    This function should be called only once from `main.py`. It sets up custom
    log levels, creates a handler, attaches the custom `LogFormatter` and
    `LogProfiler` filter, and adds the handler to the root logger.

    Args:
        logging_config: The Pydantic model for the logging configuration.
        translator: An existing translator instance to be used by the formatter.
    """
    for level_enum, level_value in CUSTOM_LEVELS.items():
        logging.addLevelName(level_value, level_enum.value)

    # Use dotted access on the Pydantic model
    log_profile = logging_config.profile
    profile_definitions = logging_config.profiles
    log_format = '[%(levelname)-8s] %(message)s'

    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    # Clear any existing handlers to prevent duplicate logs.
    if logger.hasHandlers():
        logger.handlers.clear()

    handler = logging.StreamHandler(sys.stdout)
    # The Formatter is the only component that needs the translator.
    handler.setFormatter(LogFormatter(log_format, translator=translator))
    handler.addFilter(LogProfiler(log_profile, profile_definitions))
    logger.addHandler(handler)

--- END FILE: backend/utils/app_logger.py ---

--- START FILE: backend/utils/data_utils.py ---
# backend/utils/data_utils.py
"""
Utility functions for data manipulation
"""

--- END FILE: backend/utils/data_utils.py ---

--- START FILE: backend/utils/dynamic_loader.py ---
# backend/utils/dynamic_loader.py
"""
Handles the dynamic loading of classes from plugin modules.

@layer: Backend (Utility)
@dependencies: [importlib]
@responsibilities:
    - Provides a single function to dynamically import a class from a module
      using a string-based path and class name.
"""

import importlib
from typing import Any

def load_class_from_module(module_path: str, class_name: str) -> Any:
    """
    Dynamically imports a module and returns a specific class from it.

    Args:
        module_path (str): The full, dot-separated path to the Python module
                           (e.g., "plugins.signal_generators.my_plugin.worker").
        class_name (str): The exact name of the class to load from the module.

    Raises:
        ImportError: If the module cannot be found.
        AttributeError: If the class does not exist within the module.

    Returns:
        The loaded class object (not an instance).
    """
    try:
        module = importlib.import_module(module_path)
        loaded_class = getattr(module, class_name)
        return loaded_class
    except ImportError as e:
        raise ImportError(f"Could not import module '{module_path}': {e}") from e
    except AttributeError as e:
        raise AttributeError(
            f"Class '{class_name}' not found in module '{module_path}': {e}"
        ) from e

--- END FILE: backend/utils/dynamic_loader.py ---

--- START FILE: backend/utils/translator.py ---
# utils/translator.py
"""
Handles loading and retrieving translated strings for the application.

@layer: Utility
@dependencies:
    - Constants: Uses `core.constants` to get the default language and locale directory path.
@responsibilities:
    - Loads the appropriate language file based on the application configuration.
    - Provides a `get` method to retrieve translated strings using dot-notation keys.
    - Provides a `get_param_name` method for the special case of parameter display names.
@inputs:
    - The application `config` dictionary on initialization.
    - Dot-notation keys and format values for getter methods.
@outputs:
    - Translated and formatted strings.
"""

# 1. Standard Library Imports
from pathlib import Path
from typing import Any, Dict

# 2. Third-Party Imports
import yaml

# 3. Our Application Imports
from backend.config.schemas.platform_schema import PlatformConfig

class Translator:
    """Loads and manages internationalization (i18n) strings from YAML files.

    This class is instantiated once at startup. It loads the appropriate
    language file based on the application configuration and provides methods
    to retrieve translated strings using a dot-notation key.
    """
    def __init__(self, platform_config: PlatformConfig):
        """Initializes the Translator by loading the appropriate language file.

        Args:
            app_config (AppConfig): The application Pydantic config object.
        """
        lang_path = Path('locales') / f"{platform_config.language}.yaml"
        self.strings: Dict[str, Any] = {}
        try:
            with open(lang_path, 'r', encoding='utf-8') as f:
                self.strings = yaml.safe_load(f)
        except FileNotFoundError:
            print(f"WARNING: Language file not found at {lang_path}")

    def get(self, key: str, default: str | None = None, **kwargs: Any) -> str:
        """Retrieves and formats a nested translated string using dot-notation.

        If the key is not found, it returns the default value, or the key
        itself if no default is provided.

        Args:
            key (str): The dot-notation key (e.g., 'app.start').
            default (str, optional): A fallback value to return if the key is
                                     not found. Defaults to None.
            **kwargs: Values to format into the translated string.

        Returns:
            The translated and formatted string.
        """
        try:
            value: Any = self.strings
            for part in key.split('.'):
                value = value[part]

            # A valid translation must be a string. If we resolved a dict
            # (incomplete key), it's invalid.
            if not isinstance(value, str):
                return default or key

            return value.format(**kwargs)
        except (KeyError, TypeError):
            return default or key

    def get_param_name(self, param_path: str, default: str | None = None) -> str:
        """Retrieves a display name for a full parameter path.

        This performs a direct lookup in the 'params_display_names' dictionary
        within the language file, which is a flat key-value map.

        Args:
            param_path (str): The full parameter path to look up.
            default (str, optional): The value to return if the path is not
                                     found. Defaults to the original param_path.

        Returns:
            The display name or a fallback value.
        """
        param_dict = self.strings.get('params_display_names', {})
        return param_dict.get(param_path, default or param_path)

--- END FILE: backend/utils/translator.py ---

--- START FILE: backend/utils/__init__.py ---

--- END FILE: backend/utils/__init__.py ---

--- START FILE: config/index.yaml ---
# Placeholder for config/index.yaml

--- END FILE: config/index.yaml ---

--- START FILE: config/platform.yaml ---
# config/platform.yaml
# De minimale, fundamentele configuratie voor S1mpleTrader V2.

language: 'en'
plugins_root_path: 'plugins'

data:
  source_dir: 'source_data'

portfolio:
  initial_capital: 10000.0
  fees_pct: 0.001

logging:
  profile: 'analysis'
  profiles:
    developer: ['WARNING', 'ERROR', 'CRITICAL']
    analysis: ['DEBUG', 'INFO', 'MATCH', 'FILTER', 'TRADE', 'RESULT', 'WARNING', 'ERROR', 'CRITICAL']

--- END FILE: config/platform.yaml ---

--- START FILE: config/__init__.py ---

--- END FILE: config/__init__.py ---

--- START FILE: config/optimizations/optimize_atr_params.yaml ---
# Placeholder for config/optimizations/optimize_atr_params.yaml

--- END FILE: config/optimizations/optimize_atr_params.yaml ---

--- START FILE: config/overrides/use_eth_pair.yaml ---
# Placeholder for config/overrides/use_eth_pair.yaml

--- END FILE: config/overrides/use_eth_pair.yaml ---

--- START FILE: config/runs/mss_fvg_strategy.yaml ---
# Placeholder for config/runs/mss_fvg_strategy.yaml

--- END FILE: config/runs/mss_fvg_strategy.yaml ---

--- START FILE: config/variants/robustness_test.yaml ---
# Placeholder for config/variants/robustness_test.yaml

--- END FILE: config/variants/robustness_test.yaml ---

--- START FILE: docs/folder_file_structure.txt ---
S1mpleTraderV2/
├── backend
│   ├── assembly
│   │   ├── __init__.py
│   │   ├── context_builder.py
│   │   ├── dependency_validator.py
│   │   ├── plugin_registry.py
│   │   └── worker_builder.py
│   ├── config
│   │   ├── schemas
│   │   │   ├── __init__.py
│   │   │   ├── app_schema.py
│   │   │   ├── platform_schema.py
│   │   │   ├── plugin_manifest_schema.py
│   │   │   └── run_schema.py
│   │   └── __init__.py
│   ├── core
│   │   ├── interfaces
│   │   │   ├── __init__.py
│   │   │   ├── engine.py
│   │   │   ├── environment.py
│   │   │   ├── portfolio.py
│   │   │   └── worker.py
│   │   ├── __init__.py
│   │   ├── base_worker.py
│   │   ├── constants.py
│   │   ├── context_recorder.py
│   │   ├── directive_flattener.py
│   │   ├── enums.py
│   │   ├── execution.py
│   │   ├── performance_analyzer.py
│   │   ├── portfolio.py
│   │   └── strategy_engine.py
│   ├── data
│   │   ├── __init__.py
│   │   └── loader.py
│   ├── dtos
│   │   ├── __init__.py
│   │   ├── backtest_result.py
│   │   ├── closed_trade.py
│   │   ├── critical_event.py
│   │   ├── engine_cycle_result.py
│   │   ├── entry_signal.py
│   │   ├── execution_directive.py
│   │   ├── risk_defined_signal.py
│   │   ├── routed_trade_plan.py
│   │   ├── signal.py
│   │   ├── trade_plan.py
│   │   └── trading_context.py
│   ├── environments
│   │   ├── __init__.py
│   │   ├── backtest_environment.py
│   │   ├── live_environment.py
│   │   └── paper_environment.py
│   ├── utils
│   │   ├── __init__.py
│   │   ├── app_logger.py
│   │   ├── data_utils.py
│   │   ├── dynamic_loader.py
│   │   └── translator.py
│   ├── __init__.py
│   └── py.typed
├── config
│   ├── optimizations
│   │   └── optimize_atr_params.yaml
│   ├── overrides
│   │   └── use_eth_pair.yaml
│   ├── runs
│   │   └── mss_fvg_strategy.yaml
│   ├── variants
│   │   └── robustness_test.yaml
│   ├── __init__.py
│   ├── index.yaml
│   └── platform.yaml
├── docs
│   ├── development
│   │   ├── KanBan
│   │   │   ├── backlog_to_github.py
│   │   │   ├── clear_github_issues.py
│   │   │   └── product_backlog.csv
│   │   └── USM_DEV_ROADMAP.md
│   ├── system
│   │   ├── 0_V2_ARCHITECTURE.md
│   │   ├── 2_ARCHITECTURE.md
│   │   ├── 3_PLUGIN_ANATOMY.md
│   │   ├── 4_WORKFLOW_AND_ORCHESTRATOR.md
│   │   ├── 5_FRONTEND_INTEGRATION.md
│   │   ├── 6_RESILIENCE_AND_OPERATIONS.md
│   │   ├── 7_DEVELOPMENT_STRATEGY.md
│   │   ├── 8_META_WORKFLOWS.md
│   │   ├── 9_CODING_STANDAARDS.md
│   │   ├── A_BIJLAGE_TEMINOLOGIE.md
│   │   ├── B_BIJLAGE_OPENSTAANDE_VRAAGSTUKKEN.md
│   │   └── C_BIJLAGE_MVP
│   ├── folder_file_structure.txt
│   └── PROPOSED_FOLDER_STRUCTURE.md
├── frontends
│   ├── cli
│   │   ├── presenters
│   │   │   └── optimization_presenter.py
│   │   └── reporters
│   │       └── cli_reporter.py
│   ├── web
│   │   ├── api
│   │   │   ├── routers
│   │   │   │   ├── __init__.py
│   │   │   │   ├── backtest_router.py
│   │   │   │   └── plugins_router.py
│   │   │   ├── __init__.py
│   │   │   └── main.py
│   │   └── ui
│   │       ├── src
│   │       │   ├── components
│   │       │   ├── services
│   │       │   └── App.tsx
│   │       └── package.json
│   └── __init__.py
├── locales
│   ├── en.yaml
│   └── nl.yaml
├── plugins
│   ├── portfolio_overlays
│   │   ├── max_drawdown_overlay
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── regime_filters
│   │   ├── adx_trend_filter
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── signal_generators
│   │   ├── fvg_entry_detector
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── signal_refiners
│   │   ├── volume_spike_refiner
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── structural_context
│   │   ├── market_structure_detector
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── trade_constructors
│   │   ├── liquidity_target_exit
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   └── __init__.py
├── services
│   ├── api_services
│   │   ├── __init__.py
│   │   ├── plugin_query_service.py
│   │   └── visualization_service.py
│   ├── __init__.py
│   ├── optimization_service.py
│   ├── parallel_run_service.py
│   ├── strategy_operator.py
│   └── variant_test_service.py
├── source_data
│   └── BTC_EUR_15m.csv
├── tests
│   ├── backend
│   │   ├── assembly
│   │   │   ├── __init__.py
│   │   │   ├── test_context_builder.py
│   │   │   ├── test_dependency_validator.py
│   │   │   ├── test_plugin_registry.py
│   │   │   └── test_worker_builder.py
│   │   ├── core
│   │   │   ├── test_context_recoreder.py
│   │   │   ├── test_directive_flattener.py
│   │   │   ├── test_portfolio.py
│   │   │   └── test_strategy_engine.py
│   │   ├── data
│   │   │   ├── __init__.py
│   │   │   └── test_data_loader.py
│   │   ├── environments
│   │   │   ├── __init__.py
│   │   │   └── test_backtest_environment.py
│   │   └── __init__.py
│   ├── services
│   │   └── test_strategy_operator.py
│   └── __init__.py
├── tools
│   ├── __init__.py
│   ├── bootstrap_v2.py
│   ├── collect_context.py
│   ├── generate_structure.py
│   └── plugin_creator.py
├── .env
├── .gitignore
├── .pylintrc
├── __init__.py
├── GEMINI.md
├── pytest.ini
├── requirements.txt
├── run_backtest_cli.py
├── run_supervisor.py
└── run_web.py

--- END FILE: docs/folder_file_structure.txt ---

--- START FILE: docs/project_context.txt ---
--- START FILE: GEMINI.md ---
# S1mpleTrader V2 - AI Assistent Instructies

Hallo! Ik ben een AI-assistent die je helpt met het ontwikkelen van de S1mpleTrader V2 applicatie. Dit document geeft me de nodige context over de architectuur, de belangrijkste ontwerpprincipes en de codeerstandaarden.

## 1. Visie & Kernprincipes

Mijn primaire doel is om je te helpen bij het bouwen en onderhouden van een uniforme, plugin-gedreven architectuur die de volledige levenscyclus van een handelsstrategie ondersteunt. Ik houd me aan de volgende vier kernprincipes:

* **Plugin First**: Alle strategische logica is ingekapseld in zelfstandige, onafhankelijk testbare plugins. Dit is de kern van het systeem.
* **Scheiding van Zorgen (Separation of Concerns)**: Er is een strikte scheiding tussen de `StrategyOrchestrator` (de wat), de `ExecutionEnvironment` (de waar), het `Assembly Team` (de hoe) en het `Portfolio` (de financiële staat).
* **Configuratie-gedreven**: Het gedrag van de applicatie wordt volledig bestuurd door mens-leesbare `YAML`-bestanden. De code is de motor, de configuratie is de bestuurder.
* **Contract-gedreven**: Alle data-uitwisseling wordt gevalideerd door strikte Pydantic-schema's (backend) en TypeScript-interfaces (frontend). Dit zorgt voor voorspelbaarheid en type-veiligheid.

## 2. Architectuur Overzicht

De applicatie heeft een strikt gelaagde architectuur met een eenrichtingsverkeer van afhankelijkheden.

+-------------------------------------------------------------+
|  Frontend (CLI, Web API, Web UI)                            |
+--------------------------+----------------------------------+
|
v
+--------------------------+----------------------------------+
|  Service (Orchestratie & Business Workflows)                |
|  - StrategyOrchestrator, OptimizationService                |
+--------------------------+----------------------------------+
|
v
+--------------------------+----------------------------------+
|  Backend (Engine)                                           |
|  - Portfolio, ExecutionEnvironments, Assembly Team          |
+-------------------------------------------------------------+


* **Backend (`/backend`)**: De "engine". Bevat alle kernlogica en is ontworpen als een onafhankelijke library.
* **Service (`/services`)**: De "lijm". Orkestreert backend-componenten tot complete business workflows. Hier leeft de `StrategyOrchestrator`.
* **Frontend (`/frontends`)**: De gebruikersinterface (Web UI, API, CLI).

## 3. De 6-Fasen Quant Workflow

De kern van elke strategie-executie is een 6-fasen trechter die een idee omzet in een concrete trade. Ik moet deze flow begrijpen en respecteren bij het schrijven van code.

1.  **Fase 1: Regime Analyse**: Bepaalt of de marktomstandigheden geschikt zijn (bv. trending).
2.  **Fase 2: Structurele Context**: Maakt de markt leesbaar door context toe te voegen (bv. marktstructuur, trends).
3.  **Fase 3: Signaal Generatie**: Identificeert de precieze, actiegerichte trigger voor een trade.
4.  **Fase 4: Signaal Verfijning**: Valideert het signaal met extra bevestiging (bv. volume).
5.  **Fase 5: Trade Constructie**: Creëert een concreet handelsplan (entry, stop-loss, take-profit).
6.  **Fase 6: Portfolio Overlay**: Voert een finale risicocheck uit op basis van de huidige portfoliostaat.

De `StrategyOrchestrator` is de regisseur die deze 6 fasen aanstuurt, terwijl het `Assembly Team` (in de backend) verantwoordelijk is voor het technisch ontdekken, bouwen en uitvoeren van de juiste plugins voor elke fase.

## 4. Anatomie van een Plugin

Plugins zijn de fundamentele bouwstenen. Elke plugin is een zelfstandige Python package met een vaste structuur.

* `plugins/[plugin_naam]/`:
    * `plugin_manifest.yaml`: De "ID-kaart" die de plugin vindbaar maakt. Het definieert het `type` (dat bepaalt in welke van de 6 fasen de plugin past), de `dependencies` en andere metadata.
    * `worker.py`: Bevat de Python-klasse met de daadwerkelijke businesslogica.
    * `schema.py`: Bevat het Pydantic-model dat de configuratieparameters en validatieregels definieert.
    * `state.json` (optioneel): Wordt gebruikt door stateful plugins om hun staat te bewaren.

## 5. Codeerstandaarden & Best Practices

Ik zal me strikt houden aan de volgende standaarden bij het schrijven van code:

1.  **Code Stijl**:
    * Alle Python-code moet **PEP 8 compliant** zijn.
    * **Volledige Type Hinting** is verplicht.
    * Commentaar en docstrings zijn in het **Engels**.
    * Gebruik **Google Style Python Docstrings** voor alle functies en klassen.

2.  **Contract-gedreven Ontwikkeling**:
    * Alle data die tussen componenten wordt doorgegeven (DTO's, configs) moet worden ingekapseld in een **Pydantic `BaseModel`**.

3.  **Logging**:
    * De primaire output voor analyse is een gestructureerd **`run.log.json`**-bestand.
    * Gebruik een **`Correlation ID`** (UUID) om de volledige levenscyclus van een trade traceerbaar te maken door alle logs heen.

4.  **Testen**:
    * Code zonder tests is incompleet. Elke plugin is **verplicht** om een `tests/test_worker.py` te hebben.

5.  **Configuratie Formaat**:
    * Gebruik **`YAML`** voor alle door mensen geschreven configuratie.
    * Gebruik **`JSON`** voor machine-naar-machine data-uitwisseling (bv. API's, state-bestanden).

## 6. Snelle Referentie: Kernterminologie

* **Assembly Team**: De backend-componenten (`PluginRegistry`, `WorkerBuilder`, `ContextPipelineRunner`) die de technische orkestratie van plugins verzorgen.
* **Run**: Een `YAML`-bestand (`run_schema.yaml`) dat een complete strategie-configuratie beschrijft.
* **DTO (Data Transfer Object)**: Een Pydantic-model (`Signal`, `Trade`) dat als strikt contract dient voor data-uitwisseling.
* **ExecutionEnvironment**: De backend-laag die de "wereld" definieert waarin een strategie draait (`Backtest`, `Paper`, `Live`).
* **StrategyOrchestrator**: De "regisseur" in de Service-laag die de 6-fasen trechter uitvoert voor één enkele run.

Door deze principes en structuren te volgen, help ik je om een consistente, robuuste en onderhoudbare codebase te bouwen. Laten we beginnen!

--- END FILE: GEMINI.md ---

--- START FILE: requirements.txt ---
# requirements.txt

# --- Data & Analysis ---
# Kernbibliotheken voor dataverwerking en analyse.
pandas
pandas-stubs
numpy
scipy
pyarrow
openpyxl

# --- Configuration ---
# Voor het inlezen van YAML-configuratiebestanden.
PyYAML

# --- Web & API Server ---
# Benodigdheden voor de web-interface en de API.
fastapi
uvicorn[standard]
python-multipart
Jinja2

# --- User Interface (CLI) ---
# Tools voor de command-line interface.
tqdm
rich
prompt-toolkit

# --- Code Quality & Contracts ---
# Voor het afdwingen van code-stijl en datavalidatie.
pylint
pydantic

# --- Testing ---
# Framework en tools voor het schrijven en uitvoeren van tests.
pytest
pytest-mock

# --- Visualization ---
# Voor het genereren van grafieken en visuele rapportages.
plotly

# --- Documentation Generation ---
# Tools voor het genereren van de projectdocumentatie.
sphinx
sphinx-rtd-theme
--- END FILE: requirements.txt ---

--- START FILE: run_backtest_cli.py ---
# run_backtest_cli.py
"""
Entrypoint: For automated (headless) runs
"""

--- END FILE: run_backtest_cli.py ---

--- START FILE: run_supervisor.py ---
# run_supervisor.py
"""
Entrypoint: Starts the live trading supervisor
"""

--- END FILE: run_supervisor.py ---

--- START FILE: run_web.py ---
# run_web.py
"""
Entrypoint: Starts the Web UI and API
"""

--- END FILE: run_web.py ---

--- START FILE: __init__.py ---

--- END FILE: __init__.py ---

--- START FILE: .pytest_cache/README.md ---
# pytest cache directory #

This directory contains data from the pytest's cache plugin,
which provides the `--lf` and `--ff` options, as well as the `cache` fixture.

**Do not** commit this to version control.

See [the docs](https://docs.pytest.org/en/stable/how-to/cache.html) for more information.

--- END FILE: .pytest_cache/README.md ---

--- START FILE: backend/__init__.py ---
# backend/__init__.py
"""
Exposes the public API of the Backend package.
"""
__all__ = [
    # from .core
    "StrategyEngine",
    "Portfolio",
    "BaseStrategyWorker",
    "ContextRecorder",
    # from .dtos
    "Signal",
    "EntrySignal",
    "RiskDefinedSignal",
    "TradePlan",
    "RoutedTradePlan",
    "CriticalEvent",
    "ExecutionDirective",
    "EngineCycleResult",
    "ClosedTrade",
    "TradingContext",
    "BacktestResult",
    # from .environments
    "BacktestEnvironment",
#    "LiveEnvironment",
#    "PaperEnvironment",
    # from .assembly
    "ContextBuilder",
    "DependencyValidator",
    "PluginRegistry",
    "WorkerBuilder",
]

from .core import (
    StrategyEngine,
    Portfolio,
    BaseStrategyWorker,
    ContextRecorder,
)
from .dtos import (
    Signal,
    EntrySignal,
    RiskDefinedSignal,
    TradePlan,
    RoutedTradePlan,
    CriticalEvent,
    ExecutionDirective,
    EngineCycleResult,
    ClosedTrade,
    TradingContext,
    BacktestResult,
)
from .environments import (
    BacktestEnvironment,
#    LiveEnvironment,
#    PaperEnvironment,
)
from .assembly import (
    ContextBuilder,
    DependencyValidator,
    PluginRegistry,
    WorkerBuilder,
)

--- END FILE: backend/__init__.py ---

--- START FILE: backend/assembly/context_builder.py ---
# backend/assembly/context_builder.py
"""
Contains the ContextBuilder, responsible for executing a sequence of
context-providing plugins to enrich a DataFrame.

@layer: Backend (Assembly)
@dependencies: [pandas]
@responsibilities:
    - Sequentially applies a list of instantiated context workers to a DataFrame.
    - Ensures the original DataFrame is not modified (works on a copy).
    - Returns the final, enriched DataFrame.
"""
from typing import List

import pandas as pd

from backend.core.interfaces import ContextWorker

class ContextBuilder:
    """Executes a pipeline of context workers to enrich a DataFrame."""

    def build(self,
              initial_df: pd.DataFrame,
              context_pipeline: List[ContextWorker]
        ) -> pd.DataFrame:
        """
        Applies a list of context workers sequentially to a DataFrame.

        This method takes a starting DataFrame and a list of worker objects
        (which are expected to have a 'process' method). It creates a copy of
        the DataFrame and then passes it through each worker in order, with the
        output of one worker becoming the input for the next.

        Args:
            initial_df (pd.DataFrame): The raw OHLCV DataFrame.
            context_pipeline (List[object]): An ordered list of instantiated
                                             context worker objects.

        Returns:
            pd.DataFrame: The final, enriched DataFrame after all workers
                          have been executed.
        """
        # Werk altijd op een kopie om onverwachte bijeffecten te voorkomen.
        enriched_df = initial_df.copy()

        for worker in context_pipeline:
            # We gaan ervan uit dat elke 'worker' een .process(df) methode heeft.
            # De test die we hebben geschreven, valideert deze aanname.
            enriched_df = worker.process(enriched_df)

        return enriched_df

--- END FILE: backend/assembly/context_builder.py ---

--- START FILE: backend/assembly/dependency_validator.py ---
# backend/assembly/dependency_validator.py
"""
Contains the DependencyValidator, responsible for ensuring the integrity
of a context pipeline before execution.

@layer: Backend (Assembly)
@dependencies: [.plugin_registry]
@responsibilities:
    - Validates that the data dependencies of each plugin in a sequence are met
      by the outputs of the preceding plugins.
"""
from typing import List
from backend.assembly.plugin_registry import PluginRegistry

class DependencyValidator:
    """Validates the dataflow integrity of a context worker pipeline."""

    def __init__(self, plugin_registry: PluginRegistry):
        """Initializes the DependencyValidator.

        Args:
            plugin_registry (PluginRegistry): The registry to fetch manifests from.
        """
        self._registry = plugin_registry

    def validate(self, context_pipeline: List[str]) -> bool:
        """
        Validates a sequential pipeline of context workers.

        It checks if the `dependencies` of each worker are satisfied by the
        initial `DataFrame` columns or the `provides` of the workers that
        run before it.

        Args:
            context_pipeline (List[str]): An ordered list of context worker names.

        Returns:
            True if the pipeline is valid.

        Raises:
            ValueError: If a dependency is not met, with a descriptive error.
        """
        # Start met de basiskolommen die altijd aanwezig zijn in de ruwe DataFrame.
        available_columns = {"open", "high", "low", "close", "volume"}

        for plugin_name in context_pipeline:
            plugin_data = self._registry.get_plugin_data(plugin_name)
            if not plugin_data:
                raise ValueError(f"Plugin '{plugin_name}' not found in registry.")

            manifest, _ = plugin_data

            # Controleer de dependencies van de huidige plugin.
            if manifest.dependencies:
                for dep in manifest.dependencies:
                    if dep not in available_columns:
                        raise ValueError(
                            f"Dependency '{dep}' for plugin '{plugin_name}' not met. "
                            f"Available columns: {sorted(list(available_columns))}"
                        )

            # Voeg de output van deze plugin toe aan de set van beschikbare kolommen.
            if manifest.provides:
                available_columns.update(manifest.provides)

        return True

--- END FILE: backend/assembly/dependency_validator.py ---

--- START FILE: backend/assembly/engine_builder.py ---
# backend/assembly/engine_builder.py
"""
Contains the EngineBuilder, a specialist for assembling a StrategyEngine.
"""
from typing import Any, Dict, List

from backend.assembly.worker_builder import WorkerBuilder
from backend.config.schemas.run_schema import RunBlueprint, WorkerDefinition
from backend.core.enums import PipelinePhase
from backend.core.strategy_engine import StrategyEngine
from backend.core.interfaces.worker import ContextWorker

class EngineBuilder:
    """Assembles a StrategyEngine with all its required workers."""

    def __init__(self, worker_builder: WorkerBuilder):
        self._worker_builder = worker_builder

    def build_context_pipeline(
        self, run_conf: RunBlueprint
    ) -> List[ContextWorker]:
        """Builds the initial pipeline of context workers."""
        context_plugin_names: List[str] = run_conf.taskboard.root.get(
            PipelinePhase.STRUCTURAL_CONTEXT, []
        )

        built_workers = [
            self._worker_builder.build(
                name=name,
                user_params=run_conf.workforce.get(name, WorkerDefinition()).params
            ) for name in context_plugin_names if name
        ]
        # Filter out any workers that failed to build
        return [worker for worker in built_workers if worker is not None]

    def build_engine(self, run_conf: RunBlueprint) -> StrategyEngine:
        """Builds and returns a configured StrategyEngine."""
        active_workers: Dict[str, Any] = {}
        for phase, plugin_names in run_conf.taskboard.root.items():
            if phase != PipelinePhase.STRUCTURAL_CONTEXT:
                worker_list = [
                    self._worker_builder.build(
                        name=name,
                        user_params=run_conf.workforce.get(name, WorkerDefinition()).params
                    ) for name in plugin_names if name
                ]
                active_workers[phase.value] = [w for w in worker_list if w is not None]

        return StrategyEngine(active_workers=active_workers)

--- END FILE: backend/assembly/engine_builder.py ---

--- START FILE: backend/assembly/plugin_registry.py ---
# backend/assembly/plugin_registry.py
"""
Contains the PluginRegistry, responsible for discovering, validating, and indexing
all available plugins within the ecosystem.

@layer: Backend (Assembly)
@dependencies: [Pydantic, PyYAML, backend.config.schemas]
@responsibilities:
    - Scans plugin directories for manifests.
    - Validates manifest schemas against the PluginManifest contract.
    - Builds and maintains the central in-memory plugin registry.
"""

from pathlib import Path
from typing import Dict, Optional, Tuple

import yaml

from pydantic import ValidationError
from backend.config.schemas.platform_schema import PlatformConfig
from backend.config.schemas.plugin_manifest_schema import PluginManifest
from backend.utils.app_logger import LogEnricher

class PluginRegistry:
    """
    Discovers all valid plugins and holds their manifest data in an
    in-memory dictionary for fast retrieval by other components.
    """

    def __init__(self, platform_config: PlatformConfig, logger: LogEnricher):
        """
        Initializes the registry by scanning and validating all plugins.

        Args:
            platform_config (PlatformConfig): The validated platform configuration object.
            logger (LogEnricher): The logger instance.
        """
        self._logger = logger
        self._plugins_root_path = Path(platform_config.plugins_root_path)
        self._registry: Dict[str, Tuple[PluginManifest, Path]] = {}

        self._scan_and_register_plugins()

    def _scan_and_register_plugins(self):
        """
        Scans the plugin directory, validates each manifest, and populates the registry.
        """
        self._logger.info(f"Scanning for plugins in '{self._plugins_root_path}'...")

        if not self._plugins_root_path.is_dir():
            self._logger.error(f"Plugin root path '{self._plugins_root_path}' not found.")
            return

        for manifest_path in self._plugins_root_path.rglob("plugin_manifest.yaml"):
            try:
                with open(manifest_path, 'r', encoding='utf-8') as f:
                    manifest_data = yaml.safe_load(f)

                # Valideer de data tegen ons Pydantic-contract
                manifest = PluginManifest(**manifest_data)

                # Controleer op dubbele namen
                if manifest.name in self._registry:
                    self._logger.warning(
                        f"Duplicate plugin name '{manifest.name}' found at '{manifest_path}'. "
                        "Skipping."
                    )
                    continue

                # Voeg de gevalideerde manifest toe aan de registry
                plugin_directory = manifest_path.parent
                self._registry[manifest.name] = (manifest, plugin_directory)

            except yaml.YAMLError as e:
                self._logger.warning(f"Could not parse manifest at '{manifest_path}': {e}")
            except ValidationError as e:
                self._logger.warning(f"Invalid manifest at '{manifest_path}':\n{e}")

        self._logger.info(
            f"Scan complete. Found and registered {len(self._registry)} valid plugins."
        )

    def get_plugin_data(self, plugin_name: str) -> Optional[Tuple[PluginManifest, Path]]:
        """
        Retrieves the validated manifest for a single plugin by its unique name.

        Args:
            plugin_name (str): The unique name of the plugin.

        Returns:
            Optional[PluginManifest]: The Pydantic model of the manifest, or None if not found.
        """
        return self._registry.get(plugin_name)

    def get_all_manifests(self) -> Dict[str, PluginManifest]:
        """
        Returns the entire registry of validated plugin manifests.

        Returns:
            Dict[str, PluginManifest]: A dictionary of all registered plugins.
        """
        return {name: data[0] for name, data in self._registry.items()}

--- END FILE: backend/assembly/plugin_registry.py ---

--- START FILE: backend/assembly/worker_builder.py ---
# backend/assembly/worker_builder.py
"""
Contains the WorkerBuilder, responsible for instantiating a single plugin worker
based on its manifest and user-provided configuration.

@layer: Backend (Assembly)
@dependencies:
    - .plugin_registry: To get the manifest (the "blueprint") for a worker.
    - backend.utils.dynamic_loader: To dynamically import plugin code.
    - backend.utils.app_logger: To create and inject a specific logger for the worker.
@responsibilities:
    - Dynamically loads a worker's code and its Pydantic schema.
    - Validates user-provided parameters against the plugin's schema.
    - Injects dependencies (like a logger) into the worker instance.
    - Returns a fully instantiated and validated worker object.
"""
from typing import Any, Dict, Optional, cast

from pydantic import ValidationError

from backend.assembly.plugin_registry import PluginRegistry
from backend.utils.dynamic_loader import load_class_from_module
from backend.utils.app_logger import LogEnricher


class WorkerBuilder:
    """Constructs a single, validated plugin worker instance."""

    def __init__(self, plugin_registry: PluginRegistry, logger: LogEnricher):
        """Initializes the WorkerBuilder.

        Args:
            plugin_registry (PluginRegistry): The registry containing all discovered plugins.
            logger (LogEnricher): The main logger, used to create child loggers.
        """
        self._registry = plugin_registry
        self._logger = logger

    def build(self, name: str, user_params: Dict[str, Any]) -> Optional[Any]:
        """Builds, validates, and instantiates a single worker.

        This method orchestrates the entire lifecycle of creating a worker, from
        finding its definition to validating user input and injecting dependencies.

        Args:
            name (str): The unique name of the worker to build.
            user_params (Dict[str, Any]): The parameter dictionary from the
                                           run_blueprint's 'workforce' section.

        Returns:
            An instantiated and validated worker object if successful, otherwise None.
        """
        # 1. Vraag Manifest en Pad op
        plugin_data = self._registry.get_plugin_data(name)
        if not plugin_data:
            self._logger.error(f"Cannot build worker: plugin '{name}' not found in registry.")
            return None

        manifest, plugin_path = plugin_data

        try:
            # Converteer het file path (bv. "plugins\\signal_generators\\fvg")
            # naar een Python module path (bv. "plugins.signal_generators.fvg")
            plugin_module_path = ".".join(plugin_path.parts)

            # 2. Dynamisch Laden met expliciete paden
            schema_module_path = f"{plugin_module_path}.{manifest.schema_path.replace('.py', '')}"
            worker_module_path = f"{plugin_module_path}.worker"

            schema_class = load_class_from_module(schema_module_path, manifest.params_class)
            worker_class = load_class_from_module(worker_module_path, manifest.entry_class)

            # 3. Valideer Parameters
            validated_params = schema_class(**user_params)

            # 4. Creëer & Injecteer Logger
            # Haal de onderliggende standaard logger op om een child te maken.
            indent_val = self._logger.extra.get('indent', 0) if self._logger.extra else 0
            current_indent = cast(int, indent_val)
            child_logger = self._logger.logger.getChild(name)
            worker_logger = LogEnricher(
                child_logger,
                indent=current_indent + 1
            )

            # 5. Instantieer de Worker
            worker_instance = worker_class(
                name=name,
                params=validated_params,
                logger=worker_logger
            )

            self._logger.info(f"Successfully built worker '{name}'.")
            return worker_instance

        except (ImportError, AttributeError) as e:
            self._logger.error(
                f"Failed to load code for worker '{name}': {e}"
            )
        except ValidationError as e:
            self._logger.error(
                f"Invalid parameters for worker '{name}':\n{e}"
            )

        return None

--- END FILE: backend/assembly/worker_builder.py ---

--- START FILE: backend/assembly/__init__.py ---
# backend/assembly/__init__.py
"""
Exposes the public API of the Assembly sub-package.
"""
__all__ = [
    "ContextBuilder",
    "DependencyValidator",
    "PluginRegistry",
    "WorkerBuilder",
]

from .context_builder import ContextBuilder
from .dependency_validator import DependencyValidator
from .plugin_registry import PluginRegistry
from .worker_builder import WorkerBuilder

--- END FILE: backend/assembly/__init__.py ---

--- START FILE: backend/config/__init__.py ---

--- END FILE: backend/config/__init__.py ---

--- START FILE: backend/config/schemas/app_schema.py ---
# backend/config/schemas/app_schema.py
"""
Contains the final, composed Pydantic model for a complete application run.

@layer: Backend (Config)
@dependencies: [Pydantic, .platform_schema, .run_schema]
@responsibilities:
    - Composes platform-level and run-level configurations into a single,
      unified, and immutable AppConfig object.
"""
from pydantic import BaseModel
from .platform_schema import PlatformConfig
from .run_schema import RunBlueprint

class AppConfig(BaseModel):
    """
    The final, composed configuration object for a run. It explicitly
    combines platform-wide settings (PlatformConfig) with the blueprint for a
    specific run (RunBlueprint), creating a single source of truth.
    """
    platform: PlatformConfig
    run: RunBlueprint

--- END FILE: backend/config/schemas/app_schema.py ---

--- START FILE: backend/config/schemas/platform_schema.py ---
# backend/config/schemas/platform_schema.py
"""
Contains Pydantic models that define the structure of the platform.yaml file.
This is the foundational contract for the entire application's configuration.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the schema for global, platform-wide settings.
"""

# --- Sub-models ---

from typing import Dict, List, Literal
from pydantic import BaseModel, Field
from backend.core.enums import LogLevel

class PlatformDataConfig(BaseModel):
    """Defines the structure for the 'data' section."""
    source_dir: str = "source_data"

class PortfolioConfig(BaseModel):
    """Defines the structure for the 'portfolio' section."""
    initial_capital: float = 10000.0
    fees_pct: float = 0.001

class LoggingConfig(BaseModel):
    """Defines the structure for the 'logging' section."""
    profile: Literal['developer', 'analysis'] = 'analysis'
    profiles: Dict[str, List[LogLevel]] # Gebruikt de LogLevel Enum

# --- Main model ---

class PlatformConfig(BaseModel):
    """
    The main Pydantic model that validates the entire platform.yaml file.
    It defines only the highest-level, essential configurations.
    """
    language: Literal['en', 'nl'] = 'nl'
    plugins_root_path: str = "plugins" # De enige verantwoordelijkheid t.o.v. plugins

    data: PlatformDataConfig = Field(default_factory=PlatformDataConfig)
    portfolio: PortfolioConfig = Field(default_factory=PortfolioConfig)

--- END FILE: backend/config/schemas/platform_schema.py ---

--- START FILE: backend/config/schemas/plugin_manifest_schema.py ---
# backend/config/schemas/plugin_manifest_schema.py
"""
Contains the Pydantic model that defines the structure of a plugin_manifest.yaml file.
This schema acts as the contract for what makes a plugin discoverable and valid.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the validated structure for a plugin's metadata.
    - Enforces the presence of critical fields for the PluginRegistry.
"""

from typing import List, Optional
from pydantic import BaseModel, Field
from backend.core.enums import PipelinePhase

class PluginManifest(BaseModel):
    """
    Validates the structure and content of a plugin's manifest.yaml file.
    This is the "ID card" of any plugin in the S1mpleTrader V2 ecosystem.
    """
    # === Core Identity (Verplicht) ===
    name: str
    version: str
    description: str
    type: PipelinePhase

    # === Code Contract (Verplicht) ===
    entry_class: str
    schema_path: str
    params_class: str

    # === Optionele Features ===
    # Data-contract: welke kolommen verwacht de plugin in de DataFrame?
    dependencies: Optional[List[str]] = None

    # Visualisatie-contract: welke Pydantic-klasse definieert de context en het render-recept?
    context_schema_class: Optional[str] = None

    provides: List[str] = Field(default_factory=list)

--- END FILE: backend/config/schemas/plugin_manifest_schema.py ---

--- START FILE: backend/config/schemas/run_schema.py ---
# backend/config/schemas/run_schema.py
"""
Contains Pydantic models that define the structure of a run_schema.yaml file.
This schema defines how a user composes a strategy from available plugins.

@layer: Backend (Config)
@dependencies: [Pydantic]
@responsibilities:
    - Defines the schema for a single strategy configuration.
    - Validates the assignment of plugins to taskboard phases.
    - Validates the parameter definitions for the used plugins.
"""

from typing import List, Dict, Any
from pydantic import BaseModel, Field, RootModel
from backend.core.enums import PipelinePhase

class RunDataConfig(BaseModel):
    """Defines the data settings specific to this run."""
    trading_pair: str
    timeframe: str

class TaskboardConfig(RootModel[Dict[PipelinePhase, List[str]]]):
    """
    Defines which plugins are assigned to each phase.
    This is a flexible dictionary where keys must be valid PipelinePhase members.
    By inheriting from RootModel, this class instance acts directly as a dictionary.
    """

class WorkerDefinition(BaseModel):
    """
    Defines the user-provided parameters for a single plugin.
    The system will validate this 'params' dict against the plugin's own schema.py.
    """
    params: Dict[str, Any] = Field(default_factory=dict)

class RunBlueprint(BaseModel):
    """
    The main Pydantic model that validates a complete run_blueprint.yaml file.
    """
    data: RunDataConfig
    taskboard: TaskboardConfig
    workforce: Dict[str, WorkerDefinition] = Field(default_factory=dict)

--- END FILE: backend/config/schemas/run_schema.py ---

--- START FILE: backend/config/schemas/__init__.py ---

--- END FILE: backend/config/schemas/__init__.py ---

--- START FILE: backend/core/base_worker.py ---
# backend/core/base_worker.py
"""
Contains optional, concrete base classes for Strategy Workers to simplify
plugin development by automating DTO nesting and providing direct access
to key identifiers like the correlation_id.

@layer: Backend (Core)
@dependencies: [abc, typing, uuid]
@responsibilities:
    - Provide a generic BaseStrategyWorker that handles DTO nesting.
    - Provide specific, inheritable base classes for each worker category
      to minimize boilerplate code in plugins.
    - Automate the propagation of the correlation_id.
"""
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import TYPE_CHECKING, Any, List, Dict, Generic, Optional, TypeVar
from uuid import UUID

if TYPE_CHECKING:
    from backend.dtos import (
        EntrySignal,
        RiskDefinedSignal,
        RoutedTradePlan,
        Signal,
        TradePlan,
        TradingContext,
        CriticalEvent,
    )


# --- Generieke Type Variabelen (volgens PEP 484 conventie) ---
InputDTO_T = TypeVar("InputDTO_T")  # pylint: disable=invalid-name
OutputDTO_T = TypeVar("OutputDTO_T")  # pylint: disable=invalid-name


class BaseStrategyWorker(ABC, Generic[InputDTO_T, OutputDTO_T]):
    """
    A generic base class that automates DTO creation and `correlation_id` handling.

    This class should typically not be inherited from directly. Use the
    specific, category-based classes below (e.g., BaseEntryPlanner) instead,
    as they pre-configure the DTO types and field names, resulting in
    minimal boilerplate for the plugin developer.
    """

    def __init__(self, params: Any):
        self.params = params

    def proces(
        self, input_dto: InputDTO_T, context: "TradingContext"
    ) -> Optional[OutputDTO_T]:
        """
        Public method called by the StrategyEngine. It extracts the correlation_id,
        calls the plugin's specific logic, and wraps the result in the
        correct output DTO.
        """
        # Haal de gepromote correlation_id direct van de input DTO
        correlation_id = getattr(input_dto, "correlation_id", None)
        if not isinstance(correlation_id, UUID):
            return None  # Veiligheid: stop als er geen ID is in de keten

        # Roep de kernlogica van de plugin aan
        new_data = self._process_internal(input_dto, correlation_id, context)

        if new_data is None:
            return None

        output_dto_class = self._get_output_dto_class()
        source_field_name = self._get_source_field_name()

        # Bouw de argumenten voor de constructor van de nieuwe DTO
        constructor_args: Dict[str, Any] = {
            "correlation_id": correlation_id,
            source_field_name: input_dto,
            **new_data,
        }

        return output_dto_class(**constructor_args)

    @abstractmethod
    def _process_internal(
        self,
        input_dto: InputDTO_T,
        correlation_id: UUID,
        context: "TradingContext",
    ) -> Optional[Dict[str, Any]]:
        """
        Plugin-specific logic must be implemented here by the developer.

        Args:
            input_dto: The DTO from the previous pipeline stage.
            correlation_id: The unique ID of the signal chain, provided for convenience.
            context: The full trading context.

        Returns:
            A dictionary with the new fields for the output DTO,
            or None if no output should be generated.
        """
        raise NotImplementedError

    @abstractmethod
    def _get_output_dto_class(self) -> type[OutputDTO_T]:
        """Must specify the output DTO type."""
        raise NotImplementedError

    @abstractmethod
    def _get_source_field_name(self) -> str:
        """Must specify the field name for the nested source DTO."""
        raise NotImplementedError


# --- Categorie-Specifieke Basisklassen ---

class BaseSignalGenerator(ABC):
    """Base class for SignalGenerator plugins (Fase 3)."""
    def __init__(self, params: Any):
        self.params = params

    @abstractmethod
    def process(self, context: "TradingContext") -> List["Signal"]:
        """
        Generates a list of raw Signal DTOs based on the market context.

        Args:
            context: The full trading context, including the enriched DataFrame.

        Returns:
            A list of Signal DTOs, or an empty list if no opportunities are found.
        """
        raise NotImplementedError

class BaseSignalRefiner(BaseStrategyWorker["Signal", "Signal"]):
    """Base class for SignalRefiner plugins (Fase 4)."""

    def execute(
        self, input_dto: "Signal", context: "TradingContext"
    ) -> Optional["Signal"]:
        """
        Overrides the base execute method for the specific case of a refiner,
        which acts as a filter (1-to-1 or 1-to-0).
        """
        is_valid = self._process(input_dto, input_dto.correlation_id, context)
        return input_dto if is_valid else None

    @abstractmethod
    def _process(  # type: ignore
        self,
        input_dto: "Signal",
        correlation_id: UUID,
        context: "TradingContext",
    ) -> bool:
        """Return True to keep the signal, False to discard it."""
        raise NotImplementedError


class BaseEntryPlanner(BaseStrategyWorker["Signal", "EntrySignal"]):
    """Base class for EntryPlanner plugins (Fase 5)."""

    def _get_output_dto_class(self) -> type["EntrySignal"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import EntrySignal

        return EntrySignal

    def _get_source_field_name(self) -> str:
        return "signal"


class BaseExitPlanner(BaseStrategyWorker["EntrySignal", "RiskDefinedSignal"]):
    """Base class for ExitPlanner plugins (Fase 6)."""

    def _get_output_dto_class(self) -> type["RiskDefinedSignal"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import RiskDefinedSignal

        return RiskDefinedSignal

    def _get_source_field_name(self) -> str:
        return "entry_signal"


class BaseSizePlanner(BaseStrategyWorker["RiskDefinedSignal", "TradePlan"]):
    """Base class for SizePlanner plugins (Fase 7)."""

    def _get_output_dto_class(self) -> type["TradePlan"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import TradePlan

        return TradePlan

    def _get_source_field_name(self) -> str:
        return "risk_defined_signal"


class BaseOrderRouter(BaseStrategyWorker["TradePlan", "RoutedTradePlan"]):
    """Base class for OrderRouter plugins (Fase 8)."""

    def _get_output_dto_class(self) -> type["RoutedTradePlan"]:
        # pylint: disable=import-outside-toplevel
        from backend.dtos import RoutedTradePlan

        return RoutedTradePlan

    def _get_source_field_name(self) -> str:
        return "trade_plan"

class BaseCriticalEventDetector(ABC):
    """Base class for CriticalEventDetector plugins (Fase 9)."""
    def __init__(self, params: Any):
        self.params = params

    @abstractmethod
    def process(
        self, routed_trade_plans: List["RoutedTradePlan"], context: "TradingContext"
    ) -> List["CriticalEvent"]:
        """
        Detects and returns a list of critical events based on the final context.

        Args:
            routed_trade_plans: The list of proposed trades for the current cycle.
            context: The full trading context.

        Returns:
            A list of CriticalEvent DTOs, or an empty list if no events are detected.
        """
        raise NotImplementedError

--- END FILE: backend/core/base_worker.py ---

--- START FILE: backend/core/constants.py ---
# backend/core/constants.py
"""
Application-wide constants
"""

--- END FILE: backend/core/constants.py ---

--- START FILE: backend/core/context_recorder.py ---
# backend/core/context_recorder.py
"""
Contains the ContextRecorder, a class that acts as a central in-memory database
for storing contextual data produced by various strategy components during a run.

@layer: Backend (Core)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Provides a single, unified interface for plugins to log contextual data.
    - Stores data in a structured way, indexed by timestamp and plugin name.
    - Serializes Pydantic models into JSON-compatible dictionaries for storage.
"""
import uuid
from typing import Any, Dict
import pandas as pd
from pydantic import BaseModel

class ContextRecorder:
    """A central, in-memory database for recording contextual data from specialists."""

    def __init__(self):
        """Initializes the ContextRecorder with an empty data log."""
        self._data_log: Dict[pd.Timestamp, Dict[str, Any]] = {}

    def add_data(
        self,
        correlation_id: uuid.UUID,
        timestamp: pd.Timestamp,
        specialist_name: str,
        context_object: BaseModel
    ):
        """
        Records a Pydantic context object from a specialist at a specific timestamp.

        The object is immediately serialized to a JSON-compatible dictionary to ensure
        immutability and prevent downstream side effects.

        Args:
            correlation_id (uuid.UUID): The unique ID of the trade lifecycle.
            timestamp (pd.Timestamp): The timestamp of the event to log.
            specialist_name (str): The name of the component logging the data.
            context_object (BaseModel): The Pydantic model with the context data.
        """
        if timestamp not in self._data_log:
            self._data_log[timestamp] = {}

        # Gebruik model_dump() om direct een dictionary te krijgen
        serializable_context = context_object.model_dump()

        # We voegen de correlation_id toe aan de gelogde data voor traceability
        serializable_context['correlation_id'] = str(correlation_id)

        self._data_log[timestamp][specialist_name] = serializable_context

    def get_all_data(self) -> Dict[pd.Timestamp, Dict[str, Any]]:
        """
        Returns the complete, raw data log.

        Returns:
            The nested dictionary containing all recorded context data.
        """
        return self._data_log

--- END FILE: backend/core/context_recorder.py ---

--- START FILE: backend/core/directive_flattener.py ---
# backend/core/directive_flattener.py
"""
Contains a utility class to flatten a deeply nested RoutedTradePlan DTO
into a simple, flat ExecutionDirective.

@layer: Backend (Core)
@dependencies: [backend.dtos, pydantic]
@responsibilities:
    - Decouples the StrategyEngine's complex data structure from the simple
      contract required by the ExecutionHandler.
    - Dynamically unnests DTOs to create a flat data structure.
"""
from typing import Any, Dict, cast
from backend.dtos.routed_trade_plan import RoutedTradePlan
from backend.dtos.execution_directive import ExecutionDirective

class DirectiveFlattener:
    """
    A utility responsible for dynamically flattening the nested trade plan
    structure into a final, flat execution directive.
    """

    def _flatten_recursively(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Recursively unnests Pydantic models within a dictionary.
        """
        flat_dict: Dict[str, Any] = {}
        for key, value in data.items():
            # --- DE FIX: Controleer op 'dict' in plaats van 'BaseModel' ---
            if isinstance(value, dict):
                # We willen de geneste container-keys (zoals 'signal', 'trade_plan') niet meenemen.
                # We pakken alleen de inhoud ervan uit.
                flat_dict.update(self._flatten_recursively(cast(Dict[str, Any], value)))
            else:
                flat_dict[key] = value
        return flat_dict

    def flatten(self, routed_trade_plan: RoutedTradePlan) -> ExecutionDirective:
        """
        Transforms a deeply nested RoutedTradePlan into a flat ExecutionDirective
        using a dynamic, recursive approach.

        Args:
            routed_trade_plan (RoutedTradePlan): The complete, nested output
                                                 from the OrderRouter (Fase 8).

        Returns:
            ExecutionDirective: A flat DTO containing all necessary data for execution.
        """
        # 1. Converteer het toplevel DTO naar een dictionary.
        nested_dict = routed_trade_plan.model_dump()

        # 2. Roep de recursieve functie aan om de dictionary plat te slaan.
        flat_data = self._flatten_recursively(nested_dict)

        # 3. Rename 'timestamp' from Signal to 'entry_time' for the directive
        if 'timestamp' in flat_data:
            flat_data['entry_time'] = flat_data.pop('timestamp')

        # 4. Creëer de uiteindelijke, platte DTO. Pydantic negeert
        #    automatisch alle overbodige velden (zoals de geneste objecten zelf).
        return ExecutionDirective(**flat_data)

--- END FILE: backend/core/directive_flattener.py ---

--- START FILE: backend/core/enums.py ---
# backend/core/enums.py
"""
Contains application-wide enumerations to provide type-safety and a single
source of truth for specific sets of values.

@layer: Core
"""
from enum import Enum

class LogLevel(str, Enum):
    """Defines all valid logging levels, including custom ones."""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"
    SETUP = "SETUP"
    MATCH = "MATCH"
    FILTER = "FILTER"
    POLICY = "POLICY"
    RESULT = "RESULT"
    TRADE = "TRADE"

class PipelinePhase(str, Enum):
    """Defines the valid phases of the 6-phase strategy funnel."""
    REGIME_FILTER = "regime_filter"
    STRUCTURAL_CONTEXT = "structural_context"
    SIGNAL_GENERATOR = "signal_generator"
    SIGNAL_REFINER = "signal_refiner"
    ENTRY_PLANNER = "entry_planner"
    EXIT_PLANNER = "exit_planner"
    SIZE_PLANNER = "size_planner"
    ORDER_ROUTER = "order_router"
    CRITICAL_EVENT_DETECTOR = "critical_event_detector"

--- END FILE: backend/core/enums.py ---

--- START FILE: backend/core/execution.py ---
"""Contains the concrete implementation of an execution handler for backtests.

This module provides the `BacktestExecutionHandler`, which is a concrete
implementation of the `ExecutionHandler` interface. It is responsible for
simulating the execution of trading directives within a backtesting environment.

@layer: Backend (Core)
@dependencies: [backend.core.interfaces, backend.dtos, backend.utils]
@responsibilities:
    - Implement the `ExecutionHandler` interface for simulated backtests.
    - Receive `ExecutionDirective` objects and translate them into trade actions.
    - Interact with a `Tradable` component (e.g., Portfolio) to open trades.
    - Log all execution activities.
"""
from typing import List

# --- CORRECTIE: Importeer de GECENTRALISEERDE interface ---
from backend.core.interfaces.execution import ExecutionHandler
from backend.core.interfaces.portfolio import Tradable
from backend.dtos import ExecutionDirective
from backend.utils.app_logger import LogEnricher

class BacktestExecutionHandler(ExecutionHandler):
    """
    Handles the execution of directives within a simulated backtest environment.
    """
    def __init__(self, tradable: Tradable, logger: LogEnricher):
        self._tradable = tradable
        self._logger = logger

    def execute_plan(self, directives: List[ExecutionDirective]):
        """
        Processes a list of execution directives by calling the appropriate
        methods on the tradable entity (Portfolio).
        """
        for directive in directives:
            # Hier kun je in de toekomst logica toevoegen voor verschillende directive types
            # De huidige implementatie geeft de directive direct door.
            self._tradable.open_trade(directive)

--- END FILE: backend/core/execution.py ---

--- START FILE: backend/core/performance_analyzer.py ---
# backend/core/performance_analyzer.py
"""
Docstring for performance_analyzer.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class PerformanceAnalyzer:
    """Docstring for PerformanceAnalyzer."""
    pass

--- END FILE: backend/core/performance_analyzer.py ---

--- START FILE: backend/core/portfolio.py ---
# backend/core/portfolio.py
"""
Contains the Portfolio class, which manages the financial state of a backtest.

@layer: Backend
@dependencies:
    - backend.core.interfaces.portfolio: Implements the Tradable protocol.
    - backend.dtos: Uses ExecutionDirective and ClosedTrade DTOs.
@responsibilities:
    - Manages the account balance based on a starting capital.
    - Executes fully-formed ExecutionDirective objects without strategic validation.
    - Holds the state for multiple active trades.
    - Maintains a list of all closed trades as ClosedTrade DTOs.
@inputs:
    - `initial_capital` (float) and `fees_pct` (float) on initialization.
    - `ExecutionDirective` DTOs to be executed.
@outputs:
    - A list of `ClosedTrade` DTOs.
"""
from typing import Any, Dict, List
from uuid import UUID
import pandas as pd

from backend.core.interfaces.portfolio import Tradable
from backend.dtos.execution_directive import ExecutionDirective
from backend.dtos.closed_trade import ClosedTrade
from backend.utils.app_logger import LogEnricher
from backend.core.context_recorder import ContextRecorder


class Portfolio(Tradable):
    """
    Manages account capital, active trades, and a list of closed trades.

    This class acts as a stateful ledger. Its primary responsibility is to
    maintain the financial state of the simulation by executing pre-calculated
    ExecutionDirective objects and updating the balance. It is a concrete implementation
    of the Tradable protocol, capable of managing multiple concurrent trades.
    """

    def __init__(self,
                 initial_capital: float,
                 fees_pct: float,
                 logger: LogEnricher,
                 context_recorder: ContextRecorder):
        """
        Initializes the Portfolio.
        """
        self._initial_capital: float = initial_capital
        self._balance: float = initial_capital
        self._fees_pct: float = fees_pct
        self.logger = logger
        self.context_recorder = context_recorder

        self._closed_trades: List[ClosedTrade] = []
        self._active_trades: Dict[UUID, Dict[str, Any]] = {}

    @property
    def initial_capital(self) -> float:
        """Returns the starting capital of the portfolio."""
        return self._initial_capital

    @property
    def balance(self) -> float:
        """Returns the current account balance."""
        return self._balance

    @property
    def closed_trades(self) -> List[ClosedTrade]:
        """Returns the list of all closed trades."""
        return self._closed_trades

    @property
    def active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """A dictionary of all currently open trades, keyed by correlation_id."""
        return self._active_trades

    @property
    def active_trade_count(self) -> int:
        """Returns the number of active trades."""
        return len(self._active_trades)

    def get_active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """Returns the dictionary of active trades."""
        return self.active_trades

    def open_trade(self, execution_directive: ExecutionDirective):
        """
        Opens a new trade based on a pre-calculated ExecutionDirective object.
        """
        for trade in self._active_trades.values():
            if trade['asset'] == execution_directive.asset:
                self.logger.error(
                    "Attempted to open a trade on an asset with an existing position.",
                    values={'asset': execution_directive.asset}
                )
                return

        if execution_directive.position_value_quote > self._balance:
            self.logger.error(
                "Insufficient capital to open trade.",
                values={'required': execution_directive.position_value_quote,
                        'available': self._balance}
            )
            return

        # Sla ALLE benodigde data op, inclusief correlation_id en signal_type
        self._active_trades[execution_directive.correlation_id] = {
            "correlation_id": execution_directive.correlation_id,
            "signal_type": execution_directive.signal_type,
            "entry_time": execution_directive.entry_time,
            "asset": execution_directive.asset,
            "direction": execution_directive.direction,
            "entry_price": execution_directive.entry_price,
            "sl_price": execution_directive.sl_price,
            "tp_price": execution_directive.tp_price,
            "position_size_asset": execution_directive.position_size_asset,
            "position_value_eur": execution_directive.position_value_quote,
        }

        self.logger.trade(
            'portfolio.open_trade',
            values={
                'direction': execution_directive.direction.upper(),
                'price': f"{execution_directive.entry_price:,.2f}",
                'sl': f"{execution_directive.sl_price:,.2f}",
                'tp': f"{execution_directive.tp_price:,.2f}"if execution_directive.tp_price else "N/A"
            }
        )

    def process_candle(self, candle: pd.Series):
        """
        Processes the latest market data candle to check for SL/TP hits
        for all active trades.
        """
        if not self._active_trades:
            return

        # FIX: Controleer of de index van de candle (candle.name) een geldig Timestamp-object is
        if not isinstance(candle.name, pd.Timestamp):
            # Log een waarschuwing of negeer de candle
            return

        exit_timestamp = candle.name # Nu weten we zeker dat het een Timestamp is

        trade_ids_to_check = list(self._active_trades.keys())

        for correlation_id in trade_ids_to_check:
            trade = self._active_trades.get(correlation_id)
            if not trade:
                continue

            exit_price = None

            # TODO: In a multi-asset scenario, the candle should contain the asset
            # it belongs to, to match against the trade's asset.

            if trade['direction'] == 'long':
                if candle['low'] <= trade['sl_price']:
                    exit_price = trade['sl_price']
                elif trade['tp_price'] and candle['high'] >= trade['tp_price']:
                    exit_price = trade['tp_price']

            elif trade['direction'] == 'short':
                if candle['high'] >= trade['sl_price']:
                    exit_price = trade['sl_price']
                elif trade['tp_price'] and candle['low'] <= trade['tp_price']:
                    exit_price = trade['tp_price']

            if exit_price:
                self._close_trade(correlation_id, exit_timestamp, exit_price)

    def _close_trade(self, correlation_id: UUID, exit_timestamp: pd.Timestamp, exit_price: float):
        """
        Closes an active trade, calculates PnL, updates the balance, and archives
        the transaction.
        """
        trade_to_close = self._active_trades.pop(correlation_id, None)
        if not trade_to_close:
            return

        price_delta = exit_price - trade_to_close['entry_price']
        if trade_to_close['direction'] == 'short':
            price_delta *= -1

        gross_pnl = price_delta * trade_to_close['position_size_asset']
        fees = trade_to_close['position_value_eur'] * self._fees_pct * 2
        net_pnl = gross_pnl - fees

        self._balance += net_pnl

        # FIX: Voeg de ontbrekende correlation_id en signal_type velden toe
        closed_trade = ClosedTrade(
            correlation_id=trade_to_close['correlation_id'],
            signal_type=trade_to_close['signal_type'],
            entry_time=trade_to_close['entry_time'],
            exit_time=exit_timestamp,
            asset=trade_to_close['asset'],
            direction=trade_to_close['direction'],
            entry_price=trade_to_close['entry_price'],
            exit_price=exit_price,
            sl_price=trade_to_close['sl_price'],
            tp_price=trade_to_close['tp_price'],
            position_value_quote=trade_to_close['position_value_eur'],
            position_size_asset=trade_to_close['position_size_asset'],
            pnl_quote=net_pnl,
        )
        self._closed_trades.append(closed_trade)

        self.logger.trade(
            'portfolio.close_trade',
            values={
                'direction': closed_trade.direction.upper(),
                'price': f"{closed_trade.exit_price:,.2f}",
                'pnl': f"{closed_trade.pnl_quote:,.2f}",
                'result': "WIN" if closed_trade.pnl_quote > 0 else "LOSS"
            }
        )

--- END FILE: backend/core/portfolio.py ---

--- START FILE: backend/core/strategy_engine.py ---
# backend/core/strategy_engine.py
"""
Contains the StrategyEngine, the core component for executing the
signal-driven phases (3-9) of the trading strategy pipeline.

@layer: Backend (Core)
@dependencies:
    - backend.core.interfaces: For adhering to the Environment contract.
    - backend.dtos: For processing the DTO chain.
    - .directive_flattener: To flatten the final trade plan.
@responsibilities:
    - Orchestrates the event-driven loop, timed by the Environment's Clock.
    - Manages the DTO dataflow from Signal generation to final RoutedTradePlan.
    - Flattens approved plans into ExecutionDirectives.
    - Detects critical system-wide events.
    - Bundles all results into a final EngineCycleResult for each tick.
"""
from typing import Dict, List, Any, Generator

from backend.core.interfaces import (
    Clock, BaseStrategyEngine, SignalGenerator, SignalRefiner, EntryPlanner,
    ExitPlanner, SizePlanner, OrderRouter, CriticalEventDetector
)
from backend.dtos import (
    TradingContext, Signal, RoutedTradePlan, EngineCycleResult, CriticalEvent
)
from .directive_flattener import DirectiveFlattener


class StrategyEngine(BaseStrategyEngine):
    """
    The engine that orchestrates the signal-driven workflow (Fase 3-9).
    """

    def __init__(self, active_workers: Dict[str, Any]):
        """Initializes the StrategyEngine with a pre-built set of workers."""
        super().__init__(active_workers=active_workers)

        self._signal_generators: List[SignalGenerator] = active_workers.get('signal_generator', [])
        self._signal_refiners: List[SignalRefiner] = active_workers.get('signal_refiner', [])
        self._entry_planner: EntryPlanner | None = active_workers.get('entry_planner')
        self._exit_planner: ExitPlanner | None = active_workers.get('exit_planner')
        self._size_planner: SizePlanner | None = active_workers.get('size_planner')
        self._order_routers: List[OrderRouter] = active_workers.get('order_router', [])
        self._critical_event_detectors: List[CriticalEventDetector] = active_workers.get(
            'critical_event_detector', []
        )
        self._flattener = DirectiveFlattener()

    def run(self,
            trading_context: TradingContext,
            clock: Clock) -> Generator[EngineCycleResult, None, None]:
        """
        Starts the main event loop and yields a complete result for each cycle.
        """
        for _timestamp, _row in clock.tick():
            final_routed_plans: List[RoutedTradePlan] = []

            raw_signals: List[Signal] = []
            for generator in self._signal_generators:
                raw_signals.extend(generator.process(context=trading_context))

            for signal in raw_signals:
                routed_plan = self._process_single_signal(signal, trading_context)
                if routed_plan:
                    final_routed_plans.append(routed_plan)

            directives = [self._flattener.flatten(plan) for plan in final_routed_plans]

            events: List[CriticalEvent] = []
            for detector in self._critical_event_detectors:
                events.extend(detector.process(final_routed_plans, trading_context))

            yield EngineCycleResult(
                execution_directives=directives,
                critical_events=events
            )

    def _process_single_signal(
        self, signal: Signal, context: TradingContext
    ) -> RoutedTradePlan | None:
        """Leidt één enkel signaal door de trechter van Fase 4 tot 8."""

        approved_signal: Signal | None = signal
        for refiner in self._signal_refiners:
            if not (approved_signal := refiner.process(approved_signal, context)):
                return None

        if not self._entry_planner:
            return None
        if not (entry_signal := self._entry_planner.process(approved_signal, context)):
            return None

        if not self._exit_planner:
            return None
        if not (risk_defined_signal := self._exit_planner.process(entry_signal, context)):
            return None

        if not self._size_planner:
            return None
        if not (trade_plan := self._size_planner.process(risk_defined_signal, context)):
            return None

        final_routed_plan: RoutedTradePlan | None = None
        for router in self._order_routers:
            if final_routed_plan := router.process(trade_plan, context):
                break

        return final_routed_plan

--- END FILE: backend/core/strategy_engine.py ---

--- START FILE: backend/core/__init__.py ---
# backend/core/__init__.py
"""
Exposes the public API of the Core sub-package, making key components
available for other layers of the application, such as the Service layer
and test suites.

This centralization allows for cleaner imports, as consumers can import
directly from `backend.core` without needing to know the internal
file structure.

@layer: Backend (Core)
"""
__all__ = [
    "StrategyEngine",
    "Portfolio",
    "BaseStrategyWorker",
    "ContextRecorder",
    "BacktestExecutionHandler"
]

from .strategy_engine import StrategyEngine
from .portfolio import Portfolio
from .base_worker import BaseStrategyWorker
from .context_recorder import ContextRecorder
from .execution import BacktestExecutionHandler

--- END FILE: backend/core/__init__.py ---

--- START FILE: backend/core/interfaces/engine.py ---
# backend/core/interfaces/engine.py
"""
Contains the behavioral contracts (ABCs) for the core strategy execution engine.

@layer: Backend (Core Interfaces)
@dependencies: [abc, typing, backend.dtos]
@responsibilities:
    - Defines the abstract contract for any component that can execute the
      signal-driven portion of a strategy.
"""
from __future__ import annotations

from abc import ABC, abstractmethod
from typing import Any, Dict, Generator, TYPE_CHECKING

if TYPE_CHECKING:
    from backend.core.interfaces import Clock
    from backend.dtos import TradingContext, EngineCycleResult

class BaseStrategyEngine(ABC):
    """
    Abstract contract for a Strategy Engine.

    This interface defines the "motor" that drives the core trading logic.
    It is designed to be a pure, high-performance generator of TradePlans,
    completely decoupled from the environment in which it operates.
    """
    def __init__(self, active_workers: Dict[str, Any]):
        """Initializes the engine with its pre-built "toolbox" of workers."""
        ...

    @abstractmethod
    def run(self,
            trading_context: 'TradingContext',
            clock: 'Clock') -> Generator['EngineCycleResult', None, None]:
        """
        Starts the main event loop and yields approved TradePlans.

        Args:
            trading_context (TradingContext): The shared context object.
            clock (Clock): The clock that controls the flow of time.

        Yields:
            TradePlan: A fully validated and approved trade plan, ready for execution.
        """
        ...

--- END FILE: backend/core/interfaces/engine.py ---

--- START FILE: backend/core/interfaces/environment.py ---
# backend/core/interfaces/environment.py
"""
Contains the behavioral contracts (ABCs) for the Execution Environment
and its sub-components.

@layer: Backend (Core Interfaces)
@dependencies: [abc, typing, pandas, backend.dtos]
@responsibilities:
    - Defines the abstract contracts for the operational "world".
"""
from __future__ import annotations
from abc import ABC, abstractmethod
from typing import Generator, Tuple, TYPE_CHECKING
import pandas as pd

# --- CORRECTIE: Importeer de ExecutionHandler interface HIER ---
if TYPE_CHECKING:
    from backend.core.interfaces.execution import ExecutionHandler

class DataSource(ABC):
    """Abstract contract for any component that provides market data."""
    @abstractmethod
    def get_data(self) -> pd.DataFrame:
        """Returns the complete historical dataset for the environment."""
        ...

class Clock(ABC):
    """Abstract contract for any component that controls the flow of time."""
    @abstractmethod
    def tick(self) -> Generator[Tuple[pd.Timestamp, pd.Series], None, None]:
        """Yields the next moment in time (timestamp and data row)."""
        ...

class BaseEnvironment(ABC):
    """
    Abstract contract for an Execution Environment.
    This interface defines the "world" in which a strategy operates.
    """
    @property
    @abstractmethod
    def source(self) -> DataSource:
        """The data source for this environment."""
        ...

    @property
    @abstractmethod
    def clock(self) -> Clock:
        """The clock that controls time in this environment."""
        ...

    @property
    @abstractmethod
    def handler(self) -> "ExecutionHandler":
        """The execution handler for this environment."""
        ...

--- END FILE: backend/core/interfaces/environment.py ---

--- START FILE: backend/core/interfaces/execution.py ---
"""Defines the abstract contract for all execution handlers.

This module contains the `ExecutionHandler` Abstract Base Class (ABC), which
enforces a standard interface for any component that executes trading
directives.

@layer: Backend (Core Interfaces)
@dependencies: [abc, backend.dtos]
@responsibilities:
    - Define the `ExecutionHandler` abstract base class.
    - Specify the `execute_plan` method as the required contract for all execution environments.
"""
from abc import ABC, abstractmethod
from typing import List
from backend.dtos import ExecutionDirective

class ExecutionHandler(ABC):
    """
    Abstract Base Class that defines the contract for any component capable
    of executing trade directives.
    """

    @abstractmethod
    def execute_plan(self, directives: List[ExecutionDirective]) -> None:
        """
        Processes a list of execution directives.

        Args:
            directives (List[ExecutionDirective]): The directives to be executed.
        """
        raise NotImplementedError

--- END FILE: backend/core/interfaces/execution.py ---

--- START FILE: backend/core/interfaces/portfolio.py ---
# backend/core/interfaces/portfolio.py
"""
Contains the abstract contract (Protocol) for any component that can manage
and execute trades within the S1mpleTrader ecosystem.

@layer: Backend (Core Interfaces)
"""
from typing import Protocol, List, Dict, Any, runtime_checkable
from uuid import UUID
import pandas as pd

from backend.dtos.execution_directive import ExecutionDirective
from backend.dtos.closed_trade import ClosedTrade

@runtime_checkable
class Tradable(Protocol):
    """
    An interface for any object that can manage a financial state, open
    positions, and a history of closed trades. This contract ensures that
    high-level components like an ExecutionHandler can interact with any
    portfolio implementation in a consistent way.
    """

    @property
    def initial_capital(self) -> float:
        """The starting capital of the portfolio."""
        ...

    @property
    def balance(self) -> float:
        """The current, real-time balance of the portfolio."""
        ...

    @property
    def active_trades(self) -> Dict[UUID, Dict[str, Any]]:
        """A dictionary of all currently open trades."""
        ...

    @property
    def closed_trades(self) -> List[ClosedTrade]:
        """A list of all closed trades."""
        ...

    def open_trade(self, execution_directive: ExecutionDirective) -> None:
        """
        Receives a complete trade plan and processes it to open a new
        position, updating the internal state.
        """
        ...

    def process_candle(self, candle: pd.Series) -> None:
        """
        Processes the latest market data candle to check if any active
        trades should be closed based on their SL/TP levels.
        """
        ...

--- END FILE: backend/core/interfaces/portfolio.py ---

--- START FILE: backend/core/interfaces/worker.py ---
# backend/core/interfaces/worker.py
"""
Contains the behavioral contracts (Protocols) for all plugin worker types.

These interfaces are the "constitution" for the S1mpleTrader plugin
ecosystem, ensuring that any component created by a developer will correctly
integrate with the StrategyEngine.

@layer: Backend (Core Interfaces)
@dependencies: [typing, pandas, backend.dtos]
@responsibilities:
    - Defines the structural contracts for all types of plugin workers.
    - Enforces the logical data flow of the 9-fase strategy pipeline.
"""
from __future__ import annotations

from typing import (Any, List, Optional, Protocol, TYPE_CHECKING, runtime_checkable)
import pandas as pd

# Use TYPE_CHECKING to prevent circular imports at runtime
# while still providing type hints for static analysis.
if TYPE_CHECKING:
    from backend.dtos import (Signal, EntrySignal, RiskDefinedSignal,
                              TradePlan, RoutedTradePlan, CriticalEvent,
                              TradingContext)

# --- Base Contracts ---

@runtime_checkable
class BaseWorker(Protocol):
    """The base behavioral contract for any plugin worker."""

    def process(self, *args: Any, **kwargs: Any) -> Any:
        """The main entry point method for the worker's logic."""
        ...

@runtime_checkable
class ContextWorker(BaseWorker, Protocol):
    """
    A contract for a data enrichment worker (Fase 1 & 2).

    ContextWorkers are responsible for adding analytical data (e.g., indicators,
    market regime classifications) to the main DataFrame.
    """

    def process(self, df: pd.DataFrame, context: 'TradingContext') -> pd.DataFrame:
        ...

@runtime_checkable
class StrategyWorker(BaseWorker, Protocol):
    """A base contract for any worker operating within the main DTO pipeline."""
    ...

# --- Specific Strategy Worker Contracts (The Pipeline) ---

@runtime_checkable
class SignalGenerator(StrategyWorker, Protocol):
    """Fase 3: A contract for a worker that generates trading opportunities."""

    def process(self, context: 'TradingContext') -> List['Signal']:
        ...

@runtime_checkable
class SignalRefiner(StrategyWorker, Protocol):
    """Fase 4: A contract for a worker that filters raw signals."""

    def process(self, signal: 'Signal', context: 'TradingContext') -> Optional['Signal']:
        ...

@runtime_checkable
class EntryPlanner(StrategyWorker, Protocol):
    """Fase 5: A contract for a worker that defines the entry tactic."""

    def process(self, signal: 'Signal', context: 'TradingContext') -> Optional['EntrySignal']:
        ...

@runtime_checkable
class ExitPlanner(StrategyWorker, Protocol):
    """Fase 6: A contract for a worker that defines risk parameters (SL/TP)."""

    def process(self, entry_signal: 'EntrySignal',
                context: 'TradingContext') -> Optional['RiskDefinedSignal']:
        ...

@runtime_checkable
class SizePlanner(StrategyWorker, Protocol):
    """Fase 7: A contract for a worker that calculates position size."""

    def process(self, risk_defined_signal: 'RiskDefinedSignal',
                context: 'TradingContext') -> Optional['TradePlan']:
        ...

@runtime_checkable
class OrderRouter(StrategyWorker, Protocol):
    """Fase 8: A contract for a worker that translates a TradePlan into execution tactics."""

    def process(self, trade_plan: 'TradePlan',
                context: 'TradingContext') -> Optional['RoutedTradePlan']:
        ...

@runtime_checkable
class CriticalEventDetector(StrategyWorker, Protocol):
    """
    Fase 9: A contract for a worker that scans the final context to detect systemic events.
    """
    def process(self, routed_trade_plans: List['RoutedTradePlan'],
                context: 'TradingContext') -> List['CriticalEvent']:
        ...

--- END FILE: backend/core/interfaces/worker.py ---

--- START FILE: backend/core/interfaces/__init__.py ---
# backend/core/interfaces/__init__.py
"""Exposes all interface contracts from a single, clean namespace."""

from .worker import *
from .environment import *
from .engine import *
from .portfolio import *

--- END FILE: backend/core/interfaces/__init__.py ---

--- START FILE: backend/data/loader.py ---
# backend/data/loader.py
"""
Handles loading raw data from CSV files and performing initial cleaning.

@layer: Backend (Data)
@dependencies: [pathlib, pandas, backend.utils.app_logger]
@responsibilities:
    - Loads raw OHLCV data from a specific CSV file.
    - Performs initial data cleaning, sets the timestamp index, and handles NA values.
"""
from pathlib import Path
import pandas as pd
from backend.utils.app_logger import LogEnricher

class DataLoader:
    """Loads and performs initial preparation of OHLCV data from a CSV file."""

    def __init__(self, file_path: str, logger: LogEnricher):
        """Initializes the DataLoader."""
        self.file_path = Path(file_path)
        self.logger = logger
        if not self.file_path.is_file():
            raise FileNotFoundError(f"Data file not found at path: {self.file_path}")

    def load(self) -> pd.DataFrame:
        """Loads data from the CSV, sets the index, and cleans the data."""
        self.logger.info('loader.loading_from', values={'filename': self.file_path.name})

        df: pd.DataFrame = pd.read_csv(self.file_path) # pyright: ignore[reportUnknownMemberType]

        # Converteer timestamp naar datetime objecten, stel in als index en sorteer.
        df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True, errors='coerce')
        df = df.set_index('timestamp').sort_index()

        # Verwijder rijen met ontbrekende waarden om de datakwaliteit te garanderen.
        df = df.dropna() # pyright: ignore[reportUnknownMemberType]

        self.logger.info('loader.load_success')
        return df

--- END FILE: backend/data/loader.py ---

--- START FILE: backend/data/__init__.py ---

--- END FILE: backend/data/__init__.py ---

--- START FILE: backend/dtos/backtest_result.py ---
# backend/dtos/backtest_result.py
"""
Contains the data class for storing the complete result of a single backtest run.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas]
@responsibilities:
    - Defines the standardized data structure for holding all results from a
      single backtest run, ready for analysis and presentation.
"""
from typing import Dict, Any
from pydantic import BaseModel, ConfigDict
import pandas as pd

class BacktestResult(BaseModel):
    """A container for all results of a single backtest run.

    This object acts as a standardized Data Transfer Object (DTO) that holds
    all the essential, aggregated outputs from a backtest analysis, produced
    by the PerformanceAnalyzer.

    Attributes:
        trades_df (pd.DataFrame): A DataFrame containing all ClosedTrade objects.
        equity_curve (pd.Series): A Series representing the portfolio's equity over time.
        drawdown_curve (pd.Series): A Series representing the portfolio's drawdown.
        metrics (Dict[str, Any]): A dictionary of calculated performance metrics.
        initial_capital (float): The starting capital for the run.
    """
    trades_df: pd.DataFrame
    equity_curve: pd.Series
    drawdown_curve: pd.Series
    metrics: Dict[str, Any]
    initial_capital: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/backtest_result.py ---

--- START FILE: backend/dtos/closed_trade.py ---
# backend/dtos/closed_trade.py
"""
Contains the data class for a closed trade, representing a completed transaction.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a trade that has been fully
      executed and resulted in a profit or loss.
"""
import uuid
from typing import Optional
from pydantic import BaseModel, ConfigDict
import pandas as pd

class ClosedTrade(BaseModel):
    """Represents the final, recorded result of a single completed trade.

    This DTO is created by the Portfolio after a position is closed. It serves
    as the definitive, historical record for performance analysis and reporting.
    It contains all information from the original TradePlan, enriched with the
    actual exit details and the resulting profit or loss.

    Attributes:
        correlation_id (uuid.UUID): The unique ID linking this record to its
                                    full context log. Inherited from the TradePlan.
        entry_time (pd.Timestamp): The timestamp when the trade was opened.
        exit_time (pd.Timestamp): The timestamp when the trade was closed.
        asset (str): The asset that was traded.
        direction (str): The direction of the trade ('long' or 'short').
        signal_type (str): The name of the logic that generated the original signal.
        entry_price (float): The actual entry price.
        exit_price (float): The actual exit price.
        sl_price (float): The original stop-loss price from the TradePlan.
        tp_price (Optional[float]): The original take-profit price, if any.
        position_value_quote (float): The initial value of the position.
        position_size_asset (float): The size of the position.
        pnl_quote (float): The net profit or loss of the trade, after fees.
    """
    correlation_id: uuid.UUID
    entry_time: pd.Timestamp
    exit_time: pd.Timestamp
    asset: str
    direction: str
    signal_type: str
    entry_price: float
    exit_price: float
    sl_price: float
    tp_price: Optional[float] = None
    position_value_quote: float
    position_size_asset: float
    pnl_quote: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/closed_trade.py ---

--- START FILE: backend/dtos/critical_event.py ---
# backend/dtos/critical_event.py
"""
Contains the DTO for a critical event notification.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a critical event detected
      by the StrategyEngine.
"""
import uuid
import pandas as pd
from pydantic import BaseModel, ConfigDict, Field

class CriticalEvent(BaseModel):
    """
    Represents a minimal, agnostic notification of a critical event.

    This DTO acts as an "alarm bell" generated by a CriticalEventDetector
    plugin (Fase 9). It signals that a significant systemic event has
    occurred. The detailed context that led to this event is stored
    separately in the ContextRecorder. The RunService interprets this
    event and decides on the appropriate action (e.g., halting trading).

    Attributes:
        correlation_id (uuid.UUID): A unique ID for this specific event.
        event_type (str): A string identifier for the event type (e.g., "MAX_DRAWDOWN_BREACHED").
        timestamp (pd.Timestamp): The timestamp of the candle on which the event was detected.
    """
    correlation_id: uuid.UUID = Field(default_factory=uuid.uuid4)
    event_type: str
    timestamp: pd.Timestamp

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/critical_event.py ---

--- START FILE: backend/dtos/engine_cycle_result.py ---
# backend/dtos/engine_cycle_result.py
"""
Contains the DTO that represents the complete output of a single StrategyEngine cycle.

@layer: Backend (DTO)
@dependencies: [pydantic, .execution_directive, .critical_event]
@responsibilities:
    - Bundles all outcomes of a single engine tick into one object.
    - Decouples new trade instructions from systemic event notifications.
"""
from typing import List
from pydantic import BaseModel, ConfigDict
from .execution_directive import ExecutionDirective
from .critical_event import CriticalEvent

class EngineCycleResult(BaseModel):
    """
    Represents the complete output of a single processing cycle (tick)
    of the StrategyEngine. It decouples trade proposals from critical events.

    This object is yielded by the StrategyEngine on every tick and allows the
    consuming service (e.g., BacktestService) to intelligently decide on the
    next course of action.

    Attributes:
        execution_directives (List[ExecutionDirective]): A list of new trades to be executed.
        critical_events (List[CriticalEvent]): A list of detected systemic events.
    """
    execution_directives: List[ExecutionDirective]
    critical_events: List[CriticalEvent]

    model_config = ConfigDict(arbitrary_types_allowed=True)

--- END FILE: backend/dtos/engine_cycle_result.py ---

--- START FILE: backend/dtos/entry_signal.py ---
# backend/dtos/entry_signal.py
"""
Contains the data class for a signal enriched with an entry tactic.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the data structure for a signal that has been enriched with
      a concrete entry tactic by an EntryPlanner.
"""
import uuid
from pydantic import BaseModel, ConfigDict
from .signal import Signal

class EntrySignal(BaseModel):
    """Represents a signal with a concrete entry tactic.

    This DTO is created by an EntryPlanner (Fase 5a). It enriches a raw
    Signal DTO with a calculated entry price and a descriptive entry method.
    It serves as the input for the ExitPlanner (Fase 5b).

    Attributes:
        correlation_id (uuid.UUID): The unique ID inherited from the source Signal.
        signal: the original Signal DTO.
        entry_price (float): The calculated entry price for the trade.
    """
    correlation_id: uuid.UUID
    signal: Signal
    entry_price: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/entry_signal.py ---

--- START FILE: backend/dtos/execution_directive.py ---
# backend/dtos/execution_directive.py
"""
Contains the DTO for a final, flattened execution instruction.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the flat, universal contract for an instruction sent to the
      ExecutionHandler.
"""
import uuid
from typing import Literal, Optional, Dict, Any
from pydantic import BaseModel, ConfigDict
import pandas as pd

class ExecutionDirective(BaseModel):
    """
    A flat, final, and universal instruction for the ExecutionHandler.

    This DTO is a flattened representation of a RoutedTradePlan and contains
    all necessary information to execute, manage, and track a trade. It serves
    as the definitive, simple contract between the StrategyEngine's output and
    the execution layer.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        signal_type (str): The name of the logic that generated the original signal.
        asset (str): The asset to be traded.
        direction (Literal['long', 'short']): The direction of the trade.
        entry_price (float): The calculated entry price for the trade.
        sl_price (float): The absolute stop-loss price.
        tp_price (Optional[float]): The absolute take-profit price, if any.
        position_value_quote (float): The total value of the position in the quote currency.
        position_size_asset (float): The size of the position in the base asset.
        order_type (Literal['market', 'limit']): The fundamental order type.
        limit_price (Optional[float]): The price for a limit order.
        time_in_force (Literal['GTC', 'IOC', 'FOK']): How long the order remains valid.
        post_only (bool): Flag to ensure the order is a "maker" order.
        execution_strategy (Optional[Literal['twap']]): Label for an algorithmic strategy.
        strategy_params (Optional[Dict[str, Any]]): Parameters for the algorithmic strategy.
        preferred_exchange (Optional[str]): A hint for the ExecutionHandler.
        entry_time (pd.Timestamp): From the original signal.
    """
    # Traceability & Identity
    correlation_id: uuid.UUID
    signal_type: str

    # Core Trade Parameters
    asset: str
    direction: Literal['long', 'short']
    entry_price: float
    sl_price: float
    tp_price: Optional[float]

    # Sizing
    position_value_quote: float
    position_size_asset: float

    # Tactical Execution Instructions
    order_type: Literal['market', 'limit']
    limit_price: Optional[float] = None
    time_in_force: Literal['GTC', 'IOC', 'FOK'] = 'GTC'
    post_only: bool = False
    execution_strategy: Optional[Literal['twap']] = None
    strategy_params: Optional[Dict[str, Any]] = None
    preferred_exchange: Optional[str] = None

    # Timestamps
    entry_time: pd.Timestamp

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/execution_directive.py ---

--- START FILE: backend/dtos/risk_defined_signal.py ---
# backend/dtos/risk_defined_signal.py
"""
Contains the data class for a signal enriched with exit prices (risk definition).

@layer: Backend (DTO)
@dependencies: [pydantic, uuid]
@responsibilities:
    - Defines the data structure for a signal that has been enriched with
      absolute stop-loss and take-profit prices by an ExitPlanner.
"""
import uuid
from typing import Optional
from pydantic import BaseModel, ConfigDict
from .entry_signal import EntrySignal

class RiskDefinedSignal(BaseModel):
    """Represents a signal with its risk parameters fully defined.

    This DTO is created by an ExitPlanner (Fase 5b). It enriches an
    EntrySignal with the absolute stop-loss and (optional) take-profit prices.
    It serves as the direct input for the SizePlanner (Fase 5c), providing all
    necessary information to calculate position size based on risk.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        entry_signal: the original EntrySignal DTO.
        sl_price (float): The absolute stop-loss price, defining the risk boundary.
        tp_price (Optional[float]): The absolute take-profit price, if any.
    """
    correlation_id: uuid.UUID
    entry_signal: EntrySignal
    sl_price: float
    tp_price: Optional[float] = None

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/risk_defined_signal.py ---

--- START FILE: backend/dtos/routed_trade_plan.py ---
# backend/dtos/routed_trade_plan.py
"""
Contains the DTO that represents a TradePlan decorated with execution tactics.

@layer: Backend (DTO)
@dependencies: [pydantic, uuid, backend.dtos.trade_plan]
@responsibilities:
    - Defines the universal blueprint for how an order should be executed.
"""
import uuid
from typing import Literal, Optional, Dict, Any
from pydantic import BaseModel, ConfigDict

from .trade_plan import TradePlan

class RoutedTradePlan(BaseModel):
    """
    The universal blueprint for how an order should be executed.

    This DTO is the output of an OrderRouter plugin (Fase 8). It takes the
    complete strategic intent (the TradePlan) and enriches it with concrete,
    technical execution instructions for the ExecutionHandler. It serves as the
    definitive contract between the strategy layer and the execution layer.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        trade_plan (TradePlan): The nested strategic plan to be executed.
        order_type (Literal['market', 'limit']): The fundamental order type.
        limit_price (Optional[float]): The price for a limit order.
        time_in_force (Literal['GTC', 'IOC', 'FOK']): How long the order remains valid.
        post_only (bool): Flag to ensure the order is a "maker" order.
        execution_strategy (Optional[Literal['twap']]): Label for an algorithmic strategy.
        strategy_params (Optional[Dict[str, Any]]): Parameters for the algorithmic strategy.
        preferred_exchange (Optional[str]): A hint for the ExecutionHandler.
    """
    correlation_id: uuid.UUID
    trade_plan: TradePlan

    # --- Tactical Execution Instructions ---
    order_type: Literal['market', 'limit']
    limit_price: Optional[float] = None
    time_in_force: Literal['GTC', 'IOC', 'FOK'] = 'GTC'
    post_only: bool = False
    execution_strategy: Optional[Literal['twap']] = None
    strategy_params: Optional[Dict[str, Any]] = None
    preferred_exchange: Optional[str] = None

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/routed_trade_plan.py ---

--- START FILE: backend/dtos/signal.py ---
# backend/dtos/signal.py
"""
Contains the data class for a raw, unfiltered signal event.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, uuid]
@responsibilities:
    - Defines the standardized data structure for a raw signal event, generated
      by a SignalGenerator plugin.
"""
import uuid
from typing import Literal
from pydantic import BaseModel, Field, ConfigDict
import pandas as pd

class Signal(BaseModel):
    """Represents a pure, unrefined signal event from a specific strategy logic.

    This DTO signifies that a pattern or condition was met at a specific time.
    It contains only the essential "what, where, and when" information, plus a
    unique identifier for traceability. This is the first DTO in the
    SignalOrchestrator's pipeline.

    Attributes:
        correlation_id (uuid.UUID): The unique ID that links this signal and all
                                    subsequent objects (Trade, ClosedTrade) to its
                                    full context log in the ContextRecorder.
                                    Generated by the SignalGenerator.
        timestamp (pd.Timestamp): The timestamp of the candle where the signal occurred.
        asset (str): The asset for which the signal was generated (e.g., 'BTC/EUR').
        direction (str): The directional bias of the signal ('long' or 'short').
        signal_type (str): The name of the logic that generated the signal (e.g.,
                           'golden_cross', 'fvg_entry_detector'). This defines the
                           identity of the signal.
    """
    correlation_id: uuid.UUID = Field(default_factory=uuid.uuid4)
    timestamp: pd.Timestamp
    asset: str
    direction: Literal['long', 'short']
    signal_type: str

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/signal.py ---

--- START FILE: backend/dtos/trade_plan.py ---
# backend/dtos/trade_plan.py
"""
Contains the data class for a complete, executable trade plan.

@layer: Backend (DTO)
@dependencies: [pydantic, uuid, .risk_defined_signal]
@responsibilities:
    - Defines the standardized data structure for a fully planned trade, ready
      for the OrderRouter.
"""
import uuid
from pydantic import BaseModel, ConfigDict
from .risk_defined_signal import RiskDefinedSignal

class TradePlan(BaseModel):
    """
    Represents a complete strategic plan for a single trade.

    This DTO is created by a SizePlanner (Fase 7). It enriches a
    RiskDefinedSignal with the final position size and value. It contains
    all necessary strategic information before being passed to the
    OrderRouter (Fase 8) to be translated into tactical execution instructions.

    Attributes:
        correlation_id (uuid.UUID): The unique ID from the source Signal.
        risk_defined_signal (RiskDefinedSignal): The nested DTO from the previous phase.
        position_value_quote (float): The total value of the position in the quote currency.
        position_size_asset (float): The size of the position in the base asset.
    """
    correlation_id: uuid.UUID
    risk_defined_signal: RiskDefinedSignal
    position_value_quote: float
    position_size_asset: float

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/trade_plan.py ---

--- START FILE: backend/dtos/trading_context.py ---
# backend/dtos/trading_context.py
"""
Contains the data class for the TradingContext.

@layer: Backend (DTO)
@dependencies: [pydantic, pandas, backend.core.interfaces]
@responsibilities:
    - Defines a standardized data structure to hold all shared, contextual
      information available during a single run.
"""
from __future__ import annotations
from typing import Dict, Any, TYPE_CHECKING
from pydantic import BaseModel, ConfigDict
import pandas as pd

from backend.core.context_recorder import ContextRecorder

# Gebruik TYPE_CHECKING om de circulaire import tijdens runtime te voorkomen
if TYPE_CHECKING:
    from backend.core.interfaces import Tradable


class TradingContext(BaseModel):
    """
    A container for all shared data available during a single run.
    This object is the single source of truth for the state of the world
    at the time a plugin is executed.

    Attributes:
        enriched_df (pd.DataFrame): The fully enriched DataFrame, containing all
                                    indicator and context columns.
        portfolio (Tradable): A reference to the active portfolio object.
        context_recorder (ContextRecorder): The recorder for logging detailed context.
        structural_context_registry (Dict[str, Any]): A registry for complex,
                                                      non-tabular context data.
    """
    enriched_df: pd.DataFrame
    # --- DE FIX: Gebruik een forward reference (string) voor Tradable ---
    portfolio: "Tradable"
    context_recorder: ContextRecorder
    structural_context_registry: Dict[str, Any] = {}

    def register_structural_data(self, source_plugin: str, data: Any):
        """Allows a plugin to register a complex data structure."""
        self.structural_context_registry[source_plugin] = data

    def get_structural_data(self, source_plugin: str) -> Any | None:
        """Allows a later plugin to retrieve a complex data structure."""
        return self.structural_context_registry.get(source_plugin)

    model_config = ConfigDict(
        arbitrary_types_allowed=True
    )

--- END FILE: backend/dtos/trading_context.py ---

--- START FILE: backend/dtos/__init__.py ---
# backend/dtos/__init__.py
"""
Exposes the public API of the DTOs sub-package.

This file centralizes all DTO imports, allowing other parts of the
application to import any DTO directly from `backend.dtos` without
needing to know the specific internal file structure.

@layer: Backend (DTO)
"""
__all__ = [
    "Signal",
    "EntrySignal",
    "RiskDefinedSignal",
    "TradePlan",
    "RoutedTradePlan",
    "CriticalEvent",
    "ExecutionDirective",
    "EngineCycleResult",
    "ClosedTrade",
    "TradingContext",
    "BacktestResult",
]

from .signal import Signal
from .entry_signal import EntrySignal
from .risk_defined_signal import RiskDefinedSignal
from .trade_plan import TradePlan
from .routed_trade_plan import RoutedTradePlan
from .critical_event import CriticalEvent
from .execution_directive import ExecutionDirective
from .engine_cycle_result import EngineCycleResult
from .closed_trade import ClosedTrade
from .backtest_result import BacktestResult
from .trading_context import TradingContext

--- END FILE: backend/dtos/__init__.py ---

--- START FILE: backend/environments/backtest_environment.py ---
# backend/environments/backtest_environment.py
"""
Contains the BacktestEnvironment and its specialized sub-components, providing
a complete, isolated world for running historical strategy tests.

@layer: Backend (Environment)
@dependencies: [pandas, backend.core.interfaces, backend.data.loader]
@responsibilities:
    - Implements the BaseEnvironment interface for backtesting.
    - Orchestrates the creation of CSV-based data sources, simulated clocks,
      and backtest execution handlers.
"""
import logging
from pathlib import Path
from typing import Generator, Tuple

import pandas as pd

from backend.config.schemas.app_schema import AppConfig
# --- CORRECTIE: Importeer de JUISTE, GECENTRALISEERDE interfaces ---
from backend.core.interfaces import BaseEnvironment, Clock, DataSource, Tradable
from backend.core.interfaces.execution import ExecutionHandler
from backend.data.loader import DataLoader
from backend.utils.app_logger import LogEnricher
# --- CORRECTIE: Importeer de CONCRETE handler ---
from backend.core.execution import BacktestExecutionHandler


# --- Sub-component Implementations ---
class CSVDataSource(DataSource):
    """A data source that loads market data from a CSV file."""

    def __init__(self, source_dir: str, trading_pair: str, timeframe: str, logger: LogEnricher):
        self._logger = logger
        base_path = Path(source_dir)
        pair_filename = trading_pair.replace('/', '_')
        filename = f"{pair_filename}_{timeframe}.csv"
        file_path = base_path / filename

        self._data_loader = DataLoader(str(file_path), self._logger)
        self._data: pd.DataFrame = pd.DataFrame()

    def get_data(self) -> pd.DataFrame:
        """Loads data if not already loaded, then returns it."""
        if self._data.empty:
            self._data = self._data_loader.load()
        return self._data

class SimulatedClock(Clock):
    """A clock that simulates the passage of time by iterating over a DataFrame."""

    def __init__(self, df: pd.DataFrame):
        self._df = df

    def tick(self) -> Generator[Tuple[pd.Timestamp, pd.Series], None, None]:
        """Yields each row of the DataFrame as a moment in time."""
        for timestamp, row in self._df.iterrows():
            assert isinstance(timestamp, pd.Timestamp)
            yield timestamp, row

# --- Main Environment Class ---
class BacktestEnvironment(BaseEnvironment):
    """
    The concrete implementation of a BaseEnvironment for running backtests.
    """
    def __init__(self, app_config: AppConfig, tradable: Tradable):
        """Initializes the environment and constructs its sub-components."""
        self._logger = LogEnricher(logging.getLogger(__name__))

        self._source = CSVDataSource(
            source_dir=app_config.platform.data.source_dir,
            trading_pair=app_config.run.data.trading_pair,
            timeframe=app_config.run.data.timeframe,
            logger=self._logger
        )
        self._clock = SimulatedClock(self._source.get_data())
        self._handler = BacktestExecutionHandler(tradable, self._logger)

    @property
    def source(self) -> DataSource:
        return self._source

    @property
    def clock(self) -> Clock:
        return self._clock

    @property
    def handler(self) -> ExecutionHandler:
        return self._handler

--- END FILE: backend/environments/backtest_environment.py ---

--- START FILE: backend/environments/live_environment.py ---
# backend/environments/live_environment.py
"""
Docstring for live_environment.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class LiveTradeEnvironment:
    """Docstring for LiveTradeEnvironment."""

--- END FILE: backend/environments/live_environment.py ---

--- START FILE: backend/environments/paper_environment.py ---
# backend/environments/paper_environment.py
"""
Docstring for paper_environment.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class PaperTradeEnvironment:
    """Docstring for PaperTradeEnvironment."""
    pass

--- END FILE: backend/environments/paper_environment.py ---

--- START FILE: backend/environments/__init__.py ---
# backend/environments/__init__.py
"""
Exposes the public API of the Environments sub-package.
"""
__all__ = [
    "BacktestEnvironment",
#    "LiveEnvironment",
#    "PaperEnvironment",
]

from .backtest_environment import BacktestEnvironment
#from .live_environment import LiveEnvironment
#from .paper_environment import PaperEnvironment

--- END FILE: backend/environments/__init__.py ---

--- START FILE: backend/utils/app_logger.py ---
# utils/app_logger.py
"""
Configures and provides the application's logging system.

This module is the single source of truth for all logging-related setup.
It is designed to be configured once at the application's entry point.

@layer: Utility
@dependencies:
    - Translator: The `LogFormatter` receives a `Translator` instance to translate log message keys.
    - Constants: Uses `core.constants` for log level definitions and default profile names.
@responsibilities:
    - Defines the custom `LogFormatter` to handle translation and indentation of log messages.
    - Defines the `LogEnricher` adapter, which is the standard logger interface for the application.
    - Defines the `LogProfiler` to filter logs based on the configured profile.
    - Provides the central `configure_logging` function to bootstrap the logging system.
@inputs:
    - The application `config` dictionary.
    - A `Translator` instance.
@outputs:
    - A fully configured root logger (side-effect).
"""

# 1. Standard Library Imports
import logging
import sys
from typing import Any, Dict, List, Literal, MutableMapping, Optional, Tuple

# 3. Our Application Imports
from backend.utils.translator import Translator
from backend.core.enums import LogLevel
from backend.config.schemas.platform_schema import LoggingConfig

class LogFormatter(logging.Formatter):
    """A custom log formatter that handles translation, value formatting, and indentation.

    This formatter intercepts the log record, translates the message key if
    applicable, formats the translated string with any provided values, and
    applies an indentation level based on the record's context.
    """

    def __init__(self,
                 fmt: Optional[str] = None,
                 datefmt: Optional[str] = None,
                 style: Literal['%', '{', '$'] = '%',
                 translator: Optional[Translator] = None):
        """Initializes the LogFormatter.

        Args:
            fmt (str, optional): The format string for the log. Defaults to None.
            datefmt (str, optional): The format string for dates. Defaults to None.
            style (str, optional): The formatting style. Defaults to '%'.
            translator (Translator, optional): The translator instance for
                                               translating log keys. Defaults to None.
        """
        super().__init__(fmt, datefmt, style)
        self.translator = translator

    def format(self, record: logging.LogRecord) -> str:
        """Formats the log record by translating, populating, and indenting it.

        Args:
            record (logging.LogRecord): The log record to format.

        Returns:
            The fully formatted log message string.
        """
        key = record.msg
        translated_template = key
        values_dict = getattr(record, 'values', {})

        # Step 1: Translate the message key, if it's a valid key.
        if self.translator and isinstance(key, str) and '.' in key and ' ' not in key:
            translated_template = self.translator.get(key, default=key)

        # Step 2: Format the template with any provided values.
        final_message = translated_template
        if values_dict:
            try:
                final_message = translated_template.format(**values_dict)
            except (KeyError, TypeError):
                final_message = f"{translated_template} [FORMATTING ERROR]"

        record.msg = final_message
        record.args = ()

        # Step 3: Apply our custom indentation directly to the message content.
        indent_level = getattr(record, 'indent', 0)
        indented_message = "  " * indent_level + final_message

        # Place the fully prepared (and indented) message back into the record.
        record.msg = indented_message

        # Step 4: Let the original Formatter handle the primary layout (e.g., [INFO   ]).
        return super().format(record)

class LogEnricher(logging.LoggerAdapter[logging.Logger]):
    """A logger adapter that enriches log records with indentation and context.

    This adapter provides the standard logging interface for the application. Its
    main purpose is to shuttle contextual data (like 'indent' or 'values') into
    the 'extra' payload of a log record, which can then be used by the
    `LogFormatter`. It also provides convenience methods for custom log levels.
    """

    def __init__(self, logger: logging.Logger, indent: int = 0):
        """Initializes the LogEnricher adapter.

        Args:
            logger: The logger instance to wrap.
            indent: The indentation level for messages from this logger.
        """
        super().__init__(logger, {'indent': indent})

    def process(
        self, msg: Any, kwargs: MutableMapping[str, Any]
    ) -> Tuple[Any, MutableMapping[str, Any]]:
        """Merges the adapter's contextual information into the kwargs.

        Args:
            msg: The log message.
            kwargs: Keyword arguments to the logging call.

        Returns:
            A tuple containing the message and the modified keyword arguments.
        """
        # Ensure 'extra' dictionary exists and merge adapter's context into it.
        kwargs["extra"] = kwargs.get("extra", {})
        kwargs["extra"].update(self.extra)

        # Move 'values' from kwargs into the 'extra' dict for the formatter.
        if 'values' in kwargs:
            kwargs['extra']['values'] = kwargs.pop('values')

        return msg, kwargs

    # --- Convenience methods for custom levels ---
    def setup(self, key: str, **values: Any) -> None:
        """Logs a message with the SETUP level."""
        self.log(CUSTOM_LEVELS[LogLevel.SETUP], key, values=values)

    def match(self, key: str, **values: Any) -> None:
        """Logs a message with the MATCH level."""
        self.log(CUSTOM_LEVELS[LogLevel.MATCH], key, values=values)

    def filter(self, key: str, **values: Any) -> None:
        """Logs a message with the FILTER level."""
        self.log(CUSTOM_LEVELS[LogLevel.FILTER], key, values=values)

    def policy(self, key: str, **values: Any) -> None:
        """Logs a message with the POLICY level."""
        self.log(CUSTOM_LEVELS[LogLevel.POLICY], key, values=values)

    def result(self, key: str, **values: Any) -> None:
        """Logs a message with the RESULT level."""
        self.log(CUSTOM_LEVELS[LogLevel.RESULT], key, values=values)

    def trade(self, key: str, **values: Any) -> None:
        """Logs a message with the TRADE level."""
        self.log(CUSTOM_LEVELS[LogLevel.TRADE], key, values=values)

class LogProfiler(logging.Filter):
    """A logging filter that allows messages based on the active profile."""

    def __init__(self, profile: str, profile_definitions: Dict[str, List[LogLevel]]):
        """Initializes the filter.

        Args:
            profile: The name of the active logging profile.
            profile_definitions: A dictionary defining all available profiles
                                 and their allowed log level names.
        """
        super().__init__()
        allowed_levels_for_profile = profile_definitions.get(profile, [])
        self.allowed_levels = {level.value for level in allowed_levels_for_profile}

    def filter(self, record: logging.LogRecord) -> bool:
        """Determines if a log record should be processed.

        Args:
            record: The log record to check.

        Returns:
            True if the record's level name is in the allowed set for the
            active profile, False otherwise.
        """
        return record.levelname in self.allowed_levels

# Define and register custom log levels. This mapping is an implementation
# detail of the logger and is therefore defined here, not in core.constants.
CUSTOM_LEVELS = {
    LogLevel.SETUP: 15,
    LogLevel.MATCH: 22,
    LogLevel.FILTER: 23,
    LogLevel.POLICY: 24,
    LogLevel.RESULT: 25,
    LogLevel.TRADE: 26,
}

def configure_logging(logging_config: LoggingConfig, translator: Translator):
    """Configures the central, root logger for the entire application.

    This function should be called only once from `main.py`. It sets up custom
    log levels, creates a handler, attaches the custom `LogFormatter` and
    `LogProfiler` filter, and adds the handler to the root logger.

    Args:
        logging_config: The Pydantic model for the logging configuration.
        translator: An existing translator instance to be used by the formatter.
    """
    for level_enum, level_value in CUSTOM_LEVELS.items():
        logging.addLevelName(level_value, level_enum.value)

    # Use dotted access on the Pydantic model
    log_profile = logging_config.profile
    profile_definitions = logging_config.profiles
    log_format = '[%(levelname)-8s] %(message)s'

    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)

    # Clear any existing handlers to prevent duplicate logs.
    if logger.hasHandlers():
        logger.handlers.clear()

    handler = logging.StreamHandler(sys.stdout)
    # The Formatter is the only component that needs the translator.
    handler.setFormatter(LogFormatter(log_format, translator=translator))
    handler.addFilter(LogProfiler(log_profile, profile_definitions))
    logger.addHandler(handler)

--- END FILE: backend/utils/app_logger.py ---

--- START FILE: backend/utils/data_utils.py ---
# backend/utils/data_utils.py
"""
Utility functions for data manipulation
"""

--- END FILE: backend/utils/data_utils.py ---

--- START FILE: backend/utils/dynamic_loader.py ---
# backend/utils/dynamic_loader.py
"""
Handles the dynamic loading of classes from plugin modules.

@layer: Backend (Utility)
@dependencies: [importlib]
@responsibilities:
    - Provides a single function to dynamically import a class from a module
      using a string-based path and class name.
"""

import importlib
from typing import Any

def load_class_from_module(module_path: str, class_name: str) -> Any:
    """
    Dynamically imports a module and returns a specific class from it.

    Args:
        module_path (str): The full, dot-separated path to the Python module
                           (e.g., "plugins.signal_generators.my_plugin.worker").
        class_name (str): The exact name of the class to load from the module.

    Raises:
        ImportError: If the module cannot be found.
        AttributeError: If the class does not exist within the module.

    Returns:
        The loaded class object (not an instance).
    """
    try:
        module = importlib.import_module(module_path)
        loaded_class = getattr(module, class_name)
        return loaded_class
    except ImportError as e:
        raise ImportError(f"Could not import module '{module_path}': {e}") from e
    except AttributeError as e:
        raise AttributeError(
            f"Class '{class_name}' not found in module '{module_path}': {e}"
        ) from e

--- END FILE: backend/utils/dynamic_loader.py ---

--- START FILE: backend/utils/translator.py ---
# utils/translator.py
"""
Handles loading and retrieving translated strings for the application.

@layer: Utility
@dependencies:
    - Constants: Uses `core.constants` to get the default language and locale directory path.
@responsibilities:
    - Loads the appropriate language file based on the application configuration.
    - Provides a `get` method to retrieve translated strings using dot-notation keys.
    - Provides a `get_param_name` method for the special case of parameter display names.
@inputs:
    - The application `config` dictionary on initialization.
    - Dot-notation keys and format values for getter methods.
@outputs:
    - Translated and formatted strings.
"""

# 1. Standard Library Imports
from pathlib import Path
from typing import Any, Dict

# 2. Third-Party Imports
import yaml

# 3. Our Application Imports
from backend.config.schemas.platform_schema import PlatformConfig

class Translator:
    """Loads and manages internationalization (i18n) strings from YAML files.

    This class is instantiated once at startup. It loads the appropriate
    language file based on the application configuration and provides methods
    to retrieve translated strings using a dot-notation key.
    """
    def __init__(self, platform_config: PlatformConfig):
        """Initializes the Translator by loading the appropriate language file.

        Args:
            app_config (AppConfig): The application Pydantic config object.
        """
        lang_path = Path('locales') / f"{platform_config.language}.yaml"
        self.strings: Dict[str, Any] = {}
        try:
            with open(lang_path, 'r', encoding='utf-8') as f:
                self.strings = yaml.safe_load(f)
        except FileNotFoundError:
            print(f"WARNING: Language file not found at {lang_path}")

    def get(self, key: str, default: str | None = None, **kwargs: Any) -> str:
        """Retrieves and formats a nested translated string using dot-notation.

        If the key is not found, it returns the default value, or the key
        itself if no default is provided.

        Args:
            key (str): The dot-notation key (e.g., 'app.start').
            default (str, optional): A fallback value to return if the key is
                                     not found. Defaults to None.
            **kwargs: Values to format into the translated string.

        Returns:
            The translated and formatted string.
        """
        try:
            value: Any = self.strings
            for part in key.split('.'):
                value = value[part]

            # A valid translation must be a string. If we resolved a dict
            # (incomplete key), it's invalid.
            if not isinstance(value, str):
                return default or key

            return value.format(**kwargs)
        except (KeyError, TypeError):
            return default or key

    def get_param_name(self, param_path: str, default: str | None = None) -> str:
        """Retrieves a display name for a full parameter path.

        This performs a direct lookup in the 'params_display_names' dictionary
        within the language file, which is a flat key-value map.

        Args:
            param_path (str): The full parameter path to look up.
            default (str, optional): The value to return if the path is not
                                     found. Defaults to the original param_path.

        Returns:
            The display name or a fallback value.
        """
        param_dict = self.strings.get('params_display_names', {})
        return param_dict.get(param_path, default or param_path)

--- END FILE: backend/utils/translator.py ---

--- START FILE: backend/utils/__init__.py ---

--- END FILE: backend/utils/__init__.py ---

--- START FILE: config/index.yaml ---
# Placeholder for config/index.yaml

--- END FILE: config/index.yaml ---

--- START FILE: config/platform.yaml ---
# config/platform.yaml
# De minimale, fundamentele configuratie voor S1mpleTrader V2.

language: 'en'
plugins_root_path: 'plugins'

data:
  source_dir: 'source_data'

portfolio:
  initial_capital: 10000.0
  fees_pct: 0.001

logging:
  profile: 'analysis'
  profiles:
    developer: ['WARNING', 'ERROR', 'CRITICAL']
    analysis: ['DEBUG', 'INFO', 'MATCH', 'FILTER', 'TRADE', 'RESULT', 'WARNING', 'ERROR', 'CRITICAL']

--- END FILE: config/platform.yaml ---

--- START FILE: config/__init__.py ---

--- END FILE: config/__init__.py ---

--- START FILE: config/optimizations/optimize_atr_params.yaml ---
# Placeholder for config/optimizations/optimize_atr_params.yaml

--- END FILE: config/optimizations/optimize_atr_params.yaml ---

--- START FILE: config/overrides/use_eth_pair.yaml ---
# Placeholder for config/overrides/use_eth_pair.yaml

--- END FILE: config/overrides/use_eth_pair.yaml ---

--- START FILE: config/runs/mss_fvg_strategy.yaml ---
# Placeholder for config/runs/mss_fvg_strategy.yaml

--- END FILE: config/runs/mss_fvg_strategy.yaml ---

--- START FILE: config/variants/robustness_test.yaml ---
# Placeholder for config/variants/robustness_test.yaml

--- END FILE: config/variants/robustness_test.yaml ---

--- START FILE: docs/folder_file_structure.txt ---
S1mpleTraderV2/
├── backend
│   ├── assembly
│   │   ├── __init__.py
│   │   ├── context_builder.py
│   │   ├── dependency_validator.py
│   │   ├── plugin_registry.py
│   │   └── worker_builder.py
│   ├── config
│   │   ├── schemas
│   │   │   ├── __init__.py
│   │   │   ├── app_schema.py
│   │   │   ├── platform_schema.py
│   │   │   ├── plugin_manifest_schema.py
│   │   │   └── run_schema.py
│   │   └── __init__.py
│   ├── core
│   │   ├── interfaces
│   │   │   ├── __init__.py
│   │   │   ├── engine.py
│   │   │   ├── environment.py
│   │   │   ├── portfolio.py
│   │   │   └── worker.py
│   │   ├── __init__.py
│   │   ├── base_worker.py
│   │   ├── constants.py
│   │   ├── context_recorder.py
│   │   ├── directive_flattener.py
│   │   ├── enums.py
│   │   ├── execution.py
│   │   ├── performance_analyzer.py
│   │   ├── portfolio.py
│   │   └── strategy_engine.py
│   ├── data
│   │   ├── __init__.py
│   │   └── loader.py
│   ├── dtos
│   │   ├── __init__.py
│   │   ├── backtest_result.py
│   │   ├── closed_trade.py
│   │   ├── critical_event.py
│   │   ├── engine_cycle_result.py
│   │   ├── entry_signal.py
│   │   ├── execution_directive.py
│   │   ├── risk_defined_signal.py
│   │   ├── routed_trade_plan.py
│   │   ├── signal.py
│   │   ├── trade_plan.py
│   │   └── trading_context.py
│   ├── environments
│   │   ├── __init__.py
│   │   ├── backtest_environment.py
│   │   ├── live_environment.py
│   │   └── paper_environment.py
│   ├── utils
│   │   ├── __init__.py
│   │   ├── app_logger.py
│   │   ├── data_utils.py
│   │   ├── dynamic_loader.py
│   │   └── translator.py
│   ├── __init__.py
│   └── py.typed
├── config
│   ├── optimizations
│   │   └── optimize_atr_params.yaml
│   ├── overrides
│   │   └── use_eth_pair.yaml
│   ├── runs
│   │   └── mss_fvg_strategy.yaml
│   ├── variants
│   │   └── robustness_test.yaml
│   ├── __init__.py
│   ├── index.yaml
│   └── platform.yaml
├── docs
│   ├── development
│   │   ├── KanBan
│   │   │   ├── backlog_to_github.py
│   │   │   ├── clear_github_issues.py
│   │   │   └── product_backlog.csv
│   │   └── USM_DEV_ROADMAP.md
│   ├── system
│   │   ├── 0_V2_ARCHITECTURE.md
│   │   ├── 2_ARCHITECTURE.md
│   │   ├── 3_PLUGIN_ANATOMY.md
│   │   ├── 4_WORKFLOW_AND_ORCHESTRATOR.md
│   │   ├── 5_FRONTEND_INTEGRATION.md
│   │   ├── 6_RESILIENCE_AND_OPERATIONS.md
│   │   ├── 7_DEVELOPMENT_STRATEGY.md
│   │   ├── 8_META_WORKFLOWS.md
│   │   ├── 9_CODING_STANDAARDS.md
│   │   ├── A_BIJLAGE_TEMINOLOGIE.md
│   │   ├── B_BIJLAGE_OPENSTAANDE_VRAAGSTUKKEN.md
│   │   └── C_BIJLAGE_MVP
│   ├── folder_file_structure.txt
│   └── PROPOSED_FOLDER_STRUCTURE.md
├── frontends
│   ├── cli
│   │   ├── presenters
│   │   │   └── optimization_presenter.py
│   │   └── reporters
│   │       └── cli_reporter.py
│   ├── web
│   │   ├── api
│   │   │   ├── routers
│   │   │   │   ├── __init__.py
│   │   │   │   ├── backtest_router.py
│   │   │   │   └── plugins_router.py
│   │   │   ├── __init__.py
│   │   │   └── main.py
│   │   └── ui
│   │       ├── src
│   │       │   ├── components
│   │       │   ├── services
│   │       │   └── App.tsx
│   │       └── package.json
│   └── __init__.py
├── locales
│   ├── en.yaml
│   └── nl.yaml
├── plugins
│   ├── portfolio_overlays
│   │   ├── max_drawdown_overlay
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── regime_filters
│   │   ├── adx_trend_filter
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── signal_generators
│   │   ├── fvg_entry_detector
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── signal_refiners
│   │   ├── volume_spike_refiner
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── structural_context
│   │   ├── market_structure_detector
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   ├── trade_constructors
│   │   ├── liquidity_target_exit
│   │   │   ├── tests
│   │   │   │   ├── __init__.py
│   │   │   │   └── test_worker.py
│   │   │   ├── __init__.py
│   │   │   ├── plugin_manifest.yaml
│   │   │   ├── schema.py
│   │   │   └── worker.py
│   │   └── __init__.py
│   └── __init__.py
├── services
│   ├── api_services
│   │   ├── __init__.py
│   │   ├── plugin_query_service.py
│   │   └── visualization_service.py
│   ├── __init__.py
│   ├── optimization_service.py
│   ├── parallel_run_service.py
│   ├── strategy_operator.py
│   └── variant_test_service.py
├── source_data
│   └── BTC_EUR_15m.csv
├── tests
│   ├── backend
│   │   ├── assembly
│   │   │   ├── __init__.py
│   │   │   ├── test_context_builder.py
│   │   │   ├── test_dependency_validator.py
│   │   │   ├── test_plugin_registry.py
│   │   │   └── test_worker_builder.py
│   │   ├── core
│   │   │   ├── test_context_recoreder.py
│   │   │   ├── test_directive_flattener.py
│   │   │   ├── test_portfolio.py
│   │   │   └── test_strategy_engine.py
│   │   ├── data
│   │   │   ├── __init__.py
│   │   │   └── test_data_loader.py
│   │   ├── environments
│   │   │   ├── __init__.py
│   │   │   └── test_backtest_environment.py
│   │   └── __init__.py
│   ├── services
│   │   └── test_strategy_operator.py
│   └── __init__.py
├── tools
│   ├── __init__.py
│   ├── bootstrap_v2.py
│   ├── collect_context.py
│   ├── generate_structure.py
│   └── plugin_creator.py
├── .env
├── .gitignore
├── .pylintrc
├── __init__.py
├── GEMINI.md
├── pytest.ini
├── requirements.txt
├── run_backtest_cli.py
├── run_supervisor.py
└── run_web.py

--- END FILE: docs/project_context.txt ---

--- START FILE: docs/PROPOSED_FOLDER_STRUCTURE.md ---
S1mpleTrader_V2/
├── config/
│   ├── runs/
│   │   └── mss_fvg_strategy.yaml
│   ├── optimizations/
│   │   └── optimize_atr_params.yaml
│   ├── variants/
│   │   └── robustness_test.yaml
│   ├── overrides/
│   │   └── use_eth_pair.yaml
│   ├── index.yaml
│   └── platform.yaml
│
├── plugins/
│   ├── regime_filters/
│   │   └── adx_trend_filter/
│   │       ├── init.py
│   │       ├── plugin_manifest.yaml
│   │       ├── worker.py
│   │       ├── schema.py
│   │       └── tests/
│   │           └── test_worker.py
│   │
│   ├── structural_context/
│   │   └── market_structure_detector/
│   │       ├── init.py
│   │       ├── plugin_manifest.yaml
│   │       ├── worker.py
│   │       ├── schema.py
│   │       └── tests/
│   │           └── test_worker.py
│   │
│   ├── signal_generators/
│   │   └── fvg_entry_detector/
│   │       ├── init.py
│   │       ├── plugin_manifest.yaml
│   │       ├── worker.py
│   │       ├── schema.py
│   │       └── tests/
│   │           └── test_worker.py
│   │
│   ├── signal_refiners/
│   │   └── volume_spike_refiner/
│   │       ├── init.py
│   │       ├── plugin_manifest.yaml
│   │       ├── worker.py
│   │       ├── schema.py
│   │       └── tests/
│   │           └── test_worker.py
│   │
│   ├── trade_constructors/
│   │   └── liquidity_target_exit/
│   │       ├── init.py
│   │       ├── plugin_manifest.yaml
│   │       ├── worker.py
│   │       ├── schema.py
│   │       └── tests/
│   │           └── test_worker.py
│   │
│   └── portfolio_overlays/
│       └── max_drawdown_overlay/
│           ├── init.py
│           ├── plugin_manifest.yaml
│           ├── worker.py
│           ├── schema.py
│           └── tests/
│               └── test_worker.py
│
├── backend/
│   ├── config/
│   │   └── schemas/
│   │       ├── init.py
│   │       ├── app_schema.py
│   │       └── run_schema.py
│   │
│   ├── assembly/
│   │   ├── init.py
│   │   ├── plugin_registry.py
│   │   ├── worker_builder.py
│   │   └── context_pipeline_runner.py
│   │
│   ├── core/
│   │   ├── init.py
│   │   ├── portfolio.py
│   │   ├── execution.py
│   │   ├── performance_analyzer.py
│   │   ├── interfaces.py
│   │   └── constants.py
│   │
│   ├── environments/
│   │   ├── init.py
│   │   ├── base_environment.py
│   │   ├── backtest_environment.py
│   │   ├── paper_environment.py
│   │   └── live_environment.py
│   │
│   ├── dtos/
│   │   ├── init.py
│   │   ├── signal.py
│   │   ├── trade.py
│   │   ├── closed_trade.py
│   │   └── backtest_result.py
│   │
│   └── utils/
│       ├── init.py
│       ├── app_logger.py
│       ├── translator.py
│       └── data_utils.py
│
├── services/
│   ├── init.py
│   ├── strategy_orchestrator.py
│   ├── optimization_service.py
│   ├── variant_test_service.py
│   ├── parallel_run_service.py
│   └── api_services/
│       ├── init.py
│       ├── plugin_query_service.py
│       └── visualization_service.py
│
├── frontends/
│   ├── web/
│   │   ├── api/
│   │   │   ├── init.py
│   │   │   ├── main.py
│   │   │   └── routers/
│   │   │       ├── init.py
│   │   │       ├── plugins_router.py
│   │   │       └── backtest_router.py
│   │   └── ui/
│   │       ├── src/
│   │       │   ├── components/
│   │       │   ├── services/
│   │       │   └── App.tsx
│   │       └── package.json
│   │
│   └── cli/
│       ├── presenters/
│       │   └── optimization_presenter.py
│       └── reporters/
│           └── cli_reporter.py
│
├── docs/
│   └── system/
│       ├── V2_ARCHITECTURE.md
│       ├── 3_PLUGIN_ANATOMY.md
│       ├── 4_WORKFLOW_AND_ORCHESTRATION.md
│       ├── 5_FRONTEND_INTEGRATION.md
│       ├── 6_RESILIENCE_AND_OPERATIONS.md
│       └── 7_DEVELOPMENT_STRATEGY.md
│
├── locales/
│   ├── en.yaml
│   └── nl.yaml
│
├── tools/
│   ├── generate_structure.py
│   └── plugin_creator.py
│
├── source_data/
│   └── BTC_EUR_15m.csv
│
├── results/
│   └── 20250924_213000_mss_fvg_strategy/
│       ├── run_config.yaml
│       ├── result_trades.csv
│       ├── result_metrics.yaml
│       └── run.log.json
│
├── run_web.py
├── run_supervisor.py
├── run_backtest_cli.py
└── pyproject.toml
--- END FILE: docs/PROPOSED_FOLDER_STRUCTURE.md ---

--- START FILE: docs/development/USM_DEV_ROADMAP.md ---
Release 1: The Walking Skeleton (MVP)
Doel: Een strategie kunnen bouwen, een enkele backtest uitvoeren en de basisresultaten (PnL & trades) kunnen zien.

PLUGIN DEVELOPMENT	STRATEGY BUILDER	BACKTESTING & ANALYSIS	PAPER TRADING	LIVE MONITORING
[DEV] Plugin-idee beschrijven.	[UI] Nieuwe strategie aanmaken in de web-UI.	[UI] Een enkele backtest-run starten.		
[DEV] Nieuwe plugin ontwikkelen (worker, schema, manifest).	[UI] Beschikbare plugins per fase tonen.	[UI] Basis-resultatenpagina met PnL-grafiek en key metrics.		
[DEV] Plugin testen (unit test).	[UI] Plugins toevoegen aan de 6 fasen.	[UI] Lijst van alle trades tonen in een simpele tabel.		
[UI] Plugin-parameters instellen via een formulier.			
[UI] Strategie opslaan.			

Exporteren naar Spreadsheets
Release 2: Advanced Analysis & Tooling
Doel: De strateeg krachtige tools geven om strategieën te optimaliseren, te vergelijken en diepgaand visueel te analyseren.

PLUGIN DEVELOPMENT	STRATEGY BUILDER	BACKTESTING & ANALYSIS	PAPER TRADING	LIVE MONITORING
[UI] Een optimalisatie-run opzetten.		
[UI] Te optimaliseren parameters en ranges definiëren.		
[UI] Interactieve tabel voor optimization-resultaten (sorteren, filteren).		
[UI] Een varianten-test opzetten om kandidaten te vergelijken.		
[UI] Vergelijkende resultaten tonen (equity curves, heatmap).		
[UI] "Trade Explorer": diepgaande visuele analyse van enkele trades met context.		

Exporteren naar Spreadsheets
Release 3: Live Operations
Doel: De gevalideerde strategie veilig en betrouwbaar in een gesimuleerde (paper) en uiteindelijk live omgeving draaien.

PLUGIN DEVELOPMENT	STRATEGY BUILDER	BACKTESTING & ANALYSIS	PAPER TRADING	LIVE MONITORING
[UI] Strategie selecteren voor paper trading.	[UI] Dashboard voor live-portfolio monitoring.
[UI] Paper trading sessie starten/stoppen.	[UI] Live PnL, open posities en alerts tonen.
[UI] Real-time PnL en open posities bekijken.	[UI] Noodstop-knop.
[BE] PaperTradeEnvironment implementeren.	[BE] LiveEnvironment & run_supervisor.py implementeren.
[BE] Resilience-strategieën implementeren.
--- END FILE: docs/development/USM_DEV_ROADMAP.md ---

--- START FILE: docs/development/KanBan/backlog_to_github.py ---
# backlog_to_github.py
"""
Reads a product_backlog.csv file and creates GitHub issues for each entry
using the GitHub CLI (`gh`). It automatically creates labels if they don't exist.

@layer: Tool
@dependencies:
    - GitHub CLI (must be installed and authenticated)
@responsibilities:
    - Parses a CSV file with backlog items.
    - Ensures required labels exist in the GitHub repository.
    - Constructs and executes `gh issue create` commands.
@inputs:
    - A `product_backlog.csv` file in the same directory.
@outputs:
    - Creates GitHub issues in the repository associated with the current directory.
"""

import csv
import subprocess
import shutil
import sys
import json
import random

# --- Constants ---
BACKLOG_FILE = 'product_backlog.csv'

# --- Global Cache ---
# A set to store the names of labels that are confirmed to exist in the repo.
EXISTING_LABELS = set()

def check_gh_cli():
    """Checks if the GitHub CLI tool 'gh' is installed and accessible."""
    if not shutil.which("gh"):
        print("❌ FOUT: De GitHub CLI ('gh') is niet geïnstalleerd of niet gevonden in je PATH.")
        print("   Installeer het via: https://cli.github.com/")
        return False
    return True

def populate_existing_labels_cache():
    """
    Fetches all existing labels from the repository once and stores them in the
    global cache to minimize API calls.
    """
    global EXISTING_LABELS
    print("Labels in de repository controleren...", end='', flush=True)
    try:
        command = ["gh", "label", "list", "--json", "name"]
        result = subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8')
        labels = json.loads(result.stdout)
        EXISTING_LABELS = {label['name'] for label in labels}
        print(f" ✅ {len(EXISTING_LABELS)} labels gevonden.")
    except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
        print(f"\n⚠️ Waarschuwing: Kon bestaande labels niet ophalen: {e}.")
        print("   Het script zal proberen de labels aan te maken, dit kan mislukken als ze al bestaan.")
        EXISTING_LABELS = set()

def ensure_label_exists(label_name):
    """
    Checks if a label exists locally, and if not, creates it via the GitHub CLI.
    """
    # Check against the cache first.
    if label_name in EXISTING_LABELS:
        return

    # If not in cache, create it.
    print(f"   Label '{label_name}' niet gevonden, wordt aangemaakt...", end='', flush=True)
    
    # Generate a random color for better visual distinction.
    color = f'{random.randint(0, 0xFFFFFF):06x}'
    
    command = [
        "gh", "label", "create", label_name,
        "--color", color,
        "--description", "Automatisch aangemaakt door backlog script."
    ]
    
    try:
        subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8')
        print(" ✅")
        # Add the newly created label to the cache to avoid re-creating it.
        EXISTING_LABELS.add(label_name)
    except subprocess.CalledProcessError as e:
        # Handle the case where the label might already exist but wasn't in our initial fetch.
        if "already exists" in e.stderr:
            print(" ⚠️  Bestond al.")
            EXISTING_LABELS.add(label_name)
        else:
            print(" ❌ Fout!")
            print(f"      Error bij aanmaken van label: {e.stderr.strip()}")

def create_github_issue(title, release, fase, issue_type):
    """Creates a single GitHub issue with appropriate labels."""
    # Define the desired labels
    release_label = f"Release: {release}"
    fase_label = f"Fase: {fase}"
    type_label = f"Type: {issue_type}"
    
    # Ensure all labels exist before creating the issue
    ensure_label_exists(release_label)
    ensure_label_exists(fase_label)
    ensure_label_exists(type_label)

    # Construct the issue creation command
    command = [
        "gh", "issue", "create",
        "--title", title,
        "--body", f"Automatisch aangemaakt vanuit de product backlog voor **Release {release}**.",
        "--label", release_label,
        "--label", fase_label,
        "--label", type_label
    ]

    try:
        print(f"Issue aanmaken voor: '{title}'...", end='', flush=True)
        result = subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8')
        print(f" ✅ Gelukt! ({result.stdout.strip()})")
    except subprocess.CalledProcessError as e:
        print(" ❌ Fout!")
        print(f"   Error bij het aanmaken van issue: {e.stderr.strip()}")

def main():
    """Main function to read the backlog and create all issues."""
    if not check_gh_cli():
        return

    print("🚀 Starten met het aanmaken van GitHub issues vanuit de backlog...")
    print("-" * 60)

    # 1. Fetch existing labels once at the beginning
    populate_existing_labels_cache()
    
    # 2. Process the CSV file
    try:
        with open(BACKLOG_FILE, mode='r', encoding='utf-8') as infile:
            reader = csv.DictReader(infile, delimiter=';')
            for row in reader:
                create_github_issue(
                    title=row['User Story'],
                    release=row['Release'],
                    fase=row['Fase'],
                    issue_type=row['Type']
                )
    except FileNotFoundError:
        print(f"❌ FOUT: Het bestand '{BACKLOG_FILE}' niet gevonden in de huidige map.")
        return
    except KeyError as e:
        print(f"❌ FOUT: Een verwachte kolom ontbreekt in je CSV-bestand: {e}")
        return

    print("-" * 60)
    print("✅ Alle items uit de backlog zijn verwerkt.")

if __name__ == "__main__":
    main()


--- END FILE: docs/development/KanBan/backlog_to_github.py ---

--- START FILE: docs/development/KanBan/clear_github_issues.py ---
# clear_github_issues.py
"""
Deletes all CLOSED issues in the current GitHub repository.
This is useful for cleaning up the 'Done' column in a project board after a bulk close.

@layer: Tool
@dependencies:
    - GitHub CLI (must be installed and authenticated)
@responsibilities:
    - Fetches all closed issue numbers.
    - Executes `gh issue delete` for each issue.
@inputs: None
@outputs:
    - Deletes issues in the GitHub repository.
"""

import subprocess
import json
import sys
import shutil

def check_gh_cli():
    """Checks if the GitHub CLI tool 'gh' is installed and accessible."""
    if not shutil.which("gh"):
        print("❌ FOUT: De GitHub CLI ('gh') is niet geïnstalleerd of niet gevonden in je PATH.")
        print("   Installeer het via: https://cli.github.com/")
        return False
    return True

def get_closed_issue_numbers() -> list[int]:
    """Fetches a list of all CLOSED issue numbers from the repository."""
    print("Ophalen van alle gesloten issues...", end='', flush=True)
    try:
        # De enige wijziging is hier: --state "closed"
        command = ["gh", "issue", "list", "--state", "closed", "--json", "number"]
        result = subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8')
        issues = json.loads(result.stdout)
        issue_numbers = [issue['number'] for issue in issues]
        print(f" ✅ {len(issue_numbers)} gevonden.")
        return issue_numbers
    except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
        print(f"\n❌ FOUT: Kon gesloten issues niet ophalen: {e}")
        return []

def delete_issue(issue_number: int):
    """Deletes a single GitHub issue by its number."""
    print(f"   Issue #{issue_number} verwijderen...", end='', flush=True)
    # Gebruik 'issue delete' en de '--yes' vlag om de interactieve prompt over te slaan
    command = ["gh", "issue", "delete", str(issue_number), "--yes"]
    try:
        subprocess.run(command, check=True, capture_output=True, text=True, encoding='utf-8')
        print(" ✅")
    except subprocess.CalledProcessError as e:
        print(" ❌ Fout!")
        print(f"      Error bij verwijderen van issue: {e.stderr.strip()}")

def main():
    """Main function to fetch and delete all closed issues."""
    if not check_gh_cli():
        return

    print("🚀 Starten met het permanent verwijderen van GESLOTEN issues...")
    print("-" * 60)

    issue_numbers = get_closed_issue_numbers()

    if not issue_numbers:
        print("Geen gesloten issues gevonden om te verwijderen.")
    else:
        # User confirmation with a clear warning
        print("⚠️ WAARSCHUWING: Deze actie is permanent en kan niet ongedaan worden gemaakt.")
        confirm = input(f"Je staat op het punt om {len(issue_numbers)} GESLOTEN issues permanent te VERWIJDEREN. Weet je het zeker? (ja/nee): ")
        if confirm.lower() not in ['ja', 'y']:
            print("Actie geannuleerd.")
            return

        for number in issue_numbers:
            delete_issue(number)

    print("-" * 60)
    print("✅ Opschonen van de 'Done' lijst is voltooid.")

if __name__ == "__main__":
    main()


--- END FILE: docs/development/KanBan/clear_github_issues.py ---

--- START FILE: docs/system/0_V2_ARCHITECTURE.md ---
# S1mpleTrader V2: Architectonische Blauwdruk
**Versie:** 2.0 · **Status:** Definitief

---

## Hoofdstuk 1: Visie & Kernprincipes

* **1.1. Visie**
  
  Het creëren van één uniforme, plugin-gedreven architectuur die de volledige levenscyclus van een handelsstrategie ondersteunt: van concept & ontwikkeling, via rigoureuze backtesting en optimalisatie, naar paper trading en uiteindelijk live executie.

* **1.2. Kernprincipes**

  * **Plugin First** Alle strategische en contextuele logica wordt ingekapseld in zelfstandige, ontdekbare en onafhankelijk testbare plugins. Dit is de doorontwikkeling van het Strategy Pattern uit V1: waar V1 een set uitwisselbare “specialisten” had, formaliseert V2 dit tot een gestandaardiseerd ecosysteem.

  * **Scheiding van Zorgen (Separation of Concerns)** Strikte scheiding tussen:
    - **Strategie-logica:** `StrategyEngine` (weet **hoe** de signaal-gedreven fasen (3-6) worden uitgevoerd).
    - **Executie-omgeving:** `ExecutionEnvironment` (weet **waar** het gebeurt — backtest, paper, live).
    - **Assemblage & Bouw:** Het `Assembly Team` (`PluginRegistry`, `WorkerBuilder`, `ContextBuilder`) weet hoe plugins worden beheerd en samengesteld.
    - **Portfolio:** `Portfolio` (weet alleen **wat** de financiële staat is en fungeert als “dom” grootboek).

  * **Configuratie-gedreven (Configuration-driven)** Samenstelling, gedrag en parametrisering van de actieve plugins worden volledig gedefinieerd in **mens-leesbare `YAML`-bestanden**. De code is de motor; **configuratie is de bestuurder**.

  * **Contract-gedreven (Contract-driven)** **Pydantic**-schema’s (en, voor de UI, **TypeScript**-interfaces) definiëren de contracten voor alle configuraties, **DTO**-input/output van plugins en data-uitwisseling tussen lagen. Dit borgt voorspelbaarheid, type-veiligheid en voorkomt runtime-fouten door ongeldige data.

---

## Hoofdstuk 2: Architectuur & Componenten

De architectuur is opgebouwd uit drie strikt gescheiden lagen (Frontend → Service → Backend) en wordt aangestuurd door gespecialiseerde entrypoints (`run_web.py`, `run_supervisor.py`, `run_backtest_cli.py`). Dit hoofdstuk beschrijft de verantwoordelijkheden van elke laag en de hoofdcomponenten zoals de `StrategyOperator`, `ExecutionEnvironment`, en het `Assembly Team`.

**→ Lees de volledige uitwerking in: `docs/system/2_ARCHITECTURE.md`**

---

## Hoofdstuk 3: De Anatomie van een Plugin

Een plugin is een zelfstandige package met eigen logica, contracten (**Pydantic**-modellen), manifest (`plugin_manifest.yaml`) en metadata. Elke plugin declareert zijn `type` (bv. `regime_context`, `signal_generator`, `execution_planner`, etc.), `dependencies`, en Pydantic-gevalideerde `params`.
 
**→ Lees de volledige uitwerking in: `docs/system/3_PLUGIN_ANATOMY.md`**

---

## Hoofdstuk 4: De Quant Workflow: Van Idee tot Inzicht

De kern van de strategie-executie is een systematische, **9-fasen trechter** die een idee valideert en omzet in een `TradeProposal`. Dit hoofdstuk beschrijft elke fase, van `Regime Context` tot de `Critical Event Detector`, en verduidelijkt de rollen van de `StrategyEngine` (de motor) en het `Assembly Team` (de bouwers).

**→ Lees de volledige uitwerking in: `docs/system/4_WORKFLOW_AND_ORCHESTRATOR.md`**

---

## Hoofdstuk 5: Frontend Integratie

De frontend in V2 is de primaire ontwikkelomgeving (IDE) voor de strateeg, ontworpen om de "Bouwen -> Meten -> Leren" cyclus te maximaliseren. Dit hoofdstuk beschrijft hoe de UI zichzelf dynamisch opbouwt op basis van ontdekte plugins en hun schema's. Het detailleert de verschillende "Werkruimtes", van de Strategy Builder tot de Trade Explorer, en legt uit hoe een strikt contract tussen de Pydantic-backend en de TypeScript-frontend zorgt voor een robuuste, naadloze gebruikerservaring.

**→ Lees de volledige uitwerking in: `docs/system/5_FRONTEND_INTEGRATION.md`**

---

## Hoofdstuk 6: Robuustheid & Operationele Betrouwbaarheid

Een live trading-systeem moet veerkrachtig zijn tegen crashes, corrupte data en netwerkproblemen. Dit hoofdstuk beschrijft de drie verdedigingslinies van de architectuur: atomische schrijfacties (journaling) om de integriteit van de staat te garanderen, protocollen voor netwerkveerkracht (heartbeat, reconnect, reconciliation) en een Supervisor-model voor automatische crash recovery.

**→ Lees de volledige uitwerking in: `docs/system/6_RESILIENCE_AND_OPERATIONS.md`**

---

## Hoofdstuk 7: Ontwikkelstrategie & Tooling

De ontwikkelstrategie van V2 is gebaseerd op een snelle, visuele 'Bouwen -> Meten -> Leren' cyclus, met de Web UI als de primaire ontwikkelomgeving (IDE). Dit hoofdstuk beschrijft de workflow, van de visuele 'Strategy Builder' tot de diepgaande 'Trade Explorer'. Daarnaast worden de kern-tools behandeld, zoals de gespecialiseerde entrypoints, de gelaagde logging-aanpak en de cruciale rol van de Correlation ID voor volledige traceerbaarheid van trades.

**→ Lees de volledige uitwerking in: `docs/system/7_DEVELOPMENT_STRATEGY.md`**

---

## Hoofdstuk 8: Meta Workflows

Bovenop de executie van een enkele strategie draaien "Meta Workflows" om geavanceerde analyses uit te voeren. Dit hoofdstuk beschrijft de `OptimizationService` en `VariantTestService`, die de kern-executielogica herhaaldelijk en parallel aanroepen om systematisch de beste parameters te vinden of om de robuustheid van strategie-varianten te testen. Dit maakt complexe kwantitatieve analyse een "eerste klas burger" binnen de architectuur.

**→ Lees de volledige uitwerking in: `docs/system/8_META_WORKFLOWS.md`**

---

## Hoofdstuk 9: Coding Standaarden

Een consistente en kwalitatieve codebase is essentieel. Dit hoofdstuk beschrijft de verplichte standaarden voor het S1mpleTrader V2 project, inclusief PEP 8, volledige type hinting en Google Style Docstrings. Het behandelt de kernprincipes van contract-gedreven ontwikkeling via Pydantic, de gelaagde logging-strategie met Correlation ID voor traceability, en de eis dat alle code vergezeld wordt van tests die via Continue Integratie worden gevalideerd.

**→ Lees de volledige uitwerking in: `docs/system/9_CODING_STANDAARDS.md`**

---

## Bijlages

* **`Bijlage A: Terminologie`**: Een uitgebreid naslagwerk met kernachtige beschrijvingen van alle belangrijke concepten, componenten en patronen binnen de S1mpleTrader V2-architectuur.
* **`Bijlage B: Openstaande Vraagstukken`**: Een overzicht van bekende "onbekenden" en complexe vraagstukken die tijdens de implementatie verder onderzocht moeten worden.
--- END FILE: docs/system/0_V2_ARCHITECTURE.md ---

--- START FILE: docs/system/2_ARCHITECTURE.md ---
# 2. Architectuur & Componenten

De applicatie is opgebouwd uit drie strikt gescheiden lagen die een **eenrichtingsverkeer** van afhankelijkheden afdwingen (`Frontend → Service → Backend`). Deze structuur ontkoppelt de lagen, maximaliseert de testbaarheid en garandeert de herbruikbaarheid van de `Backend`-laag als een onafhankelijke "engine".

---
## 2.1. De Gelaagde Architectuur

* **Frontend Laag (`/frontends`)**
    Verantwoordelijk voor alle gebruikersinteractie (CLI, Web API, Web UI). Vertaalt gebruikersinput naar aanroepen van de **Service**-laag en presenteert de resultaten.

* **Service Laag (`/services`)**
    Fungeert als de **lijm** en orkestreert Backend-componenten tot complete **business workflows**. Hier leven de `StrategyOperator`, `PortfolioSupervisor` en de **Analytische Services** (`OptimizationService`, `VariantTestService`).

* **Backend Laag (`/backend`)**
    De **engine** van de applicatie. Bevat de `AbstractPluginFactory specialisten`, het `Portfolio` en de `ExecutionEnvironments`. Deze laag is volledig onafhankelijk en ontworpen als een **library**.

* **ASCII-overzicht**
    ```
    +-------------------------------------------------------------+
    |  Frontend (CLI, Web API, Web UI)                            |
    +--------------------------+----------------------------------+
                               |
                               v
    +--------------------------+----------------------------------+
    |  Service (Orchestratie & Business Workflows)                |
    |  - PortfolioSupervisor, StrategyOperator,                   |
    |     OptimizationService, VariantTestService                 |
    +--------------------------+----------------------------------+
                               |
                               v
    +--------------------------+----------------------------------+
    |  Backend (Engine)                                           |
    |  - Portfolio, ExecutionEnvironments, Assembly Workers       |
    +-------------------------------------------------------------+
    ```
   
---

## 2.2. Visueel diagram (uitwerking)

+---------------------------------------------------------------------------------------------------------+
|                                    GEBRUIKER (Via Web UI / API)                                         |
|    (Start runs, analyseert resultaten, beheert portfolio)                                               |
+-----------------------------------------------------+---------------------------------------------------+
                                                      |
           +------------------------------------------+------------------------------------------+
           |                                                                                     |
           v                                                                                     v
+----------+----------------------------------+  +------------------------------------------------+------------+
|  OPERATIONELE HIËRARCHIE (SERVICE LAAG)     |  |          R&D / OFFLINE ANALYSE (META WORKFLOWS)             |
|  (Live / Paper Trading)                     |  |                                                             |
|                                             |  |  +---------------------------+                              |
|  +---------------------------------------+  |  |  |   OptimizationService /   |                              |
|  |       PortfolioSupervisor             |  |  |  |    VariantTestService     |                              |
|  |       (De "Fondsbeheerder")           |  |  |  +------------+--------------+                              |
|  +------------------+--------------------+  |  |               | (Analyseert configuratiepad)                |
|                     ^ (5. Events/Directives)|  |               |                                             |
|                     | (naar boven)          |  |  +------------+------------------------------------------+  |
|                     |                       |  |  | Scenario A (Micro/Meso)      |   | Scenario B (Macro) |  |
|  (6. Management Commando's)                 |  |  v                                  v                       |
|  (naar beneden)     v                       |  |  +-------------------------------+  +--------------------+  |
|  +------------------+--------------------+  |  |  | Simuleert 1x StrategyOperator |  | Simuleert 1x       |  |
|  |  StrategyOperator (Specialist) A      |  |  |  +-------------------------------+  | PortfolioSupervisor|  |
|  |  (Voorheen "WorkflowService")         |  |  |                                     +--------------------+  |
|  +---------------------------------------+  |  |                                                             |
|                                             |  +------------------------------------------------+------------+
|  +---------------------------------------+  |
|  |  StrategyOperator (Specialist) B      |  |                      Λ
|  |  (Draait parallel)                    |  |                      |
|  +---------------------------------------+  |                      | (Gebruikt dezelfde Backend componenten)
|                                             |                      |
+--------------------------------------------+----------------------+-------------------------------------+
                                             | (Roept Backend aan)
                                             v
+--------------------------------------------+-------------------------------------------------------------+
|                                        DE FUNDERING (BACKEND LAAG)                                       |
|                    (De herbruikbare, agnostische "Motor" & "Gereedschapskist")                           |
|                                                                                                          |
|  - StrategyEngine (De 9-fasen motor)            - AssemblyTeam (De bouwers: Registry, Builder)           |
|  - ExecutionEnvironments (Backtest/Live/Paper)  - Portfolio (De "domme" boekhouder)                      |
|  - Alle DTO's, Interfaces & Utilities           - DirectiveFlattener (De vertaler)                       |
|                                                                                                          |
+----------------------------------------------------------------------------------------------------------+


+--------------------------------------------------------------------------------------------------+
|                                         FRONTEND LAAG                                            |
|                  (Web UI / CLI - De "Marketing & Communicatie" afdeling)                         |
└─────────────────────────────────────────────┬────────────────────────────────────────────────────┘
                                              │
           ┌──────────────────────────────────┴──────────────────────────────────┐
           │ Roept de juiste specialist aan voor de gevraagde dienst...          │
           v                                                                     v
+----------┴---------------------------------------------------------------------┴-----------------+
|                                          SERVICE LAAG                                            |
| (De "Gereedschapskist" met onafhankelijke specialisten, elk met een eigen taak)                  |
| ┌───────────────────────────────┐                                                                |
| │   Configuratie & Management   │                                                                |
| │      (De Archivarissen)       │                                                                |
| │-------------------------------|                                                                |
| │ - BlueprintQueryService       │                                                                |
| │ - BlueprintEditorService      │                                                                |
| │ - PluginEnrollmentService     │                                                                |
| └───────────────────────────────┘                                                                |
| ┌──────────────────────────┐      ┌───────────────────────────────┐                              |
| │   Analytische Services   │      │    WORKFLOW SERVICES          │                              |
| │     (De Onderzoekers)    │      │  (De Fabrieksmanagers)        │                              |
| │--------------------------│      │-------------------------------│                              |
| │ - OptimizationService    ├─────>│ - BacktestService             │                              |
| │ - VariantTestService     │      │ - TradingService (paper/live) │                              |
| └───────────┬──────────────┘      └────────────┬──────────────────┘                              |
|             │(roept herhaaldelijk aan)         │ 1. Ontvangt AppConfig                           |
|             │                                  │ 2. Bouwt de Environment                         |
|             └────────────────────────────────> │ 3. Instantieert                                 |
|                                                │    PortfolioSupervisor                          |
|                                                └────────────┬────────────┘                       |
|                                                             │                                    |
|                                                             v                                    |
|                           ┌─────────────────────────────────────────────────────────┐            |
|                           │                  OPERATIONELE SERVICES                  │            |
|                           │                      (De Operators)                     │            |
|                           │---------------------------------------------------------│            |
|                           │                PortfolioSupervisor                      │            |
|                           │        (De Ploegleider, stuurt de werkvloer aan)        │            |
|                           └─────────────────────────────┬───────────────────────────┘            |
|                                                         │ Managet een of meerdere...             |
|                                                         v                                        |
|                           ┌─────────────────────────────┴───────────────────────────┐            |
|                           │                   StrategyOperator(s)                   │            |
|                           │          (De Specialist, voert de 6 Fases uit)          │            |
|                           └─────────────────────────────────────────────────────────┘            |
+------------------------------------------------------------------------------------|-------------+
                                                                                     │
                  ┌───────────────────────────────────────────────────────────────────────────────┤
                  │ (De Operationele Services krijgen de Environment geïnjecteerd en gebruiken de │
                  │  Backend-componenten om hun taak uit te voeren)                               │
                  v                                                                               v
+-----------------┴------------------------------------------[ BACKEND LAAG (DE "ENGINE") ]-------┴-------------+
|                                                                                                               |
|   ┌──────────────────────┐   wordt gebruikt door   ┌──────────────────────┐                                   |
|   │     Assembly Team    │<────────────────────────┤   StrategyOperator   │                                   |
|   │ (Plugin Specialisten)│                         └──────────────────────┘                                   |
|   └──────────┬───────────┘                                                                                    |
|              │ Gebruikt                                                                                       |
|              v                                                                                                |
|   ┌──────────┴──────────┐                                                                                     |
|   │       Plugins       │                                                                                     |
|   └─────────────────────┘                                                                                     |
|                                                                                                               |
|   ┌──────────────────────┐   wordt gelezen door   ┌──────────────────────┐                                    |
|   │      Portfolio       │<───────────────────────┤  PortfolioSupervisor │                                    |
|   │   (Het Grootboek)    │                        └──────────────────────┘                                    |
|   └──────────▲───────────┘                                                                                    |
|              │ Werkt bij                                                                                      |
|   ┌──────────┴───────────┐                                                                                    |
|   │ ExecutionEnvironment │ (Bevat de ExecutionHandler die het Portfolio bijwerkt)                             |
|   │    (Het Chassis)     │                                                                                    |
|   └──────────────────────┘                                                                                    |
|                                                                                                               |
+---------------------------------------------------------------------------------------------------------------+
---
## 2.3. Gespecialiseerde Entrypoints

De V2-architectuur stapt af van één generieke `main.py` en introduceert doelgerichte starters in de project root:

* **`run_web.py`**: Start de Web UI en de bijbehorende API. Dit is de primaire interface voor strategie-ontwikkeling, analyse en monitoring.
* **`run_supervisor.py`**: Start de live trading-omgeving op een robuuste, minimalistische manier (de "aan"-knop). Deze entrypoint is ontworpen om de `PortfolioSupervisor` te starten voor het managen van een live portfolio.
* **`run_backtest_cli.py`**: Dient als "headless" entrypoint voor geautomatiseerde taken. Deze kan elke service aanroepen, van een simpele `StrategyOperator` tot een complexe `OptimizationService` voor CI/CD-workflows.

---
## 2.4. Componenten in Detail: De Service Laag Hiërarchie

De Service-laag is geen verzameling losse componenten, maar een gestructureerde hiërarchie van "Operators" en "Services" met duidelijk afgebakende verantwoordelijkheden. De `ExecutionEnvironment` fungeert hierbij als de cruciale schakelaar die bepaalt of een operator in een Backtest-, Paper- of Live-modus draait.

#### **2.4.1. Niveau 1: De StrategyOperator (De Specialist)**
* **Laag:** Service
* **Verantwoordelijkheid:** Het uitvoeren van één enkele strategie (de 6-fasen trechter) voor één instrument. Dit is wat voorheen de `StrategyOrchestrator` werd genoemd; de nieuwe naam benadrukt zijn actieve, operationele rol.
* **Proces:** De `StrategyOperator` is de "regisseur" van de 6-fasen trechter. Hij is volledig agnostisch over de omgeving; hij ontvangt een geïnitialiseerde `ExecutionEnvironment` en weet niet of hij een backtest of een live trade uitvoert.

#### **2.4.2. Niveau 2: De PortfolioSupervisor (De Ploegleider)**
* **Laag:** Service
* **Verantwoordelijkheid:** Het managen van de levenscyclus en het risico van een portfolio van meerdere, gelijktijdig actieve `StrategyOperator`-instanties.
* **Proces:**
  * Leest een `portfolio_blueprint.yaml` die definieert welke strategieën (en dus `StrategyOperators`) actief zijn.
  * Ontvangt "trade-voorstellen" van de individuele `StrategyOperators`.
  * Past overkoepelend, portfolio-breed risicomanagement toe (bv. "maximale totale exposure").
  * Alleen goedgekeurde trade-voorstellen worden doorgestuurd naar de `ExecutionHandler` van de gedeelde `ExecutionEnvironment`.
* **Belang:** Deze component kan, net als elke andere operator, worden uitgevoerd in een `BacktestEnvironment` om een volledige, complexe portfolio-strategie tegen historische data te testen.

#### **2.4.3. Niveau 3: Analytische Services (De Onderzoekers)**
* **Laag:** Service (bv. `services/optimization_service.py`)
* **Verantwoordelijkheid:** Het uitvoeren van grootschalige, analytische experimenten om kwantitatieve vragen te beantwoorden.
* **Voorbeelden en Proces:**
  * De **`OptimizationService`** genereert een grote set van configuratie-varianten. Via een volledig gekwalificeerd pad (bv. `"workforce.structural_context.my_plugin.params.length"`) weet het precies welke parameter het moet aanpassen, of dit nu een diepe plugin-parameter is of een hoog-niveau risico-parameter in de `PortfolioSupervisor`.
  * De **`VariantTestService`** voert een kleine, gedefinieerde set van varianten uit om de prestaties direct te vergelijken.
* **Executie:** Deze services zijn de enige componenten die de `ParallelRunService` aanroepen om hun experimenten (die een `StrategyOperator` of zelfs een hele `PortfolioSupervisor` kunnen aanroepen) efficiënt en parallel uit te voeren.

#### **2.4.4. De ExecutionEnvironment (Het Chassis / De Wereld)**
* **Laag:** Backend
* **Verantwoordelijkheid:** Definieert de "wereld" (Backtest, Paper, Live) waarin de strategie opereert. Het ontkoppelt de strategie-logica volledig van de data- en executiebronnen.
* **Componenten:**
  * **`DataSource`**: Levert marktdata (uit een CSV-bestand of een live WebSocket).
  * **`Clock`**: Genereert de "hartslag" van het systeem.
  * **`ExecutionHandler`**: Voert `Trade` DTO's uit.

#### **2.4.5. Het Portfolio (Het Grootboek)**
* **Laag:** Backend (`backend/core/portfolio.py`)
* **Verantwoordelijkheid:** Het "domme" grootboek. Managet kapitaal, posities en openstaande orders. Het is volledig agnostisch over de omgeving en wordt geïnitialiseerd met simpele waarden, niet met een config-object.
* **Proces:**
    * Houdt de cash-balans en de totale waarde van het portfolio bij.
    * Registreert openstaande orders en actieve posities per `correlation_id`.
* **Output:** Een continu bijgewerkte equity curve en een lijst van `ClosedTrade` DTO's.

#### **2.4.6. Assembly Team (`PluginRegistry`, `WorkerBuilder`, `ContextBuilder`)**
* **Laag:** Backend
* **Verantwoordelijkheid:** Het "technische projectbureau". Bestaat uit specialisten die plugins ontdekken, valideren, bouwen en de context-pijplijn (Fase 1 & 2) uitvoeren.

---
## 2.5. Design Principles & Kernconcepten

De architectuur is gebouwd op de **SOLID**-principes en een aantal kern-ontwerppatronen die de vier kernprincipes (Plugin First, Scheiding van Zorgen, Configuratie-gedreven, Contract-gedreven) tot leven brengen.

### **De Synergie: Configuratie- & Contract-gedreven Executie**

Het meest krachtige concept van V2 is de combinatie van configuratie- en contract-gedreven werken. De code is de motor; **de configuratie is de bestuurder, en de contracten zijn de verkeersregels die zorgen dat de bestuurder binnen de lijntjes blijft.**

* **Configuratie-gedreven:** De *volledige samenstelling* van een strategie (welke plugins, in welke volgorde, met welke parameters) wordt gedefinieerd in een `YAML`-bestand. Dit maakt het mogelijk om strategieën drastisch te wijzigen zonder één regel code aan te passen.

* **Contract-gedreven:** Elk stukje configuratie en data wordt gevalideerd door een strikt **Pydantic-schema**. Dit werkt op twee niveaus:
  1.  **Algemene Schema's:** De hoofdstructuur van een `run_blueprint.yaml` wordt gevalideerd door een algemeen `app_schema.py`. Dit contract dwingt af dat er bijvoorbeeld altijd een `environment` en een `strategy_pipeline` sectie aanwezig is.
  2.  **Plugin-Specifieke Schema's:** De parameters voor een specifieke plugin (bv. de `length` van een `EMA`-indicator) worden gevalideerd door de Pydantic-klasse in de `schema.py` van *die ene plugin*.

Bij het starten van een run, leest de applicatie het `YAML`-bestand en bouwt een gevalideerd `AppConfig`-object. Als een parameter ontbreekt, een verkeerd type heeft, of een plugin wordt aangeroepen die niet bestaat, faalt de applicatie *onmiddellijk* met een duidelijke foutmelding. Dit voorkomt onvoorspelbare runtime-fouten en maakt het systeem extreem robuust en voorspelbaar.

### **SOLID in de Praktijk**
* **SRP (Single Responsibility Principle):** Elke klasse heeft één duidelijke taak.
  * ***V2 voorbeeld:*** Een `FVGEntryDetector`-plugin detecteert alleen Fair Value Gaps. Het bepalen van de positiegrootte of het analyseren van de marktstructuur gebeurt in aparte `position_sizer`- of context-plugins.

* **OCP (Open/Closed Principle):** Uitbreidbaar zonder bestaande code te wijzigen.
    * ***V2 voorbeeld:*** Wil je een nieuwe exit-strategie toevoegen? Je maakt simpelweg een nieuwe `exit_planner`-plugin; de `StrategyEngine` hoeft hiervoor niet aangepast te worden.

* **DIP (Dependency Inversion Principle):** Hoge-level modules hangen af van abstracties.
    * ***V2 voorbeeld:*** De `BacktestService` (Service-laag) hangt af van de `BaseEnvironment`-interface, niet van de specifieke `BacktestEnvironment`. Hierdoor zijn de services volledig herbruikbaar in elke context.

### **Kernpatronen**
* **Factory Pattern:** Het `Assembly Team` (met `WorkerBuilder`) centraliseert het ontdekken, valideren en creëren van alle plugins.
* **Strategy Pattern:** De "Plugin First"-benadering is de puurste vorm van dit patroon. Elke plugin is een uitwisselbare strategie voor een specifieke taak.
* **DTO’s (Data Transfer Objects):** Pydantic-modellen (`Signal`, `TradePlan`, `ClosedTrade`) zorgen voor een voorspelbare en type-veilige dataflow tussen alle componenten.
--- END FILE: docs/system/2_ARCHITECTURE.md ---

--- START FILE: docs/system/3_PLUGIN_ANATOMY.md ---
# 3. De Anatomie van een V2 Plugin

Dit document beschrijft de gedetailleerde structuur en de technische keuzes achter de plugins in de S1mpleTrader V2 architectuur. Plugins zijn de specialistische, onafhankelijke en testbare bouwstenen van elke strategie.

---
## 3.1. Fundamentele Mappenstructuur

Elke plugin is een opzichzelfstaande Python package. Deze structuur garandeert dat logica, contracten en metadata altijd bij elkaar blijven, wat essentieel is voor het "Plugin First" principe.

Een typische plugin heeft de volgende structuur:

plugins/[plugin_naam]/
├── plugin_manifest.yaml  # De ID-kaart (wie ben ik?)
├── worker.py             # De Logica (wat doe ik?)
├── schema.py             # Het Contract (wat heb ik nodig?)
└── state.json            # (Optioneel) Het Geheugen (wat was mijn vorige staat?)


* `plugin_manifest.yaml`: De "ID-kaart" van de plugin. Dit bestand maakt de plugin vindbaar en begrijpelijk voor de `AbstractPluginFactory`.
* `worker.py`: Bevat de Python-klasse met de daadwerkelijke businesslogica van de plugin.
* `schema.py`: Bevat het Pydantic-model dat de structuur en validatieregels voor de configuratieparameters van de plugin definieert.
* `state.json`: Dit bestand is **optioneel** en wordt alleen gebruikt door 'stateful' plugins (zoals een Grid Trading manager die zijn openstaande orders moet onthouden). De `StrategyOrchestrator` is verantwoordelijk voor het aanroepen van `load_state()` en `save_state()` op de worker, maar de worker zelf beheert de inhoud van dit bestand.

---
## 3.2. Formaat Keuzes: `YAML` vs. `JSON`

De keuze voor een dataformaat hangt af van de primaire gebruiker: **een mens of een machine**. We hanteren daarom een hybride model om zowel leesbaarheid als betrouwbaarheid te maximaliseren.

* **`YAML` voor Menselijke Configuratie**
    * **Toepassing:** `plugin_manifest.yaml` en alle door de gebruiker geschreven `run_config.yaml`-bestanden.
    * **Waarom:** De superieure leesbaarheid, de mogelijkheid om commentaar toe te voegen, en de flexibelere syntax zijn essentieel voor ontwikkelaars en strategen die deze bestanden handmatig schrijven en onderhouden.

* **`JSON` voor Machine-Data**
    * **Toepassing:** Alle machine-gegenereerde data, zoals API-responses, `state.json`-bestanden, en gestructureerde logs (`run.log.json`).
    * **Waarom:** De strikte syntax en universele portabiliteit maken `JSON` de betrouwbare standaard voor communicatie tussen systemen (bv. tussen de Python backend en een TypeScript frontend) en voor het opslaan van gestructureerde data waar absolute betrouwbaarheid vereist is.

---
## 3.3. Het Manifest: De Zelfbeschrijvende ID-kaart

Het `plugin_manifest.yaml` is de kern van het "plugin discovery" mechanisme. Het stelt de `AbstractPluginFactory` in staat om een plugin volledig te begrijpen, te valideren en correct te categoriseren **zonder de Python-code te hoeven inspecteren**.

Dit manifest is een contract dat de volgende cruciale informatie vastlegt:

* **`name`**: De unieke, machine-leesbare naam van de plugin (bv. `market_structure_detector`).
* **`version`**: Semantische versie (bv. "1.0.1") om dependency management mogelijk te maken.
* **`type`**: De belangrijkste categorie-aanduiding. Dit veld bepaalt in welke van de workflow-fasen van de `StrategyOrchestrator` de plugin thuishoort. Mogelijke waarden zijn:
    * `regime_context`
    * `structural_context`
    * `signal_generator`
    * `signal_refiner`
    * `execution_planner`
    * `exit_planner`
    * `size_planner`
    * `portfolio_overlay`
* **`entry_class`**: De exacte naam van de hoofdklasse in het `worker.py` bestand (bv. `MarketStructureDetector`).
* **`schema_path`**: Het pad naar het Python-bestand dat het Pydantic-schema bevat (meestal `schema.py`).
* **`params_class`**: De exacte naam van de Pydantic-klasse in het `schema.py` bestand (bv. `MarketStructureParams`).
* **`stateful`**: Een boolean (`true` / `false`) die aangeeft of de plugin een `state.json`-bestand gebruikt.
* **`dependencies`**: Een lijst van datavelden die de plugin verwacht als input. Voor een `ContextWorker` is dit een lijst van kolomnamen (bv. `['high', 'low', 'close']`) die aanwezig moeten zijn in de DataFrame. De `AbstractPluginFactory` valideert hierop voordat de plugin wordt uitgevoerd.

## 3.4. De Worker & het BaseWorker Raamwerk

De `worker.py` bevat de daadwerkelijke logica. Om de ontwikkeling te versnellen en de consistentie te borgen, biedt de architectuur een set aan basisklassen in `backend/core/base_worker.py`.

* **Doel:** Het automatiseren van de complexe, geneste DTO-creatie en het doorgeven van de `correlation_id`.
* **Voorbeeld (`BaseEntryPlanner`):**
    ```python
    class MyEntryPlanner(BaseEntryPlanner):
        def _process(self, input_dto: Signal, correlation_id: UUID, context: TradingContext) -> Optional[Dict[str, Any]]:
            # Developer focust alleen op de logica
            entry_price = ... # bereken de entry prijs
            return {"entry_price": entry_price}
    ```
De `BaseEntryPlanner` handelt automatisch de creatie van de `EntrySignal` DTO af, nest de oorspronkelijke `Signal` erin, en zorgt dat de `correlation_id` correct wordt doorgegeven. Dit maakt de plugin-code extreem schoon en gefocust.
--- END FILE: docs/system/3_PLUGIN_ANATOMY.md ---

--- START FILE: docs/system/4_WORKFLOW_AND_ORCHESTRATOR.md ---
# 4. De Quant Workflow & Orkestratie

Dit document beschrijft de volledige "data-assemblagelijn" van de S1mpleTrader V2 architectuur. De kern is een gelaagde workflow die een handelsidee systematisch transformeert, valideert en omzet in een uitvoerbaar handelsplan.

---
## 4.1. De Workflow Trechter: Een Praktijkvoorbeeld

       ┌───────────────────────────────────────────┐
       │        RUWE DATAFRAME (OHLCV)             │
       └────────────────────┬──────────────────────┘
                            │
                            v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 1: REGIME CONTEXT (De "Weerman")                            │
│ Plugin: regime_context                                           │
│ Taak:   Voegt macro-context toe (bv. regime='trending').         │
└────────────────────┬─────────────────────────────────────────────┘
│
v
┌───────────────────────────────────────────┐
│   VERRIJKTE DATAFRAME (enriched_df)       │
└────────────────────┬──────────────────────┘
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 2: STRUCTURELE CONTEXT (De "Cartograaf")                    │
│ Plugin: structural_context                                       │
│ Taak:   Voegt micro-context toe (bv. is_mss, support_level).     │
└────────────────────┬─────────────────────────────────────────────┘
│
v
┌───────────────────────────────────────────┐
│   FINALE ENRICHED DATAFRAME               │
└────────────────────┬──────────────────────┘
│ (Start StrategyEngine Loop)
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 3: SIGNAAL GENERATIE (De "Verkenner")                       │
│ Plugin: signal_generator                                         │
│ Taak:   Detecteert een specifieke, actiegerichte gebeurtenis.    │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: Signal
│ -------------------------------
│ { correlation_id, timestamp, asset,
│   direction, signal_type }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 4: SIGNAAL VERFIJNING (De "Kwaliteitscontroleur")           │
│ Plugin: signal_refiner                                           │
│ Taak:   Keurt Signal goed of af op basis van secundaire criteria.│
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: Signal (of None)
│ -------------------------------
│ { ... (inhoud blijft gelijk) }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 5: ENTRY PLANNING (De "Timing Expert")                      │
│ Plugin: entry_planner                                            │
│ Taak:   Bepaalt de precieze entry-prijs.                         │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: EntrySignal
│ -------------------------------
│ { correlation_id (gepromoot),
│   signal: Signal (genest),
│   + entry_price }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 6: EXIT PLANNING (De "Strateeg")                            │
│ Plugin: exit_planner                                             │
│ Taak:   Berekent de initiële stop-loss en take-profit.           │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: RiskDefinedSignal
│ -------------------------------
│ { correlation_id (gepromoot),
│   entry_signal: EntrySignal (genest),
│   + sl_price, tp_price }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 7: SIZE PLANNING (De "Logistiek Manager")                   │
│ Plugin: size_planner                                             │
│ Taak:   Berekent de definitieve positiegrootte.                  │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: TradePlan
│ -------------------------------
│ { correlation_id (gepromoot),
│   risk_defined_signal: RiskDefinedSignal (genest),
│   + position_value_quote, position_size_asset }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 8: ORDER ROUTING (De "Verkeersleider")                      │
│ Plugin: order_router                                             │
│ Taak:   Vertaalt het plan naar technische executie-instructies.  │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: RoutedTradePlan
│ -------------------------------
│ { correlation_id (gepromoot),
│   trade_plan: TradePlan (genest),
│   + order_type, time_in_force, ... }
│
v
┌──────────────────────────────────────────────────────────────────┐
│ Fase 9: CRITICAL EVENT DETECTION (De "Waakhond")                 │
│ Plugin: critical_event_detector                                  │
│ Taak:   Detecteert systeem-brede risico's (bv. max drawdown).    │
└────────────────────┬─────────────────────────────────────────────┘
│
│ DTO: CriticalEvent
│ -------------------------------
│ { correlation_id, event_type, timestamp }
│
v
┌───────────────────────────────────────────┐
│        FINAAL TRADEPROPOSAL DTO           │
│ { routed_trade_plan?, critical_event? }   │
└────────────────────┬──────────────────────┘
│
v
[ Naar de Workflow Service & ExecutionHandler ]

Elk handelsidee wordt systematisch gevalideerd door een vaste, logische trechter. We volgen een concreet voorbeeld: een **"Market Structure Shift + FVG Entry"** strategie.

#### **Fase 1: Regime Context (De "Weerman")**
* **Doel:** Wat is de algemene "weersverwachting" van de markt? Deze fase classificeert de marktomstandigheid zonder data weg te gooien.
* **Input:** De ruwe `DataFrame` met OHLCV-data.
* **Proces (voorbeeld):** Een `ADXContext`-plugin (`type: regime_context`) berekent de ADX-indicator en voegt een nieuwe kolom `regime` toe. Deze kolom krijgt de waarde 'trending' als `ADX > 25` en 'ranging' als `ADX < 25`.
* **Output:** Een verrijkte `DataFrame`. Er wordt geen data verwijderd; er wordt alleen een contextuele "tag" toegevoegd aan elke rij.

#### **Fase 2: Structurele Context (De "Cartograaf")**
* **Doel:** De markt "leesbaar" maken. Waar is de trend en wat zijn de belangrijke zones?
* **Input:** De verrijkte `DataFrame` uit Fase 1.
* **Proces (voorbeeld):** Een `MarketStructureDetector`-plugin (`type: structural_context`) analyseert de prijs en voegt twee nieuwe kolommen toe: `trend_direction` (met waarden als `bullish` of `bearish`) en `is_mss` (een `True`/`False` vlag op de candle waar een Market Structure Shift plaatsvindt).
* **Output:** De finale `enriched_df`. We hebben nu "slimme" data met meerdere lagen context, klaar voor de `StrategyEngine`.

#### **Fase 3: Signaal Generatie (De "Verkenner")**
* **Doel:** Waar is de precieze, actiegerichte trigger? We zoeken naar een Fair Value Gap (FVG) ná een Market Structure Shift.
* **Input:** De `enriched_df` (via het `TradingContext` object).
* **Proces (voorbeeld):** Een `FVGEntryDetector`-plugin (`type: signal_generator`) scant de data. Wanneer het een rij tegenkomt waar `is_mss` `True` is, begint het te zoeken naar een FVG. Als het er een vindt, genereert het een signaal.
* **Output:** Een **`Signal` DTO**. Dit object krijgt een unieke `correlation_id` (UUID) en bevat de essentie: `{asset: 'BTC/EUR', timestamp: '...', direction: 'long', signal_type: 'fvg_entry'}`.

#### **Fase 4: Signaal Verfijning (De "Kwaliteitscontroleur")**
* **Doel:** Is er bevestiging voor het signaal? We willen volume zien bij de FVG-entry.
* **Input:** Het `Signal` DTO en het `TradingContext`.
* **Proces (voorbeeld):** Een `VolumeSpikeRefiner`-plugin (`type: signal_refiner`) controleert het volume op de timestamp van het `Signal`. Als het volume te laag is, wordt het signaal afgekeurd.
* **Output:** Het **gevalideerde `Signal` DTO** of `None`. De `correlation_id` blijft behouden.

#### **Fase 5: Entry Planning (De "Timing Expert")**
* **Doel:** Wat is de precieze entry-prijs voor ons goedgekeurde signaal?
* **Input:** Het gevalideerde `Signal` DTO.
* **Proces (voorbeeld):** Een `LimitEntryPlanner`-plugin (`type: entry_planner`) bepaalt dat de entry een limietorder moet zijn op de 50% retracement van de FVG.
* **Output:** Een **`EntrySignal` DTO**. Dit DTO *nest* het originele `Signal` en verrijkt het met `{ entry_price: 34500.50 }`. De `correlation_id` wordt gepromoot naar het top-level voor gemakkelijke toegang.

#### **Fase 6: Exit Planning (De "Strateeg")**
* **Doel:** Wat is het initiële plan voor risico- en winstmanagement?
* **Input:** Het `EntrySignal` DTO.
* **Proces (voorbeeld):** Een `LiquidityTargetExit`-plugin (`type: exit_planner`) plaatst de stop-loss onder de laatste swing low en de take-profit op de volgende major liquidity high.
* **Output:** Een **`RiskDefinedSignal` DTO**. Nest het `EntrySignal` en voegt `{ sl_price: 34200.0, tp_price: 35100.0 }` toe.

#### **Fase 7: Size Planning (De "Logistiek Manager")**
* **Doel:** Wat is de definitieve positiegrootte, gegeven ons risicoplan en kapitaal?
* **Input:** Het `RiskDefinedSignal` DTO en het `Portfolio` (via `TradingContext`).
* **Proces (voorbeeld):** Een `FixedRiskSizer`-plugin (`type: size_planner`) berekent de positiegrootte zodat het risico (`entry_price - sl_price`) exact 1% van de totale equity van het portfolio is.
* **Output:** Een **`TradePlan` DTO**. Dit DTO nest het `RiskDefinedSignal` en bevat de finale, berekende `{ position_value_quote: 1000.0, position_size_asset: 0.0289 }`. Dit is het complete *strategische* plan.

#### **Fase 8: Order Routing (De "Verkeersleider")**
* **Doel:** Hoe moet dit strategische plan *technisch* worden uitgevoerd?
* **Input:** Het `TradePlan` DTO.
* **Proces (voorbeeld):** Een `DefaultRouter`-plugin (`type: order_router`) vertaalt het plan naar concrete order-instructies.
* **Output:** Een **`RoutedTradePlan` DTO**. Dit nest het `TradePlan` en voegt de *tactische* executie-instructies toe, zoals `{ order_type: 'limit', time_in_force: 'GTC' }`. Dit is de definitieve opdracht voor de `ExecutionHandler`.

#### **Fase 9: Critical Event Detection (De "Waakhond")**
* **Doel:** Zijn er systeem-brede risico's die onmiddellijke actie vereisen, los van nieuwe trades?
* **Input:** De volledige `TradingContext` en de lijst van `RoutedTradePlan`'s.
* **Proces (voorbeeld):** Een `MaxDrawdownDetector`-plugin (`type: critical_event_detector`) controleert de equity curve van het `Portfolio`. Als de drawdown een drempel overschrijdt, genereert het een event.
* **Output:** Een **`CriticalEvent` DTO** (bv. `{ event_type: 'MAX_DRAWDOWN_BREACHED' }`) of `None`.

**Finale Output: Het `TradeProposal` DTO**
De `StrategyEngine` verpakt de outputs van Fase 8 en 9 in één enkel `TradeProposal`-object. Dit object wordt teruggestuurd naar de `Workflow Service`, die het interpreteert en de juiste acties onderneemt (bv. de `RoutedTradePlan` naar de `ExecutionHandler` sturen of de run stoppen bij een `CriticalEvent`).

---
## 4.2. Rolverdeling: De Manager en de Motor

### **De Workflow Service (bv. `BacktestService`) (De Manager)**
Een service zoals de `BacktestService` is de **"manager"** van een enkele run. Hij is de eigenaar van de setup-logica en bereidt de fabriek voor.

* **Plek:** `Service`-laag.
* **Verantwoordelijkheid:** Het end-to-end voorbereiden en starten van een strategie-executie.

#### **Procesflow van de Service:**
1.  **Initialisatie:** Ontvangt de `AppConfig` van de frontend of CLI.
2.  **Bouwfase:** Instantieert alle benodigde, langlevende backend-componenten:
    * De `ExecutionEnvironment` (bv. `BacktestEnvironment`).
    * Het `Portfolio` (geïnitialiseerd met simpele waarden, niet de config).
    * Het `Assembly Team` (`PluginRegistry`, `WorkerBuilder`, `ContextBuilder`).
3.  **Assemblage:** Gebruikt het `Assembly Team` om de `StrategyEngine` te bouwen, en injecteert een "toolbox" met alle benodigde, geïnstantieerde plugin-workers.
4.  **Context Preparatie (Fase 1 & 2):** Roept de `ContextBuilder` aan om de `enriched_df` te genereren.
5.  **Startschot:** Creëert het finale `TradingContext` DTO (met de `enriched_df`, `Portfolio`, etc.) en roept de `run()`-methode van de `StrategyEngine` aan, waarmee de controle wordt overgedragen.

### **De `StrategyEngine` (De Motor)**
De `StrategyEngine` is de **"motor"** van de executie-loop (Fase 3-9). Hij weet niets van de setup, maar is een expert in het efficiënt doorlopen van de signaal-pijplijn.

* **Plek:** `Backend`-laag.
* **Verantwoordelijkheid:** Het uitvoeren van de event-loop, gestuurd door de `Clock`, en het doorlopen van de DTO-trechter van `Signal` tot `TradeProposal`.
* **Procesflow van de Engine:**
    1.  **Start:** De `run()`-methode wordt aangeroepen door de `Service`.
    2.  **Event Loop:** Voor elke `tick` van de `Clock`:
        * Vraagt alle `signal_generator` plugins om een lijst van `Signal` DTO's.
        * Voor elk `Signal`, leidt het door de volledige trechter (Fase 4-8), waarbij elke stap de DTO verder nest en verrijkt via de `BaseWorker`-automatisering.
        * Roept de `critical_event_detector` plugins aan (Fase 9).
        * `yield` elk `TradeProposal` terug naar de `Service`.

### **Het `Assembly Team` (De Technische Projectmanager)**
Het `Assembly Team` (`PluginRegistry`, `WorkerBuilder`, `ContextBuilder`) is het **"technische projectbureau"**. Het weet niets over de fasen, maar is expert in het beheren en bouwen van plugins.

* **Plek:** `Backend`-laag.
* **Verantwoordelijkheid:** Het ontdekken, bouwen en technisch orkestreren van de context-pijplijn.
* **Taken in Detail:**
    * **Plugin Discovery:** Scant de `plugins/`-map en bouwt het `PluginRegistry`.
    * **Worker Constructie:** Bouwt op aanvraag van de `Workflow Service` alle benodigde, gevalideerde plugin-instanties.
    * **Orkestratie van Context:** Voert de `context_pipeline` (Fase 1 & 2) uit.

---
## 4.3. De Feedback Loops: Technisch vs. Strategisch

De architectuur faciliteert twee cruciale cycli:

1.  **De Technische Feedback Loop (Real-time):** Dit gebeurt ***binnen*** **een run**. De staat van het `Portfolio` (het "domme" grootboek) wordt via het `TradingContext` object gebruikt als input voor plugins in latere fasen (bv. de `SizePlanner` in Fase 7).
2.  **De Strategische "Supercharged" Ontwikkelcyclus (Human-in-the-loop):** Dit is de cyclus die *jij* als strateeg doorloopt ***tussen*** **de runs**, volgens het **"Bouwen -> Meten -> Leren"** principe. Je analyseert de resultaten van een backtest in de Web UI (**Meten**), ontdekt een zwakte (**Leren**), past de `YAML`-configuratie aan in de Strategy Builder (**Bouwen**) en start direct een nieuwe run.
--- END FILE: docs/system/4_WORKFLOW_AND_ORCHESTRATOR.md ---

--- START FILE: docs/system/5_FRONTEND_INTEGRATION.md ---
# 5. Frontend Integratie: De UI als Ontwikkelomgeving

Dit document beschrijft de volledige gebruikersworkflow en de frontend-architectuur die nodig is om de "supercharged" V2-ervaring te realiseren. Het is de directe vertaling van de User Story Map naar een concreet, technisch plan.

---
## 5.1. De Filosofie: De UI als IDE

De kern van de V2-frontendstrategie is een paradigmaverschuiving: de web-UI is niet langer een simpele presentatielaag, maar de **primaire, geïntegreerde ontwikkelomgeving (IDE)** voor de kwantitatieve strateeg. Elke stap in de workflow, van het bouwen van een strategie tot het diepgaand analyseren van de resultaten, vindt plaats binnen een naadloze, interactieve webapplicatie.

Dit maximaliseert de efficiëntie en verkort de **"Bouwen -> Meten -> Leren"**-cyclus van dagen of uren naar minuten.

---
## 5.2. De Werkruimtes: Van User Story Map naar Applicatie

De ruggengraat van de User Story Map (`USM_DEV_ROADMAP.md`) vertaalt zich direct naar de hoofdnavigatie (de "werkruimtes" of "tabbladen") van het S1mpleTrader-dashboard.

| PLUGIN DEVELOPMENT | STRATEGY BUILDER | BACKTESTING & ANALYSIS | PAPER TRADING | LIVE MONITORING |
| :--- | :--- | :--- | :--- | :--- |
| :--- | :--- | :--- | :--- | :--- |

Elk van deze secties representeert een "werkruimte" binnen de applicatie, met een eigen set aan gespecialiseerde tools en visualisaties.

---
## 5.3. Gedetailleerde Workflow per Werkruimte

### **Werkruimte 1: PLUGIN DEVELOPMENT**

* **User Goal:** Het snel en betrouwbaar ontwikkelen, testen en beheren van de herbruikbare bouwblokken (plugins) van het systeem.
* **UI Componenten:**
    * **Plugin Registry Viewer:** Een overzichtstabel van alle door de backend ontdekte plugins, met details uit hun `plugin_manifest.yaml` (versie, type, dependencies).
    * **Plugin Creator Wizard:** Een formulier dat de gebruiker helpt een nieuwe plugin-map aan te maken met de correcte boilerplate-code (`worker.py`, `schema.py`, `manifest.yaml`).
    * **Unit Test Runner:** Een UI-knop per plugin die de bijbehorende `test_worker.py` op de backend uitvoert en het resultaat (pass/fail) direct terugkoppelt.
* **Backend Interactie:** De UI communiceert met de `PluginQueryService` om de lijst van plugins op te halen en met een nieuwe `PluginEditorService` om de boilerplate aan te maken.

### **Werkruimte 2: STRATEGY BUILDER**

* **User Goal:** Het intuïtief en foutloos samenstellen van een complete handelsstrategie (`run.yaml`) door plugins te combineren.
* **UI Componenten:**
    * **Visuele Pijplijn:** Een grafische weergave van de 6-fasen trechter. Elke fase is een "slot" waar een of meerdere plugins in gesleept kunnen worden.
    * **Plugin Bibliotheek:** Een zijbalk toont alle beschikbare plugins, slim gegroepeerd op basis van het `type`-veld uit hun manifest (bv. `regime_filters`, `signal_generators`).
    * **Configuratie Paneel:** Dit is waar de magie gebeurt. Wanneer een plugin in een slot wordt geplaatst, verschijnt er een paneel met een **automatisch gegenereerd formulier**.
        * **Voorbeeld:** Als de `schema.py` van een EMA-plugin `length: int = Field(default=20, gt=1)` definieert, genereert de UI een numeriek inputveld, vooraf ingevuld met "20", met een validatieregel die afdwingt dat de waarde groter dan 1 moet zijn. Foutieve input wordt onmogelijk gemaakt.
* **Backend Interactie:** De UI haalt de plugins op via de `PluginQueryService`. Bij het opslaan stuurt de UI een `JSON`-representatie van de samengestelde strategie naar de `BlueprintEditorService`, die het als een `YAML`-bestand wegschrijft in de `config/runs/` map.

* **Hint naar frontend implementatie:**
+----------------------------------------------------------------------+
| Fase 1: Regime Context (Selecteer de "Weerman" plugins)              |
| +-----------------+   +-----------------+                            |
| | ADXContext      |   | VolatilityContext | ...                      |
| +-----------------+   +-----------------+                            |
+----------------------------------------------------------------------+
| Fase 2: Structurele Context (Selecteer de "Cartograaf" plugins)    |
| +----------------------+   +-------------------------+               |
| | MarketStructure      |   | SupportResistanceFinder | ...           |
| +----------------------+   +-------------------------+               |
+----------------------------------------------------------------------+

### **Werkruimte 3: BACKTESTING & ANALYSIS**

* **User Goal:** Het rigoureus testen van strategieën onder verschillende condities en het diepgaand analyseren van de resultaten om inzichten te verkrijgen.
* **UI Componenten:**
    1.  **Run Launcher:** Een sectie waar de gebruiker een opgeslagen strategie-blueprint selecteert en een backtest, optimalisatie of varianten-test kan starten.
    2.  **Live Progress Dashboard:** Na het starten van een run, toont de UI een live-updating dashboard met de voortgang (bv. voortgangsbalken voor de `ParallelRunService` bij een optimalisatie).
    3.  **Resultaten Hub:** Een centrale plek waar alle voltooide runs worden getoond. Vanuit hier kan de gebruiker doorklikken naar:
        * **Optimization Results:** Een interactieve tabel (sorteren, filteren, zoeken) met de resultaten van een optimalisatierun, om snel de beste parameter-sets te vinden.
        * **Comparison Arena:** Een grafische vergelijking van varianten, met overlappende equity curves en een heatmap van key metrics om de robuustheid te beoordelen.
        * **Trade Explorer:** De meest krachtige analyse-tool. Hier kan de gebruiker door individuele trades van een *enkele* run klikken en op een grafiek precies zien wat de context was op het moment van de trade: welke indicatoren waren actief, waar lag de marktstructuur, waarom werd de entry getriggerd, etc.
* **Backend Interactie:** De UI roept de `StrategyOrchestrator`, `OptimizationService` en `VariantTestService` aan. De resultaten worden opgehaald via de `VisualizationService`, die kant-en-klare "visualisatie-pakketten" (JSON-data voor grafieken en tabellen) levert.

### **Werkruimte 4 & 5: PAPER TRADING & LIVE MONITORING**

* **User Goal:** Een gevalideerde strategie naadloos overzetten naar een gesimuleerde en vervolgens een live-omgeving, en de prestaties continu monitoren.
* **UI Componenten:**
    * **Deployment Manager:** Een scherm waar een gebruiker een succesvolle strategie-configuratie kan "promoveren" naar Paper of Live trading.
    * **Live Dashboard:** Een real-time dashboard dat data leest uit de gedeelde datastore (bv. Redis) van de live-omgeving. Het toont:
        * Huidige PnL.
        * Open posities en orders.
        * Een live log-stream.
        * Alerts en notificaties.
        * Een prominente **"Noodstop"-knop** om de strategie onmiddellijk te deactiveren.
* **Backend Interactie:** De UI communiceert met de `LiveEnvironment` via een `Command Queue` (voor acties als "start" of "stop") en leest de live-staat via API-endpoints die gekoppeld zijn aan de real-time datastore.

---
## 5.4. Het Frontend-Backend Contract: BFF & TypeScript

De naadloze ervaring wordt technisch mogelijk gemaakt door twee kernprincipes:

1.  **Backend-for-Frontend (BFF):** De `frontends/web/api/` is geen generieke API, maar een **backend die exclusief voor de `frontends/web/ui/` werkt**. Hij levert data in exact het formaat dat de UI-componenten nodig hebben. Dit voorkomt complexe data-manipulatie in de frontend en houdt de UI-code schoon en gefocust op presentatie.

2.  **Contractuele Zekerheid met TypeScript:** We formaliseren het contract tussen de BFF en de UI om robuustheid te garanderen.
    * **Automatische Type Generatie:** Een tool in de ontwikkel-workflow leest de Pydantic-modellen (uit `schema.py` en DTO-bestanden) in de backend.
    * **Resultaat:** Het genereert automatisch corresponderende **TypeScript `interfaces`**. De frontend-code weet hierdoor al tijdens het ontwikkelen (*compile-time*) exact hoe elk data-object eruitziet. Een wijziging in de backend (bv. een veld hernoemen in een Pydantic-model) die niet in de frontend wordt doorgevoerd, leidt onmiddellijk tot een **compile-fout**, niet tot een onverwachte bug in productie.

Deze aanpak zorgt voor een robuust, ontkoppeld en tegelijkertijd perfect gesynchroniseerd ecosysteem, wat essentieel is voor de "supercharged" en efficiënte workflow die we voor ogen hebben.
--- END FILE: docs/system/5_FRONTEND_INTEGRATION.md ---

--- START FILE: docs/system/6_RESILIENCE_AND_OPERATIONS.md ---
# 6. Robuustheid & Operationele Betrouwbaarheid

Dit document beschrijft de strategieën en architectonische patronen die S1mpleTrader V2 veerkrachtig maken tegen technische fouten. Deze principes zijn essentieel voor de betrouwbaarheid van het systeem, met name in een live trading-omgeving waar kapitaal op het spel staat.

---
## 6.1. Integriteit van de Staat: Atomiciteit en Persistentie

Een trading-systeem is inherent 'stateful'. De huidige staat (open posities, kapitaal, state van een plugin) is de basis voor toekomstige beslissingen. Het corrumperen van deze staat is catastrofaal.

### **6.1.1. Atomische Schrijfacties (Journaling)**

* **Probleem:** Een applicatiecrash of stroomuitval tijdens het schrijven van een state-bestand (bv. `state.json` voor een stateful plugin) kan leiden tot een half geschreven, corrupt bestand, met permanent dataverlies tot gevolg.
* **Architectonische Oplossing:** We implementeren een **Write-Ahead Log (WAL)** of **Journaling**-patroon, een techniek die door professionele databases wordt gebruikt.

* **Gedetailleerde Workflow:**
    1.  **Schrijf naar Journaal:** De `save_state()`-methode van een stateful plugin schrijft de nieuwe staat **nooit** direct naar `state.json`. Het serialiseert de data naar een tijdelijk bestand: `state.json.journal`.
    2.  **Forceer Sync naar Schijf:** Na het schrijven roept de methode `os.fsync()` aan op het `.journal`-bestands-handle. Dit is een cruciale, expliciete instructie aan het besturingssysteem om alle databuffers onmiddellijk naar de fysieke schijf te schrijven. Dit voorkomt dat de data alleen in het geheugen blijft en verloren gaat bij een stroomstoring.
    3.  **Atomische Hernoeming:** Alleen als de sync succesvol is, wordt de `os.rename()`-operatie uitgevoerd om `state.json.journal` te hernoemen naar `state.json`. Deze `rename`-operatie is op de meeste moderne bestandssystemen een **atomische handeling**: het slaagt in zijn geheel, of het faalt in zijn geheel.
    4.  **Herstel-Logica:** De `load_state()`-methode van de plugin bevat de herstel-logica. Bij het opstarten controleert het: "Bestaat er een `.journal`-bestand?". Zo ja, dan weet het dat de applicatie is gecrasht na stap 2 maar vóór stap 3. De herstelprocedure is dan het voltooien van de `rename`-operatie, waarmee de laatste succesvol geschreven staat wordt hersteld.

---
## 6.2. Netwerkveerkracht (Live/Paper Trading)

Een live-systeem is afhankelijk van een stabiele verbinding met externe databronnen en brokers. De architectuur moet ontworpen zijn om met de onvermijdelijke instabiliteit van het internet om te gaan.

* **Probleem:** Een tijdelijke of langdurige onderbreking van de WebSocket-verbinding kan leiden tot gemiste data, een incorrecte portfolio-staat en het onvermogen om posities te beheren.
* **Architectonische Oplossing:** De verantwoordelijkheid voor het managen van de verbinding ligt volledig bij de `LiveEnvironment` en zijn componenten.

* **Gedetailleerde Componenten:**
    1.  **`LiveDataSource` (met Heartbeat & Reconnect):**
        * **Heartbeat:** De `DataSource` verwacht niet alleen data, maar ook periodieke "heartbeat"-berichten van de exchange. Als er gedurende een configureerbare periode (bv. 30 seconden) geen enkel bericht binnenkomt, wordt de verbinding als verbroken beschouwd.
        * **Reconnect Protocol:** Zodra een verbreking wordt gedetetecteerd, start een automatisch reconnect-protocol. Dit gebruikt een **exponential backoff**-algoritme: het wacht 1s, dan 2s, 4s, 8s, etc., om de server van de exchange niet te overbelasten.

    2.  **`LiveExecutionHandler` (met State Reconciliation):**
        * **Principe:** Na een reconnect is de interne staat van het `Portfolio`-object **onbetrouwbaar**. Het systeem moet uitgaan van de "single source of truth": de exchange zelf.
        * **Proces:** De `ExecutionHandler` voert een **reconciliation**-procedure uit. Het roept de REST API van de exchange aan met de vragen: "Geef mij de status van al mijn openstaande orders" en "Geef mij al mijn huidige posities". Het vergelijkt dit antwoord met de data in het `Portfolio`-object en corrigeert eventuele discrepanties.

    3.  **`StrategyOrchestrator` (met Circuit Breaker):**
        * **Principe:** Als de `LiveDataSource` na een configureerbaar aantal pogingen geen verbinding kan herstellen, moet het systeem in een veilige modus gaan om verdere schade te voorkomen.
        * **Proces:** De `DataSource` stuurt een `CONNECTION_LOST`-event naar de `Orchestrator`. De `Orchestrator` activeert dan de **Circuit Breaker**:
            * Het stopt onmiddellijk met het verwerken van nieuwe signalen.
            * Het stuurt een kritieke alert (via e-mail, Telegram, etc.) naar de gebruiker.
            * Het kan (optioneel) proberen alle open posities te sluiten als laatste redmiddel.

---
## 6.3. Applicatie Crash Recovery (Supervisor Model)

* **Probleem:** Het hoofdproces van de `StrategyOrchestrator` kan crashen door een onverwachte bug in een plugin of een geheugenprobleem.
* **Architectonische Oplossing:** We scheiden het *starten* van de applicatie van de *applicatie zelf* door middel van een **Supervisor (Watchdog)**-proces, aangestuurd door `run_supervisor.py`.

* **Gedetailleerde Workflow:**
    1.  **Entrypoint `run_supervisor.py`:** Dit is het enige script dat je handmatig start in een live-omgeving.
    2.  **Supervisor Proces:** Dit script start een extreem lichtgewicht en robuust "supervisor"-proces. Zijn enige taak is het spawnen van een *kind-proces* voor de daadwerkelijke `StrategyOrchestrator` en het monitoren van dit kind-proces.
    3.  **Herstart & Herstel Cyclus:**
        * Als het `Orchestrator`-proces onverwacht stopt, detecteert de `Supervisor` dit.
        * De `Supervisor` start de `Orchestrator` opnieuw.
        * De *nieuwe* `Orchestrator`-instantie start in een **"herstelmodus"**:
            * **Stap A (State Herstel):** Het roept de `load_state()`-methodes aan van al zijn stateful plugins, die de journaling-logica (zie 6.1) gebruiken om een consistente staat te herstellen.
            * **Stap B (Portfolio Herstel):** Het voert de **State Reconciliation**-procedure uit (zie 6.2) om zijn `Portfolio` te synchroniseren met de exchange.
            * **Stap C (Hervatting):** Alleen als beide stappen succesvol zijn, gaat de `Orchestrator` over naar de normale, live-operatie en begint het weer met het verwerken van marktdata.
--- END FILE: docs/system/6_RESILIENCE_AND_OPERATIONS.md ---

--- START FILE: docs/system/7_DEVELOPMENT_STRATEGY.md ---
# 7. Ontwikkelstrategie & Tooling

Dit document beschrijft de methodiek, de workflow en de tooling voor het ontwikkelen, testen en debuggen van het S1mpleTrader V2 ecosysteem. Het is de blauwdruk voor een snelle, efficiënte en data-gedreven ontwikkelomgeving.

---
## 7.1. Filosofie: Rapid, Lean & User-Centered

We stappen af van een traditionele, op de CLI gerichte workflow. De nieuwe filosofie is gebaseerd op een combinatie van **Lean UX** en **User-Centered Design (UCD)**, met als doel een "supercharged" ontwikkelcyclus te creëren.

* **De Gebruiker staat Centraal:** De primaire gebruiker ("De Kwantitatieve Strateeg") en diens workflow bepalen wat we bouwen en in welke volgorde. De Web UI is het centrale instrument.
* **Compact Ontwikkelen:** We bouwen in de kleinst mogelijke, onafhankelijke eenheden (een plugin) en testen deze geïsoleerd.
* **Direct Testen:** Elke plugin wordt vergezeld van unit tests. Geen enkele component wordt als "klaar" beschouwd zonder succesvolle, geautomatiseerde tests.
* **Snelle Feedback Loop (Bouwen -> Meten -> Leren):** De tijd tussen een idee, een codewijziging en het zien van het visuele resultaat moet minimaal zijn. De Web UI is de motor van deze cyclus.

---
## 7.2. De "Supercharged" Ontwikkelcyclus in de Praktijk

De gehele workflow, van het bouwen van een strategie tot het analyseren van de resultaten, vindt plaats binnen de naadloze, visuele webapplicatie.

### **Fase 1: Visuele Strategie Constructie (De "Strategy Builder")**
* **Doel:** Snel en foutloos een nieuwe strategie (`run.yaml`) samenstellen.
* **Proces:**
    1.  De gebruiker opent de "Strategy Builder" in de Web UI.
    2.  In een zijbalk verschijnen alle beschikbare plugins, opgehaald via een API en gegroepeerd per `type` (bv. `signal_generators`).
    3.  De gebruiker sleept plugins naar de "slots" in een visuele weergave van de 6-fasen trechter.
    4.  Voor elke geplaatste plugin genereert de UI automatisch een configuratieformulier op basis van de `schema.py` van de plugin. Input wordt direct in de browser gevalideerd.
    5.  Bij het opslaan wordt de configuratie als `YAML` op de server aangemaakt.

### **Fase 2: Interactieve Analyse (De "Backtesting Hub")**
* **Doel:** De gebouwde strategieën rigoureus testen en de resultaten diepgaand analyseren.
* **Proces:**
    1.  **Run Launcher:** Vanuit de UI start de gebruiker een backtest of optimalisatie.
    2.  **Live Progress:** Een dashboard toont de live voortgang.
    3.  **Resultaten Analyse:**
        * **Optimalisatie:** Resultaten verschijnen in een interactieve tabel (sorteren, filteren).
        * **Diepgaande Analyse (Trade Explorer):** De gebruiker kan doorklikken naar een enkele run en door individuele trades bladeren, waarbij een interactieve grafiek alle contextuele data (marktstructuur, indicatoren, etc.) toont op het moment van de trade.

### **Fase 3: De Feedback Loop**
* **Doel:** Een inzicht uit de analysefase direct omzetten in een verbetering.
* **Proces:** Vanuit de "Trade Explorer" klikt de gebruiker op "Bewerk Strategie". Hij wordt direct teruggebracht naar de "Strategy Builder" met de volledige configuratie al ingeladen, klaar om een aanpassing te doen. De cyclus begint opnieuw.

---
## 7.3. De Tooling in Detail

### **7.3.1. Gespecialiseerde Entrypoints**
De applicatie kent drie manieren om gestart te worden, elk met een eigen doel:
* **`run_web.py` (De IDE):** Het primaire entrypoint voor de ontwikkelaar. Start de FastAPI-server die de Web UI en de bijbehorende API's serveert.
* **`run_backtest_cli.py` (De Robot):** De "headless" entrypoint voor automatisering, zoals regressietesten en Continuous Integration (CI/CD) workflows.
* **`run_supervisor.py` (De Productie-schakelaar):** De minimalistische, robuuste starter voor de live trading-omgeving.

### **7.3.2. Testen als Integraal Onderdeel**
* **Unit Tests per Plugin:** Elke plugin-map krijgt een `tests/test_worker.py`. Deze test laadt een stukje voorbeeld-data, draait de `worker.py` erop, en valideert of de output (bv. de nieuwe kolom of de `Signal` DTO) correct is. Dit gebeurt volledig geïsoleerd.
* **Integratietests:** Testen de samenwerking tussen de `StrategyOrchestrator` en de `Assembly`-componenten.
* **End-to-End Tests:** Een klein aantal tests die via `run_backtest_cli.py` een volledige backtest draaien op een vaste dataset en controleren of het eindresultaat (de PnL) exact overeenkomt met een vooraf berekende waarde.

### **7.3.3. Gelaagde Logging & Debugging**
Logging is een multi-inzetbare tool, geen eenheidsworst. We onderscheiden drie lagen:

1.  **Laag 1: `stdio` (De Console)**
    * **Doel:** Alleen voor *initiële, basic development* van een geïsoleerde plugin. Gebruik `print()` voor de snelle, "vuile" check. Dit is vluchtig en wordt niet bewaard.

2.  **Laag 2: Gestructureerde Logs (`JSON`)**
    * **Doel:** De primaire output voor **backtests en paper trading**. Dit is de *databron* voor analyse.
    * **Implementatie:** Een `logging.FileHandler` die log-records als gestructureerde `JSON`-objecten wegschrijft naar `run.log.json`.
    * **Principe:** De console blijft schoon. De *echte* output is het log-bestand.

3.  **Laag 3: De "Log Explorer" (Web UI)**
    * **Doel:** De primaire interface voor **analyse en debugging**.
    * **Implementatie:** Een tool in de frontend die `run.log.json` inleest en interactief presenteert, waardoor je kunt filteren op `plugin_name` of een `Correlation ID`.

#### **Traceability met de `Correlation ID`**
Elk `Signal` DTO dat wordt gecreëerd, krijgt een unieke ID (bv. een UUID). Elke plugin die dit signaal (of een afgeleid object zoals een `Trade` DTO) verwerkt, voegt deze `Correlation ID` toe aan zijn log-berichten. Door in de "Log Explorer" op deze ID te filteren, kan de gebruiker de volledige levenscyclus en beslissingsketen van één specifieke trade volgen, door alle fasen en parallelle processen heen.
--- END FILE: docs/system/7_DEVELOPMENT_STRATEGY.md ---

--- START FILE: docs/system/8_META_WORKFLOWS.md ---
# 8. Meta Workflows: Van Analyse tot Inzicht

Dit document beschrijft de architectuur en de rol van de "Meta Workflows". Dit zijn hoog-niveau services die bovenop de kern-strategie-executie draaien om geavanceerde analyses, optimalisaties en automatisering mogelijk te maken.

---
## 8.1. Concept: De Orchestrator als Werknemer

De `StrategyOrchestrator` is de motor die in staat is om **één enkele** strategie-configuratie uit te voeren. Meta Workflows zijn services in de `Service`-laag die deze motor herhaaldelijk en systematisch aanroepen om complexe, kwantitatieve vragen te beantwoorden.

Ze fungeren als "onderzoekleiders" die de `StrategyOrchestrator` als een werknemer behandelen, en leunen zwaar op de `ParallelRunService` om duizenden backtests efficiënt en parallel uit te voeren. Waar optimalisatie in V1 een ad-hoc script was, wordt het in V2 een **"eerste klas burger"** van de architectuur.

---
## 8.2. De `OptimizationService` (Het Onderzoekslab)

* **Doel:** Het systematisch doorzoeken van een grote parameterruimte om de meest performante combinaties voor een strategie te vinden.
* **Analogie:** Een farmaceutisch lab dat duizenden moleculaire variaties test om het meest effectieve medicijn te vinden.

#### **Gedetailleerde Workflow:**

1.  **Input (Het Onderzoeksplan):** De service vereist een basis `run.yaml` (de strategie) en een `optimization.yaml` die de onderzoeksvraag definieert: welke parameters (`start`, `end`, `step`) moeten worden gevarieerd en op welke metriek (`sharpe_ratio`, `profit_factor`) moet worden geoptimaliseerd.

2.  **Proces (De Experimenten):**
    * De `OptimizationService` genereert een volledige lijst van alle mogelijke parameter-combinaties.
    * Voor elke combinatie creëert het een unieke `AppConfig` in het geheugen.
    * Het delegeert de volledige lijst van configuraties aan de `ParallelRunService`.

3.  **Executie (Het Robotleger):**
    * De `ParallelRunService` start een pool van workers (één per CPU-kern).
    * Elke worker ontvangt één configuratie, start een `StrategyOrchestrator` en voert een volledige backtest uit.

4.  **Output (De Analyse):**
    * De `OptimizationService` verzamelt alle `BacktestResult`-objecten.
    * Het creëert een `pandas DataFrame` met de geteste parameters en de resulterende performance-metrieken.
    * Deze data wordt naar de Web UI gestuurd voor presentatie in een interactieve, sorteerbare tabel.

---
## 8.3. De `VariantTestService` (De Vergelijkings-Arena)

* **Doel:** Het direct vergelijken van een klein aantal discrete strategie-varianten onder exact dezelfde marktomstandigheden om de robuustheid en de impact van specifieke keuzes te valideren.
* **Analogie:** Een "head-to-head" race tussen een paar topatleten om te zien wie de beste allrounder is.

#### **Gedetailleerde Workflow:**

1.  **Input (De Deelnemers):** De service vereist een basis `run.yaml` en een `variant.yaml` die de "deelnemers" definieert.
    * **Voorbeeld:**
        * **Variant A ("Baseline"):** De basisconfiguratie.
        * **Variant B ("Hoge RR"):** Overschrijft alleen de `risk_reward_ratio` parameter.
        * **Variant C ("Andere Exit"):** Vervangt de `ATR` exit-plugin door een `FixedPercentage` exit-plugin.

2.  **Proces (De Race-Opzet):**
    * De `VariantTestService` past voor elke gedefinieerde variant de "overrides" toe op de basisconfiguratie om unieke `AppConfig`-objecten te creëren.
    * Het delegeert de lijst van deze variant-configuraties aan de `ParallelRunService`.

3.  **Executie (Het Startschot):**
    * De `ParallelRunService` voert voor elke variant een volledige backtest uit.

4.  **Output (De Finishfoto):**
    * De `VariantTestService` verzamelt de `BacktestResult`-objecten.
    * Deze data wordt naar de Web UI gestuurd voor een directe, visuele vergelijking, bijvoorbeeld door de equity curves van alle varianten in één grafiek te plotten en een heatmap van de belangrijkste metrieken te tonen.

---
## 8.4. De Rol van `ParallelRunService`

Deze service is een cruciale, herbruikbare `Backend`-component. Zowel de `OptimizationService` als de `VariantTestService` zijn "klanten" van deze service. Zijn enige verantwoordelijkheid is het efficiënt managen van de `multiprocessing`-pool, het tonen van de voortgang en het netjes aggregeren van resultaten. Dit is een perfect voorbeeld van het **Single Responsibility Principle**.
--- END FILE: docs/system/8_META_WORKFLOWS.md ---

--- START FILE: docs/system/9_CODING_STANDAARDS.md ---
# 9. Coding Standaarden

**Versie:** 2.0 · **Status:** Definitief

Dit document beschrijft de verplichte standaarden en best practices voor het schrijven van alle code binnen het S1mpleTrader V2 project. Het doel is een consistente, leesbare, onderhoudbare en robuuste codebase. Het naleven van deze standaarden is niet optioneel.

---
## 9.1. Code Kwaliteit & Stijl

### **9.1.1. Fundamenten**
* **PEP 8 Compliant:** Alle Python-code moet strikt voldoen aan de [PEP 8](https://peps.python.org/pep-0008/) stijlgids. Een linter wordt gebruikt om dit te handhaven.
    * **Regellengte:** Maximaal 100 tekens.
    * **Naamgeving:** `snake_case` voor variabelen, functies en modules; `PascalCase` voor klassen.
* **Volledige Type Hinting:** Alle functies, methodes, en variabelen moeten volledig en correct getypeerd zijn. We streven naar een 100% getypeerde codebase om runtime-fouten te minimaliseren.
* **Commentaar in het Engels:** Al het commentaar in de code (`# ...`) en docstrings moeten in het Engels zijn voor universele leesbaarheid en onderhoudbaarheid.

### **9.1.2. Gestructureerde Docstrings**
Elk bestand, elke klasse en elke functie moet een duidelijke docstring hebben.

* **Bestands-Header Docstring:** Elk `.py`-bestand begint met een gestandaardiseerde header die de inhoud en de plaats in de architectuur beschrijft.
    ```python
    # backend/assembly/plugin_registry.py
    """
    Contains the PluginRegistry, responsible for discovering and validating all
    available plugins within the ecosystem.

    @layer: Backend (Assembly)
    @dependencies: [PyYAML, Pydantic]
    @responsibilities:
        - Scans plugin directories for manifests.
        - Validates manifest schemas.
        - Builds and maintains the central plugin registry.
    """
    ```
* **Functie & Methode Docstrings (Google Style):** Voor alle functies en methodes hanteren we de **Google Style Python Docstrings**. Dit is een leesbare en gestructureerde manier om parameters, return-waarden en voorbeelden te documenteren.
    ```python
    def process_data(df: pd.DataFrame, length: int = 14) -> pd.DataFrame:
        """Calculates an indicator and adds it as a new column.

        Args:
            df (pd.DataFrame): The input DataFrame with OHLCV data.
            length (int, optional): The lookback period for the indicator.
                Defaults to 14.

        Returns:
            pd.DataFrame: The DataFrame with the new indicator column added.
        """
        # ... function logic ...
        return df
    ```

---
## 9.2. Contract-Gedreven Ontwikkeling

### **9.2.1. Pydantic voor alle Data-Structuren**
* **Principe:** Alle data die tussen componenten wordt doorgegeven, moet worden ingekapseld in een **Pydantic `BaseModel`**. Dit geldt voor DTO's, configuraties en plugin-parameters.
* **Voordeel:** Dit garandeert dat data van het juiste type en de juiste structuur is *voordat* het wordt verwerkt.

### **9.2.2. Abstracte Basisklassen (Interfaces)**
* **Principe:** Componenten die uitwisselbaar moeten zijn (zoals plugins), moeten erven van een gemeenschappelijke abstracte basisklasse (ABC) die een consistent contract afdwingt.

---
## 9.3. Gelaagde Logging & Traceability

### **9.3.1. Drie Lagen van Logging**
1.  **Laag 1: `stdio` (Console via `print()`):** Uitsluitend voor snelle, lokale, vluchtige debugging. Mag nooit gecommit worden.
2.  **Laag 2: Gestructureerde `JSON`-logs:** De standaard output voor alle runs, bedoeld voor analyse.
3.  **Laag 3: De Web UI (Log Explorer):** De primaire interface voor het analyseren en debuggen van runs.

### **9.3.2. Traceability via `Correlation ID`**
* **Principe:** Elk `Signal` DTO krijgt een unieke `UUID`. Elke volgende plugin die dit signaal verwerkt, neemt deze `correlation_id` over in zijn log-berichten. Dit maakt de volledige levenscyclus van een trade traceerbaar.

---
## 9.4. Testen als Voorwaarde

* **Principe:** Code zonder tests wordt beschouwd als onvolledig.
* **Implementatie:** Elke plugin is **verplicht** om een `tests/test_worker.py`-bestand te bevatten. Continue Integratie (CI) voert alle tests automatisch uit na elke `push`.

---
## 9.5. Overige Standaarden

* **Internationalisatie (i18n):**
    * **Principe:** Alle user-facing strings (labels in de UI, rapportages, log-berichten voor de gebruiker) moeten via een internationalisatie-laag lopen, niet hardcoded in de code staan.
    * **Implementatie:** Een centrale `Translator`-klasse laadt `YAML`-bestanden uit de `/locales` map. Code gebruikt vertaalsleutels (bv. `log.backtest.complete`).
    * **Interactie met Logger:** De `Translator` wordt één keer geïnitialiseerd en geïnjecteerd in de `LogFormatter`. De formatter is de enige component binnen het logsysteem die sleutels vertaalt naar leesbare berichten. Componenten die direct output genereren (zoals `Presenters`) krijgen de `Translator` ook apart geïnjecteerd.

* **Configuratie Formaat:** `YAML` is de standaard voor alle door mensen geschreven configuratie. `JSON` wordt gebruikt voor machine-naar-machine data-uitwisseling.

--- END FILE: docs/system/9_CODING_STANDAARDS.md ---

--- START FILE: docs/system/A_BIJLAGE_TEMINOLOGIE.md ---
# Bijlage A: Terminologie

Dit document dient als een uitgebreid naslagwerk voor alle kerntbegrippen, componenten en patronen binnen de S1mpleTrader V2-architectuur.

**6-Fasen Trechter:** De fundamentele, sequentiële workflow die elk handelsidee valideert (`Regime` -> `Context` -> `Signaal` -> `Verfijning` -> `Constructie` -> `Overlay`).
**Assembly Team:** De conceptuele naam voor de verzameling backend-componenten (`PluginRegistry`, `WorkerBuilder`, `ContextPipelineRunner`) die samen de technische orkestratie van plugins verzorgen.
**Atomic Writes (Journaling):** Het robuuste state-saving mechanisme dat dataverlies bij een crash voorkomt door eerst naar een tijdelijk `.journal`-bestand te schrijven.
**Backend-for-Frontend (BFF):** Een gespecialiseerde API-laag die data levert in het exacte formaat dat de Web UI nodig heeft, wat de frontend-code versimpelt.
**Blueprint (`run_blueprint.yaml`):** Een door de gebruiker gedefinieerd `YAML`-bestand dat een complete strategie-configuratie beschrijft, inclusief alle geselecteerde plugins en hun parameters.
**Circuit Breaker:** Een veiligheidsmechanisme in de `LiveEnvironment` dat, bij aanhoudende netwerkproblemen, de strategie in een veilige modus plaatst.
**Clock:** De component binnen een `ExecutionEnvironment` die de "hartslag" van het systeem genereert, ofwel gesimuleerd (voor backtests) of real-time.
**Configuratie-gedreven:** Het kernprincipe dat het gedrag van de applicatie wordt bestuurd door `YAML`-configuratiebestanden, niet door hardgecodeerde logica.
**Contract-gedreven:** Het kernprincipe dat alle data-uitwisseling wordt gevalideerd door strikte schema's (Pydantic voor de backend, TypeScript voor de frontend).
**Context Pipeline:** De door de `ContextPipelineRunner` beheerde executie van `ContextWorker`-plugins (Fase 1 & 2), die de ruwe marktdata verrijkt tot een `enriched_df`.
**ContextWorker:** Een type plugin dat als doel heeft data of context toe te voegen aan de `DataFrame` (bv. het berekenen van een indicator zoals RSI of ADX).
**Correlation ID:** Een unieke identifier (UUID) die wordt toegewezen aan een `Signal` DTO om de volledige levenscyclus van een trade traceerbaar te maken door alle logs heen.
**DTO (Data Transfer Object):** Een Pydantic `BaseModel` (bv. `Signal`, `Trade`, `ClosedTrade`) dat dient als een strikt contract voor data die tussen componenten wordt doorgegeven.
**Entrypoints:** De drie gespecialiseerde starter-scripts: `run_web.py` (voor de UI), `run_supervisor.py` (voor live trading), en `run_backtest_cli.py` (voor automatisering).
**ExecutionEnvironment:** De backend-laag die de "wereld" definieert waarin een strategie draait (`Backtest`, `Paper`, of `Live`).
**ExecutionHandler:** De component binnen een `ExecutionEnvironment` die verantwoordelijk is voor het daadwerkelijk uitvoeren van `Trade` DTO's (gesimuleerd of via een echte broker).
**Feedback Loop (Strategisch):** De door de gebruiker bestuurde "Bouwen -> Meten -> Leren" cyclus, gefaciliteerd door de Web UI.
**Feedback Loop (Technisch):** De real-time feedback *binnen* een run, waarbij de staat van het `Portfolio` wordt gebruikt als input voor de `Portfolio Overlay`-plugins.
**Heartbeat:** Een mechanisme in de `LiveDataSource` om de gezondheid van een live dataverbinding te monitoren door te controleren op periodieke signalen van de server.
**Manifest (`plugin_manifest.yaml`):** De "ID-kaart" van een plugin. Dit `YAML`-bestand bevat alle metadata die de `PluginRegistry` nodig heeft om de plugin te ontdekken en te begrijpen.
**Meta Workflows:** Hoog-niveau services (`OptimizationService`, `VariantTestService`) die de `StrategyOrchestrator` herhaaldelijk aanroepen voor complexe analyses.
**OptimizationService:** De service die een grote parameterruimte systematisch doorzoekt door duizenden backtests parallel uit te voeren.
**ParallelRunService:** Een herbruikbare backend-component die het efficiënt managen van een `multiprocessing`-pool voor parallelle backtests verzorgt.
**Plugin:** De fundamentele, zelfstandige en testbare eenheid van logica in het systeem, bestaande uit een `manifest`, `worker` en `schema`.
**PluginRegistry:** De specialistische klasse binnen het `Assembly Team` die verantwoordelijk is voor het scannen van de `plugins/`-map en het valideren van alle manifesten.
**Portfolio:** De backend-component die fungeert als het "domme grootboek" en de financiële staat van het systeem (kapitaal, posities, orders) bijhoudt.
**Pydantic:** De Python-bibliotheek die wordt gebruikt voor datavalidatie en het definiëren van de data-contracten via `BaseModel`-klassen.
**Schema (`schema.py`):** Het bestand binnen een plugin dat het Pydantic-model bevat dat de configuratieparameters van die specifieke plugin definieert en valideert.
**State Reconciliation:** Het cruciale proces na een netwerk-reconnect waarbij de interne `Portfolio`-staat wordt gesynchroniseerd met de 'single source of truth': de exchange.
**Strategy Builder:** De "werkruimte" in de Web UI waar een gebruiker visueel een strategie kan samenstellen door plugins te selecteren en te configureren.
**StrategyOrchestrator:** De "regisseur" in de Service-laag. Deze component is verantwoordelijk voor het uitvoeren van de 6-fasen trechter voor één enkele strategie-configuratie.
**StrategyWorker:** Een type plugin dat wordt gebruikt in de besluitvormingsfases (3-6) van de trechter en die opereert op DTO's in plaats van de `DataFrame`.
**Supervisor Model:** Het crash-recovery mechanisme voor live trading, waarbij een lichtgewicht "watchdog"-proces de `StrategyOrchestrator` monitort en herstart.
**Trade Explorer:** De "werkruimte" in de Web UI die een diepgaande visuele analyse van de trades en de context van een enkele backtest-run mogelijk maakt.
**TypeScript:** De programmeertaal die voor de frontend wordt gebruikt om een type-veilig contract met de Pydantic-backend te garanderen via automatisch gegenereerde interfaces.
**VariantTestService:** De service die een klein, gedefinieerd aantal strategie-varianten "head-to-head" met elkaar vergelijkt onder identieke marktomstandigheden.
**Worker (`worker.py`):** Het bestand binnen een plugin dat de Python-klasse met de daadwerkelijke businesslogica bevat.
**WorkerBuilder:** De specialistische klasse binnen het `Assembly Team` die op aanvraag een geïnstantieerd en gevalideerd `worker`-object bouwt.
--- END FILE: docs/system/A_BIJLAGE_TEMINOLOGIE.md ---

--- START FILE: docs/system/B_BIJLAGE_OPENSTAANDE_VRAAGSTUKKEN.md ---
Bijlage B: Openstaande Vraagstukken & Onderzoekspunten
Dit document bevat een lijst van bekende "onbekenden" en complexe vraagstukken die tijdens de detailimplementatie van de V2-architectuur verder onderzocht en opgelost moeten worden. Ze worden hier vastgelegd om te verzekeren dat ze niet vergeten worden.

B.1. State Management voor Stateful Plugins

Vraagstuk: Hoe persisteren, beheren en herstellen we de staat van stateful plugins (bv. een Grid Trading-strategie die zijn openstaande grid-levels moet onthouden) op een robuuste manier, met name na een applicatiecrash?

Zie ook: docs/system/6_RESILIENCE_AND_OPERATIONS.md

B.2. Data Synchronisatie in Live Omgevingen

Vraagstuk: Hoe gaat de LiveEnvironment om met asynchrone prijs-ticks die voor verschillende assets op verschillende momenten binnenkomen? Moet de orkestratie tick-gedreven zijn (complexer, maar nauwkeuriger) of bar-gedreven (eenvoudiger, maar met mogelijke vertraging)?

B.3. Performance en Geheugengebruik

Vraagstuk: Wat is de meest efficiënte strategie voor het beheren van geheugen bij grootschalige Multi-Time-Frame (MTF) analyses, met name wanneer dit over meerdere assets parallel gebeurt? Hoe voorkomen we onnodige duplicatie van data in het geheugen?

B.4. Debugging en Traceability

Vraagstuk: Welke tools of modi moeten we ontwikkelen om het debuggen van complexe, parallelle runs te faciliteren? Hoe kan een ontwikkelaar eenvoudig de volledige levenscyclus van één specifieke trade volgen (traceability) door alle lagen en plugins heen?

Zie ook: Het concept van een Correlation ID in docs/development/KanBan/product_backlog.csv.
--- END FILE: docs/system/B_BIJLAGE_OPENSTAANDE_VRAAGSTUKKEN.md ---

--- START FILE: frontends/__init__.py ---

--- END FILE: frontends/__init__.py ---

--- START FILE: frontends/cli/presenters/optimization_presenter.py ---
# frontends/cli/presenters/optimization_presenter.py
"""
Docstring for optimization_presenter.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class OptimizationPresenter:
    """Docstring for OptimizationPresenter."""
    pass

--- END FILE: frontends/cli/presenters/optimization_presenter.py ---

--- START FILE: frontends/cli/reporters/cli_reporter.py ---
# frontends/cli/reporters/cli_reporter.py
"""
Docstring for cli_reporter.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class CliReporter:
    """Docstring for CliReporter."""
    pass

--- END FILE: frontends/cli/reporters/cli_reporter.py ---

--- START FILE: frontends/web/api/main.py ---
# frontends/web/api/main.py
"""
FastAPI application entry point
"""

--- END FILE: frontends/web/api/main.py ---

--- START FILE: frontends/web/api/__init__.py ---

--- END FILE: frontends/web/api/__init__.py ---

--- START FILE: frontends/web/api/routers/backtest_router.py ---
# frontends/web/api/routers/backtest_router.py
"""
API endpoints for running backtests
"""

--- END FILE: frontends/web/api/routers/backtest_router.py ---

--- START FILE: frontends/web/api/routers/plugins_router.py ---
# frontends/web/api/routers/plugins_router.py
"""
API endpoints for plugins
"""

--- END FILE: frontends/web/api/routers/plugins_router.py ---

--- START FILE: frontends/web/api/routers/__init__.py ---

--- END FILE: frontends/web/api/routers/__init__.py ---

--- START FILE: locales/en.yaml ---
# locales/en.yaml

# This file contains user-facing text for the application.
# For the MVP, we use English keys that map to English text.

app:
  start: "S1mpleTrader is starting..."

plugin_registry:
  scan_start: "Scanning for plugins in path: '{path}'..."
  scan_complete: "Scan complete. Found and registered {count} valid plugins."

loader:
  loading_from: "Loading data from {filename}..."
  load_success: "Data successfully loaded and prepared."

plugin_registry:
  scan_complete: "Scan complete. Found and registered {count} valid plugins."

worker_builder:
  build_success: "Successfully built worker '{name}'."
--- END FILE: locales/en.yaml ---

--- START FILE: locales/nl.yaml ---
app:
  start: "S1mpleTrader wordt gestart..."
--- END FILE: locales/nl.yaml ---

--- START FILE: plugins/__init__.py ---

--- END FILE: plugins/__init__.py ---

--- START FILE: plugins/portfolio_overlays/__init__.py ---

--- END FILE: plugins/portfolio_overlays/__init__.py ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/plugin_manifest.yaml ---
name: max_drawdown_overlay
type: portfolio_overlay
...
--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/plugin_manifest.yaml ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/schema.py ---
# plugins/portfolio_overlays/max_drawdown_overlay/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class MaxDrawdownOverlayParams:
    """Docstring for MaxDrawdownOverlayParams."""
    pass

--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/schema.py ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/worker.py ---
# plugins/portfolio_overlays/max_drawdown_overlay/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class MaxDrawdownOverlay:
    """Docstring for MaxDrawdownOverlay."""
    pass

--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/worker.py ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/__init__.py ---

--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/__init__.py ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/tests/test_worker.py ---
# plugins/portfolio_overlays/max_drawdown_overlay/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestMaxDrawdownOverlay:
    """Docstring for TestMaxDrawdownOverlay."""
    pass

--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/tests/test_worker.py ---

--- START FILE: plugins/portfolio_overlays/max_drawdown_overlay/tests/__init__.py ---

--- END FILE: plugins/portfolio_overlays/max_drawdown_overlay/tests/__init__.py ---

--- START FILE: plugins/regime_filters/__init__.py ---

--- END FILE: plugins/regime_filters/__init__.py ---

--- START FILE: plugins/regime_filters/adx_trend_filter/plugin_manifest.yaml ---
name: adx_trend_filter
type: regime_filter
...
--- END FILE: plugins/regime_filters/adx_trend_filter/plugin_manifest.yaml ---

--- START FILE: plugins/regime_filters/adx_trend_filter/schema.py ---
# plugins/regime_filters/adx_trend_filter/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class AdxTrendFilterParams:
    """Docstring for AdxTrendFilterParams."""
    pass

--- END FILE: plugins/regime_filters/adx_trend_filter/schema.py ---

--- START FILE: plugins/regime_filters/adx_trend_filter/worker.py ---
# plugins/regime_filters/adx_trend_filter/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class AdxTrendFilter:
    """Docstring for AdxTrendFilter."""
    pass

--- END FILE: plugins/regime_filters/adx_trend_filter/worker.py ---

--- START FILE: plugins/regime_filters/adx_trend_filter/__init__.py ---

--- END FILE: plugins/regime_filters/adx_trend_filter/__init__.py ---

--- START FILE: plugins/regime_filters/adx_trend_filter/tests/test_worker.py ---
# plugins/regime_filters/adx_trend_filter/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestAdxTrendFilter:
    """Docstring for TestAdxTrendFilter."""
    pass

--- END FILE: plugins/regime_filters/adx_trend_filter/tests/test_worker.py ---

--- START FILE: plugins/regime_filters/adx_trend_filter/tests/__init__.py ---

--- END FILE: plugins/regime_filters/adx_trend_filter/tests/__init__.py ---

--- START FILE: plugins/signal_generators/__init__.py ---

--- END FILE: plugins/signal_generators/__init__.py ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/plugin_manifest.yaml ---
name: fvg_entry_detector
type: signal_generator
...
--- END FILE: plugins/signal_generators/fvg_entry_detector/plugin_manifest.yaml ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/schema.py ---
# plugins/signal_generators/fvg_entry_detector/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class FvgEntryDetectorParams:
    """Docstring for FvgEntryDetectorParams."""
    pass

--- END FILE: plugins/signal_generators/fvg_entry_detector/schema.py ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/worker.py ---
# plugins/signal_generators/fvg_entry_detector/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class FvgEntryDetector:
    """Docstring for FvgEntryDetector."""
    pass

--- END FILE: plugins/signal_generators/fvg_entry_detector/worker.py ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/__init__.py ---

--- END FILE: plugins/signal_generators/fvg_entry_detector/__init__.py ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/tests/test_worker.py ---
# plugins/signal_generators/fvg_entry_detector/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestFvgEntryDetector:
    """Docstring for TestFvgEntryDetector."""
    pass

--- END FILE: plugins/signal_generators/fvg_entry_detector/tests/test_worker.py ---

--- START FILE: plugins/signal_generators/fvg_entry_detector/tests/__init__.py ---

--- END FILE: plugins/signal_generators/fvg_entry_detector/tests/__init__.py ---

--- START FILE: plugins/signal_refiners/__init__.py ---

--- END FILE: plugins/signal_refiners/__init__.py ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/plugin_manifest.yaml ---
name: volume_spike_refiner
type: signal_refiner
...
--- END FILE: plugins/signal_refiners/volume_spike_refiner/plugin_manifest.yaml ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/schema.py ---
# plugins/signal_refiners/volume_spike_refiner/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class VolumeSpikeRefinerParams:
    """Docstring for VolumeSpikeRefinerParams."""
    pass

--- END FILE: plugins/signal_refiners/volume_spike_refiner/schema.py ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/worker.py ---
# plugins/signal_refiners/volume_spike_refiner/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class VolumeSpikeRefiner:
    """Docstring for VolumeSpikeRefiner."""
    pass

--- END FILE: plugins/signal_refiners/volume_spike_refiner/worker.py ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/__init__.py ---

--- END FILE: plugins/signal_refiners/volume_spike_refiner/__init__.py ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/tests/test_worker.py ---
# plugins/signal_refiners/volume_spike_refiner/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestVolumeSpikeRefiner:
    """Docstring for TestVolumeSpikeRefiner."""
    pass

--- END FILE: plugins/signal_refiners/volume_spike_refiner/tests/test_worker.py ---

--- START FILE: plugins/signal_refiners/volume_spike_refiner/tests/__init__.py ---

--- END FILE: plugins/signal_refiners/volume_spike_refiner/tests/__init__.py ---

--- START FILE: plugins/structural_context/__init__.py ---

--- END FILE: plugins/structural_context/__init__.py ---

--- START FILE: plugins/structural_context/market_structure_detector/plugin_manifest.yaml ---
name: market_structure_detector
type: structural_context
...
--- END FILE: plugins/structural_context/market_structure_detector/plugin_manifest.yaml ---

--- START FILE: plugins/structural_context/market_structure_detector/schema.py ---
# plugins/structural_context/market_structure_detector/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class MarketStructureDetectorParams:
    """Docstring for MarketStructureDetectorParams."""
    pass

--- END FILE: plugins/structural_context/market_structure_detector/schema.py ---

--- START FILE: plugins/structural_context/market_structure_detector/worker.py ---
# plugins/structural_context/market_structure_detector/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class MarketStructureDetector:
    """Docstring for MarketStructureDetector."""
    pass

--- END FILE: plugins/structural_context/market_structure_detector/worker.py ---

--- START FILE: plugins/structural_context/market_structure_detector/__init__.py ---

--- END FILE: plugins/structural_context/market_structure_detector/__init__.py ---

--- START FILE: plugins/structural_context/market_structure_detector/tests/test_worker.py ---
# plugins/structural_context/market_structure_detector/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestMarketStructureDetector:
    """Docstring for TestMarketStructureDetector."""
    pass

--- END FILE: plugins/structural_context/market_structure_detector/tests/test_worker.py ---

--- START FILE: plugins/structural_context/market_structure_detector/tests/__init__.py ---

--- END FILE: plugins/structural_context/market_structure_detector/tests/__init__.py ---

--- START FILE: plugins/trade_constructors/__init__.py ---

--- END FILE: plugins/trade_constructors/__init__.py ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/plugin_manifest.yaml ---
name: liquidity_target_exit
type: trade_constructor
...
--- END FILE: plugins/trade_constructors/liquidity_target_exit/plugin_manifest.yaml ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/schema.py ---
# plugins/trade_constructors/liquidity_target_exit/schema.py
"""
Docstring for schema.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class LiquidityTargetExitParams:
    """Docstring for LiquidityTargetExitParams."""
    pass

--- END FILE: plugins/trade_constructors/liquidity_target_exit/schema.py ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/worker.py ---
# plugins/trade_constructors/liquidity_target_exit/worker.py
"""
Docstring for worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class LiquidityTargetExitPlanner:
    """Docstring for LiquidityTargetExitPlanner."""
    pass

--- END FILE: plugins/trade_constructors/liquidity_target_exit/worker.py ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/__init__.py ---

--- END FILE: plugins/trade_constructors/liquidity_target_exit/__init__.py ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/tests/test_worker.py ---
# plugins/trade_constructors/liquidity_target_exit/tests/test_worker.py
"""
Docstring for test_worker.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class TestLiquidityTargetExitPlanner:
    """Docstring for TestLiquidityTargetExitPlanner."""
    pass

--- END FILE: plugins/trade_constructors/liquidity_target_exit/tests/test_worker.py ---

--- START FILE: plugins/trade_constructors/liquidity_target_exit/tests/__init__.py ---

--- END FILE: plugins/trade_constructors/liquidity_target_exit/tests/__init__.py ---

--- START FILE: results/20250924_213000_mss_fvg_strategy/result_metrics.yaml ---
# Placeholder for results/20250924_213000_mss_fvg_strategy/result_metrics.yaml

--- END FILE: results/20250924_213000_mss_fvg_strategy/result_metrics.yaml ---

--- START FILE: results/20250924_213000_mss_fvg_strategy/run_config.yaml ---
# Placeholder for results/20250924_213000_mss_fvg_strategy/run_config.yaml

--- END FILE: results/20250924_213000_mss_fvg_strategy/run_config.yaml ---

--- START FILE: services/optimization_service.py ---
# services/optimization_service.py
"""
Docstring for optimization_service.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class OptimizationService:
    """Docstring for OptimizationService."""
    pass

--- END FILE: services/optimization_service.py ---

--- START FILE: services/parallel_run_service.py ---
# services/parallel_run_service.py
"""
Docstring for parallel_run_service.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class ParallelRunService:
    """Docstring for ParallelRunService."""
    pass

--- END FILE: services/parallel_run_service.py ---

--- START FILE: services/strategy_operator.py ---
# services/strategy_operator.py
"""
Contains the StrategyOperator, the service responsible for orchestrating a
single, complete strategy run.

@layer: Service
@dependencies:
    - backend.config.schemas.app_schema: To receive the complete run configuration.
    - backend.assembly: To build all necessary components (plugins, engine).
    - backend.environments: To create the world the strategy runs in.
    - backend.core: To instantiate the portfolio and the engine itself.
@responsibilities:
    - Acts as the main "conductor" for a single backtest or trading session.
    - Initializes all necessary backend components based on an AppConfig.
    - Runs the main event loop by calling the StrategyEngine.
    - Delegates the results from the engine (Directives and Events) to the
      appropriate handlers.
"""
from typing import Optional
import pandas as pd

from backend.config.schemas.app_schema import AppConfig
from backend.utils.app_logger import LogEnricher

from backend.assembly import PluginRegistry, WorkerBuilder, ContextBuilder
from backend.assembly.engine_builder import EngineBuilder  # Import the new builder
from backend.core import Portfolio, ContextRecorder
from backend.core.interfaces import Tradable #pyright: ignore[reportUnusedImport], pylint: disable=unused-import
from backend.core.interfaces.execution import ExecutionHandler
from backend.environments.backtest_environment import BacktestEnvironment
from backend.dtos import TradingContext

# Force Pydantic to resolve any forward-looking type references (like 'Tradable')
# This is crucial for models that use abstract base classes or protocols.
TradingContext.model_rebuild()

class StrategyOperator:  # pylint: disable=too-many-instance-attributes
    """Orchestrates a single, complete strategy run from setup to execution."""

    def __init__(self, app_config: AppConfig, logger: LogEnricher):
        """Initializes the StrategyOperator."""
        self._app_config = app_config
        self._logger = logger
        self._context_recorder = ContextRecorder()

        # Attributes to be initialized in _prepare_components
        self._engine_builder: Optional[EngineBuilder] = None
        self._context_builder: Optional[ContextBuilder] = None
        self._portfolio: Optional[Portfolio] = None
        self._environment: Optional[BacktestEnvironment] = None
        self._execution_handler: Optional[ExecutionHandler] = None

    def _prepare_components(self):
        """Phase 1: Prepares all long-lived components for the run."""
        self._logger.info("operator.setup_start")
        platform_conf = self._app_config.platform

        registry = PluginRegistry(platform_config=platform_conf, logger=self._logger)
        worker_builder = WorkerBuilder(plugin_registry=registry, logger=self._logger)

        # The EngineBuilder is now a dedicated specialist for engine assembly
        self._engine_builder = EngineBuilder(worker_builder=worker_builder)
        self._context_builder = ContextBuilder()

        self._portfolio = Portfolio(
            initial_capital=platform_conf.portfolio.initial_capital,
            fees_pct=platform_conf.portfolio.fees_pct,
            logger=self._logger,
            context_recorder=self._context_recorder
        )

        # TODO: MVP HACK - Environment should be injected by a factory.
        self._environment = BacktestEnvironment(app_config=self._app_config,
                                                tradable=self._portfolio)
        self._execution_handler = self._environment.handler

    def _prepare_data(self) -> pd.DataFrame:
        """Phase 2: Builds and runs the context pipeline to create enriched data."""
        assert self._engine_builder is not None, "Components not prepared"
        assert self._context_builder is not None, "Components not prepared"
        assert self._environment is not None, "Components not prepared"

        self._logger.info("operator.context_building_start")
        run_conf = self._app_config.run

        context_pipeline = self._engine_builder.build_context_pipeline(run_conf)

        enriched_df = self._context_builder.build(
            initial_df=self._environment.source.get_data(),
            context_pipeline=context_pipeline
        )
        self._logger.info("operator.context_building_complete")
        return enriched_df

    def _run_operational_cycle(self, enriched_df: pd.DataFrame):
        """Phase 3 & 4: Assembles the engine and runs the main event loop."""
        assert self._engine_builder is not None, "Components not prepared"
        assert self._portfolio is not None, "Components not prepared"
        assert self._environment is not None, "Components not prepared"
        assert self._execution_handler is not None, "Components not prepared"

        run_conf = self._app_config.run

        # --- Assemble Engine ---
        self._logger.info("operator.engine_assembly_start")
        engine = self._engine_builder.build_engine(run_conf)
        self._logger.info("operator.engine_assembly_complete")

        # --- Run Main Loop ---
        trading_context = TradingContext(
            enriched_df=enriched_df,
            portfolio=self._portfolio,
            context_recorder=self._context_recorder
        )
        self._logger.info("operator.engine_start")
        for result in engine.run(trading_context=trading_context, clock=self._environment.clock):
            if result.critical_events:
                # TODO: MVP HACK - Proper event handling belongs in a supervisor.
                self._logger.error("operator.critical_events_detected",
                                   values={'count': len(result.critical_events)})
                break

            if result.execution_directives:
                # TODO: ARCHITECTURE REFACTOR - Directive handling belongs in the caller.
                self._execution_handler.execute_plan(result.execution_directives)

    def run(self):
        """
        Executes the full workflow by composing the private helper methods.
        This method now only describes WHAT happens, not HOW.
        """
        self._logger.info("operator.run_start")

        self._prepare_components()
        enriched_df = self._prepare_data()
        self._run_operational_cycle(enriched_df)

        self._logger.info("operator.run_complete")

--- END FILE: services/strategy_operator.py ---

--- START FILE: services/variant_test_service.py ---
# services/variant_test_service.py
"""
Docstring for variant_test_service.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class VariantTestService:
    """Docstring for VariantTestService."""
    pass

--- END FILE: services/variant_test_service.py ---

--- START FILE: services/__init__.py ---
# services/__init__.py
"""
Exposes the public API of the Services package.
"""
__all__ = [
    # Top-level services
    "StrategyOperator",
    "OptimizationService",
    "ParallelRunService",
    "VariantTestService",
    # from .api_services
    "PluginQueryService",
    "VisualizationService",
]

# This assumes a file named strategy_operator.py exists with class StrategyOperator
from .strategy_operator import StrategyOperator
from .optimization_service import OptimizationService
from .parallel_run_service import ParallelRunService
from .variant_test_service import VariantTestService
from .api_services import (
    PluginQueryService,
    VisualizationService,
)

--- END FILE: services/__init__.py ---

--- START FILE: services/api_services/plugin_query_service.py ---
# services/api_services/plugin_query_service.py
"""
Docstring for plugin_query_service.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class PluginQueryService:
    """Docstring for PluginQueryService."""
    pass

--- END FILE: services/api_services/plugin_query_service.py ---

--- START FILE: services/api_services/visualization_service.py ---
# services/api_services/visualization_service.py
"""
Docstring for visualization_service.py.

@layer: TODO
@dependencies: TODO
@responsibilities: TODO
"""

class VisualizationService:
    """Docstring for VisualizationService."""
    pass

--- END FILE: services/api_services/visualization_service.py ---

--- START FILE: services/api_services/__init__.py ---
# services/api_services/__init__.py
"""
Exposes the public API of the API Services sub-package.
"""
__all__ = [
    "PluginQueryService",
    "VisualizationService",
]

from .plugin_query_service import PluginQueryService
from .visualization_service import VisualizationService

--- END FILE: services/api_services/__init__.py ---

--- START FILE: tests/__init__.py ---

--- END FILE: tests/__init__.py ---

--- START FILE: tests/backend/__init__.py ---

--- END FILE: tests/backend/__init__.py ---

--- START FILE: tests/backend/assembly/test_context_builder.py ---
# tests/backend/assembly/test_context_builder.py
"""Unit tests for the ContextBuilder."""

import pandas as pd
import pytest
from pytest_mock import MockerFixture

from backend.assembly.context_builder import ContextBuilder

# --- Test Setup: Maak een paar "nep"-workers ---

class MockWorkerAddColumn:
    """Een nep-worker die simpelweg een kolom toevoegt."""
    def __init__(self, new_col_name: str, value: int):
        self.new_col_name = new_col_name
        self.value = value

    def process(self, df: pd.DataFrame) -> pd.DataFrame:
        df[self.new_col_name] = self.value
        return df

class MockWorkerModifyColumn:
    """Een nep-worker die een bestaande kolom aanpast."""
    def __init__(self, target_col: str, multiplier: int):
        self.target_col = target_col
        self.multiplier = multiplier

    def process(self, df: pd.DataFrame) -> pd.DataFrame:
        df[self.target_col] = df[self.target_col] * self.multiplier
        return df

# --- De Tests ---

def test_context_builder_runs_pipeline_sequentially():
    """
    Tests of de ContextBuilder de workers in de juiste, sequentiële
    volgorde uitvoert.
    """
    # Arrange (De Voorbereiding)
    # 1. Maak een simpele start-DataFrame.
    initial_df = pd.DataFrame({'close': [10, 20, 30]})

    # 2. Maak instanties van onze nep-workers.
    worker1 = MockWorkerAddColumn(new_col_name="EMA_50", value=15)
    worker2 = MockWorkerModifyColumn(target_col="EMA_50", multiplier=2)

    # 3. Stel de ContextBuilder in met deze workers.
    context_builder = ContextBuilder()
    pipeline = [worker1, worker2]

    # Act (De Actie)
    # Voer de pijplijn uit.
    result_df = context_builder.build(initial_df, pipeline)

    # Assert (De Controle)
    # We controleren of het eindresultaat correct is.
    # Worker 1 zou de kolom "EMA_50" met waarde 15 moeten toevoegen.
    # Worker 2 zou die kolom moeten vermenigvuldigen met 2, dus de eindwaarde moet 30 zijn.
    assert "EMA_50" in result_df.columns
    assert result_df["EMA_50"].tolist() == [30, 30, 30]

def test_context_builder_returns_copy_of_dataframe():
    """
    Tests of de ContextBuilder een kopie van de DataFrame retourneert en
    de originele niet aanpast. Dit is belangrijk om onverwachte bijeffecten
    in de rest van de applicatie te voorkomen.
    """
    # Arrange
    initial_df = pd.DataFrame({'close': [10]})
    initial_df_copy = initial_df.copy() # Maak een kopie voor de controle achteraf.

    worker = MockWorkerAddColumn(new_col_name="EMA_50", value=15)
    context_builder = ContextBuilder()

    # Act
    result_df = context_builder.build(initial_df, [worker])

    # Assert
    # Controleer of de geretourneerde DataFrame de nieuwe kolom heeft.
    assert "EMA_50" in result_df.columns
    # Controleer of de *originele* DataFrame ongewijzigd is.
    assert "EMA_50" not in initial_df.columns
    # Vergelijk de originele DataFrame met zijn kopie om zeker te zijn.
    pd.testing.assert_frame_equal(initial_df, initial_df_copy)

--- END FILE: tests/backend/assembly/test_context_builder.py ---

--- START FILE: tests/backend/assembly/test_dependency_validator.py ---
# tests/backend/assembly/test_dependency_validator.py
"""Unit tests for the DependencyValidator."""

from typing import List, Optional
from pathlib import Path
import pytest
from pytest_mock import MockerFixture

from backend.assembly.dependency_validator import DependencyValidator
from backend.assembly.plugin_registry import PluginRegistry
from backend.config.schemas.plugin_manifest_schema import PluginManifest

# CORRECTIE: Type hints toegevoegd voor duidelijkheid en linter.
def create_mock_manifest(
    name: str,
    dependencies: Optional[List[str]] = None,
    provides: Optional[List[str]] = None
) -> PluginManifest:
    """Creates a mock PluginManifest for testing purposes."""
    return PluginManifest(
        name=name, version="1.0", type="structural_context",
        description="A test plugin.",
        entry_class="Dummy", schema_path="dummy.py", params_class="DummyParams",
        dependencies=dependencies or [],
        provides=provides or []
    )

def test_valid_pipeline_succeeds(mocker: MockerFixture):
    """Tests that a logically correct pipeline validates successfully."""
    # Arrange
    mock_registry = mocker.MagicMock(spec=PluginRegistry)
    mock_registry.get_plugin_data.side_effect = {
        "ema_50": (create_mock_manifest("ema_50", ["close"], ["EMA_50"]), Path("path1")),
        "rsi_14": (create_mock_manifest("rsi_14", ["close"], ["RSI_14"]), Path("path2")),
        "logic": (create_mock_manifest("logic", ["EMA_50", "RSI_14"]), Path("path3"))
    }.get

    validator = DependencyValidator(mock_registry)
    pipeline = ["ema_50", "rsi_14", "logic"]

    # Act & Assert
    assert validator.validate(pipeline) is True

def test_pipeline_with_missing_dependency_fails(mocker: MockerFixture):
    """Tests that a pipeline fails if a dependency is never provided."""
    # Arrange
    mock_registry = mocker.MagicMock(spec=PluginRegistry)
    mock_registry.get_plugin_data.side_effect = {
        "ema_50": (create_mock_manifest("ema_50", ["close"], ["EMA_50"]), Path("path1")),
        "logic": (create_mock_manifest("logic", ["COLUMN_THAT_DOES_NOT_EXIST"]), Path("path2"))
    }.get

    validator = DependencyValidator(mock_registry)
    pipeline = ["ema_50", "logic"]

    # Act & Assert
    error_msg = "Dependency 'COLUMN_THAT_DOES_NOT_EXIST' for plugin 'logic' not met."
    with pytest.raises(ValueError, match=error_msg):
        validator.validate(pipeline)

def test_pipeline_with_incorrect_order_fails(mocker: MockerFixture):
    """Tests that a pipeline fails if dependencies are not met due to wrong order."""
    # Arrange
    mock_registry = mocker.MagicMock(spec=PluginRegistry)
    mock_registry.get_plugin_data.side_effect = {
        "logic": (create_mock_manifest("logic", ["EMA_50"]), Path("path1")),
        "ema_50": (create_mock_manifest("ema_50", ["close"], ["EMA_50"]), Path("path2")),
    }.get

    validator = DependencyValidator(mock_registry)
    pipeline = ["logic", "ema_50"]

    # Act & Assert
    with pytest.raises(ValueError, match="Dependency 'EMA_50' for plugin 'logic' not met."):
        validator.validate(pipeline)

--- END FILE: tests/backend/assembly/test_dependency_validator.py ---

--- START FILE: tests/backend/assembly/test_engine_builder.py ---
# tests/backend/assembly/test_engine_builder.py
"""
Unit tests for the EngineBuilder class.
"""
from unittest.mock import call
from pytest_mock import MockerFixture

from backend.assembly.engine_builder import EngineBuilder
from backend.assembly.worker_builder import WorkerBuilder
from backend.config.schemas.run_schema import RunBlueprint, WorkerDefinition
from backend.core.enums import PipelinePhase

def test_build_context_pipeline(mocker: MockerFixture):
    """
    Tests if the context pipeline is built correctly by only requesting
    workers from the STRUCTURAL_CONTEXT phase.
    """
    # --- Arrange ---
    mock_worker_builder = mocker.MagicMock(spec=WorkerBuilder)
    mock_run_conf = mocker.MagicMock(spec=RunBlueprint)

    # --- DE FIX: Maak de geneste mock-structuur voor de taskboard ---
    mock_taskboard = mocker.MagicMock()
    mock_taskboard.root = {
        PipelinePhase.STRUCTURAL_CONTEXT: ["worker_a", "worker_b"],
        PipelinePhase.SIGNAL_GENERATOR: ["worker_c"]  # Should be ignored
    }
    mock_run_conf.taskboard = mock_taskboard
    # ----------------------------------------------------------------

    # --- DE FIX: Mock ook de workforce met een get methode ---
    mock_workforce = mocker.MagicMock()
    mock_workforce.get.return_value = WorkerDefinition()
    mock_run_conf.workforce = mock_workforce
    # ---------------------------------------------------------

    # --- Act ---
    builder = EngineBuilder(worker_builder=mock_worker_builder)
    builder.build_context_pipeline(run_conf=mock_run_conf)

    # --- Assert ---
    # Verify that 'build' was called only for the context workers
    expected_calls = [
        call(name="worker_a", user_params={}),
        call(name="worker_b", user_params={})
    ]
    mock_worker_builder.build.assert_has_calls(expected_calls, any_order=True)
    assert mock_worker_builder.build.call_count == 2

def test_build_engine(mocker: MockerFixture):
    """
    Tests if the StrategyEngine is assembled correctly with workers from all
    phases EXCEPT the STRUCTURAL_CONTEXT phase.
    """
    # --- Arrange ---
    mock_worker_builder = mocker.MagicMock(spec=WorkerBuilder)
    mock_strategy_engine_class = mocker.patch('backend.assembly.engine_builder.StrategyEngine')
    mock_run_conf = mocker.MagicMock(spec=RunBlueprint)

    # --- DE FIX: Maak de geneste mock-structuur voor de taskboard ---
    mock_taskboard = mocker.MagicMock()
    mock_taskboard.root = {
        PipelinePhase.STRUCTURAL_CONTEXT: ["context_worker"],  # Should be ignored
        PipelinePhase.SIGNAL_GENERATOR: ["signal_worker_1"],
        PipelinePhase.SIGNAL_REFINER: ["refiner_worker_1", "refiner_worker_2"]
    }
    mock_run_conf.taskboard = mock_taskboard
    # ----------------------------------------------------------------

    # --- DE FIX: Mock ook de workforce met een get methode ---
    mock_workforce = mocker.MagicMock()
    mock_workforce.get.return_value = WorkerDefinition()
    mock_run_conf.workforce = mock_workforce
    # ---------------------------------------------------------

    # --- Act ---
    builder = EngineBuilder(worker_builder=mock_worker_builder)
    builder.build_engine(run_conf=mock_run_conf)

    # --- Assert ---
    # Verify the worker_builder was called for the correct, non-context workers
    expected_build_calls = [
        call(name="signal_worker_1", user_params={}),
        call(name="refiner_worker_1", user_params={}),
        call(name="refiner_worker_2", user_params={})
    ]
    mock_worker_builder.build.assert_has_calls(expected_build_calls, any_order=True)
    assert mock_worker_builder.build.call_count == 3

    # Verify the StrategyEngine was instantiated with the correctly grouped workers
    active_workers_arg = mock_strategy_engine_class.call_args[1]['active_workers']

    assert PipelinePhase.SIGNAL_GENERATOR.value in active_workers_arg
    assert len(active_workers_arg[PipelinePhase.SIGNAL_GENERATOR.value]) == 1

    assert PipelinePhase.SIGNAL_REFINER.value in active_workers_arg
    assert len(active_workers_arg[PipelinePhase.SIGNAL_REFINER.value]) == 2

    # Crucially, assert that the context phase was NOT included in the engine's workers
    assert PipelinePhase.STRUCTURAL_CONTEXT.value not in active_workers_arg

--- END FILE: tests/backend/assembly/test_engine_builder.py ---

--- START FILE: tests/backend/assembly/test_plugin_registry.py ---
# tests/backend/assembly/test_plugin_registry.py
"""Unit tests for the PluginRegistry."""

import yaml
from pathlib import Path
from unittest.mock import MagicMock

from backend.assembly.plugin_registry import PluginRegistry
from backend.config.schemas.platform_schema import PlatformConfig

def test_plugin_registry_discovers_and_validates_plugins(tmp_path: Path):
    """
    Tests if the registry correctly finds valid plugins and ignores invalid ones.
    """
    # Arrange (De Voorbereiding)
    # 1. Maak een tijdelijke, realistische plugin-structuur aan.
    plugins_root = tmp_path / "plugins"
    
    # Een valide plugin
    valid_plugin_path = plugins_root / "structural_context" / "valid_plugin"
    valid_plugin_path.mkdir(parents=True)
    valid_manifest = {
        "name": "valid_plugin", "version": "1.0", "type": "structural_context",
        "description": "A valid test plugin.", "entry_class": "ValidWorker",
        "schema_path": "schema.py", "params_class": "ValidParams"
    }
    with open(valid_plugin_path / "plugin_manifest.yaml", "w") as f:
        yaml.dump(valid_manifest, f)

    # Een plugin met een ongeldig manifest (mist 'type')
    invalid_plugin_path = plugins_root / "structural_context" / "invalid_plugin"
    invalid_plugin_path.mkdir(parents=True)
    invalid_manifest = {"name": "invalid_plugin", "version": "1.0"}
    with open(invalid_plugin_path / "plugin_manifest.yaml", "w") as f:
        yaml.dump(invalid_manifest, f)
        
    # 2. Configureer het systeem om onze tijdelijke map te gebruiken.
    mock_config = MagicMock(spec=PlatformConfig)
    mock_config.plugins_root_path = str(plugins_root)
    mock_logger = MagicMock()

    # Act (De Actie)
    registry = PluginRegistry(platform_config=mock_config, logger=mock_logger)

    # Assert (De Controle)
    all_manifests = registry.get_all_manifests()
    assert len(all_manifests) == 1, "Should only register the one valid plugin."
    assert "valid_plugin" in all_manifests, "The valid plugin should be registered."
    assert "invalid_plugin" not in all_manifests, "The invalid plugin should be ignored."
    
    # Controleer of er een waarschuwing is gelogd voor het ongeldige manifest.
    assert mock_logger.warning.call_count > 0

--- END FILE: tests/backend/assembly/test_plugin_registry.py ---

--- START FILE: tests/backend/assembly/test_worker_builder.py ---
# tests/backend/assembly/test_worker_builder.py
"""Unit tests for the WorkerBuilder."""

from pathlib import Path
from unittest.mock import MagicMock

from pydantic import BaseModel, ValidationError
from pytest_mock import MockerFixture

from backend.assembly.worker_builder import WorkerBuilder
from backend.assembly.plugin_registry import PluginRegistry

# --- Test Setup: Maak een nep-omgeving ---

class MockParams(BaseModel):
    """Een nep Pydantic-schema voor een plugin."""
    value: int

class MockWorker:
    """Een nep worker-klasse."""
    def __init__(self, name: str, params: MockParams, logger):
        self.name = name
        self.params = params
        self.logger = logger

def test_worker_builder_successfully_builds_worker(mocker: MockerFixture):
    """
    Tests the happy path: building a valid worker with correct parameters.
    """
    # Arrange
    mock_registry = mocker.MagicMock(spec=PluginRegistry)
    mock_logger = mocker.MagicMock()
    
    mock_manifest = mocker.MagicMock(
        params_class="MockParams", entry_class="MockWorker",
        schema_path="schema.py"
    )
    # CORRECTIE: Geef een Path-object terug, geen string.
    mock_registry.get_plugin_data.return_value = (mock_manifest, Path("dummy/path"))
    
    mocker.patch(
        "backend.assembly.worker_builder.load_class_from_module",
        side_effect=[MockParams, MockWorker]
    )
    
    builder = WorkerBuilder(mock_registry, mock_logger)
    
    # Act
    worker_instance = builder.build(name="my_worker", user_params={"value": 123})
    
    # Assert
    assert isinstance(worker_instance, MockWorker)
    assert worker_instance.name == "my_worker"
    assert worker_instance.params.value == 123
    mock_logger.info.assert_called_with("Successfully built worker 'my_worker'.")

def test_worker_builder_fails_on_invalid_params(mocker: MockerFixture):
    """
    Tests if the builder correctly fails when user parameters are invalid.
    """
    # Arrange
    mock_registry = mocker.MagicMock(spec=PluginRegistry)
    mock_logger = mocker.MagicMock()
    
    mock_manifest = mocker.MagicMock(
        params_class="MockParams", entry_class="MockWorker",
        schema_path="schema.py"
    )
    # CORRECTIE: Geef een Path-object terug, geen string.
    mock_registry.get_plugin_data.return_value = (mock_manifest, Path("dummy/path"))

    mocker.patch(
        "backend.assembly.worker_builder.load_class_from_module",
        side_effect=[MockParams, MockWorker]
    )
    
    builder = WorkerBuilder(mock_registry, mock_logger)
    
    # Act
    worker_instance = builder.build(name="my_worker", user_params={"value": "not-an-int"})

    # Assert
    assert worker_instance is None
    mock_logger.error.assert_called_once()
    assert "Invalid parameters for worker 'my_worker'" in mock_logger.error.call_args[0][0]

--- END FILE: tests/backend/assembly/test_worker_builder.py ---

--- START FILE: tests/backend/assembly/__init__.py ---

--- END FILE: tests/backend/assembly/__init__.py ---

--- START FILE: tests/backend/core/test_context_recoreder.py ---
# tests/backend/core/test_context_recorder.py
"""Unit tests for the ContextRecorder."""

import uuid
from datetime import datetime
import pandas as pd
from pydantic import BaseModel

from backend.core.context_recorder import ContextRecorder

# --- Test Setup ---

class MockContextObject(BaseModel):
    """Een simpele Pydantic-klasse om een context-object te simuleren."""
    value: int
    label: str

# --- De Test ---

def test_context_recorder_adds_and_serializes_data():
    """
    Tests if the ContextRecorder correctly adds data, serializes the Pydantic
    model, and structures the log correctly.
    """
    # Arrange (De Voorbereiding)
    recorder = ContextRecorder()
    
    test_timestamp = pd.to_datetime("2023-01-01 10:00:00", utc=True)
    test_specialist = "my_test_plugin"
    test_context_obj = MockContextObject(value=123, label="test")
    test_corr_id = uuid.uuid4()

    # Act (De Actie)
    # Voeg de data toe aan de recorder. Dit is de methode die we testen.
    recorder.add_data(
        correlation_id=test_corr_id,
        timestamp=test_timestamp,
        specialist_name=test_specialist,
        context_object=test_context_obj
    )

    # Assert (De Controle)
    # 1. Haal alle data op uit de recorder.
    all_data = recorder.get_all_data()

    # 2. Controleer de structuur.
    assert test_timestamp in all_data, "Timestamp should be the primary key."
    assert test_specialist in all_data[test_timestamp], "Specialist name should be the secondary key."

    # 3. Controleer de inhoud.
    logged_context = all_data[test_timestamp][test_specialist]
    
    # Is het Pydantic-object correct omgezet naar een dictionary?
    assert isinstance(logged_context, dict)
    assert logged_context['value'] == 123
    assert logged_context['label'] == "test"
    
    # Is de correlation_id correct toegevoegd?
    assert 'correlation_id' in logged_context
    assert logged_context['correlation_id'] == str(test_corr_id)

--- END FILE: tests/backend/core/test_context_recoreder.py ---

--- START FILE: tests/backend/core/test_directive_flattener.py ---
# tests/backend/core/test_directive_flattener.py
"""
Unit tests for the DirectiveFlattener utility.
"""

import uuid
import pandas as pd
from backend.dtos.signal import Signal
from backend.dtos.entry_signal import EntrySignal
from backend.dtos.risk_defined_signal import RiskDefinedSignal
from backend.dtos.trade_plan import TradePlan
from backend.dtos.routed_trade_plan import RoutedTradePlan
from backend.dtos.execution_directive import ExecutionDirective
from backend.core.directive_flattener import DirectiveFlattener

def test_flatten_routed_trade_plan_to_directive():
    """
    Tests if a deeply nested RoutedTradePlan is correctly flattened into a
    simple ExecutionDirective.
    """
    # --- Arrange (De Voorbereiding) ---
    test_corr_id = uuid.uuid4()
    test_timestamp = pd.Timestamp("2023-01-01 10:00:00", tz='UTC')

    signal = Signal(correlation_id=test_corr_id, timestamp=test_timestamp, asset="BTC/EUR", direction="long", signal_type="fvg_entry_signal")
    entry_signal = EntrySignal(correlation_id=test_corr_id, signal=signal, entry_price=25000.0)
    risk_defined_signal = RiskDefinedSignal(correlation_id=test_corr_id, entry_signal=entry_signal, sl_price=24800.0, tp_price=25500.0)
    trade_plan = TradePlan(correlation_id=test_corr_id, risk_defined_signal=risk_defined_signal, position_value_quote=1000.0, position_size_asset=0.04)
    routed_trade_plan = RoutedTradePlan(correlation_id=test_corr_id, trade_plan=trade_plan, order_type='limit', limit_price=25000.0, time_in_force='GTC', post_only=True)
    
    expected_directive = ExecutionDirective(
        correlation_id=test_corr_id,
        signal_type="fvg_entry_signal",
        asset="BTC/EUR",
        direction="long",
        entry_price=25000.0,
        sl_price=24800.0,
        tp_price=25500.0,
        position_value_quote=1000.0,
        position_size_asset=0.04,
        order_type='limit',
        limit_price=25000.0,
        time_in_force='GTC',
        post_only=True,
        entry_time=test_timestamp
    )

    # --- Act (De Actie) ---
    flattener = DirectiveFlattener()
    actual_directive = flattener.flatten(routed_trade_plan)

    # --- Assert (De Controle) ---
    assert actual_directive == expected_directive

--- END FILE: tests/backend/core/test_directive_flattener.py ---

--- START FILE: tests/backend/core/test_portfolio.py ---
# tests/backend/core/test_portfolio.py
import pytest
import uuid
import pandas as pd

from backend.core.interfaces.portfolio import Tradable
from backend.core.portfolio import Portfolio
from backend.dtos.execution_directive import ExecutionDirective

class MockLogger:
    def info(self, *args, **kwargs): pass
    def trade(self, *args, **kwargs): pass
    def error(self, *args, **kwargs): pass

class MockContextRecorder:
    def add_data(self, *args, **kwargs): pass

@pytest.fixture
def empty_portfolio() -> Portfolio:
    return Portfolio(
        initial_capital=10000.0, fees_pct=0.001,
        logger=MockLogger(), context_recorder=MockContextRecorder()
    )

@pytest.fixture
def sample_directive() -> ExecutionDirective:
    """A fixture for a sample long execution directive."""
    return ExecutionDirective(
        correlation_id=uuid.uuid4(),
        signal_type='TEST_SIGNAL_LONG',
        entry_time=pd.to_datetime("2023-01-01 10:00:00"),
        asset="BTC/EUR",
        direction='long',
        entry_price=20000.0,
        sl_price=19800.0,
        tp_price=20400.0,
        position_value_quote=1000.0,
        position_size_asset=0.05,
        order_type='limit'  # Toegevoegd verplicht veld
    )

@pytest.fixture
def sample_short_directive() -> ExecutionDirective:
    """A fixture for a sample short execution directive."""
    return ExecutionDirective(
        correlation_id=uuid.uuid4(),
        signal_type='TEST_SIGNAL_SHORT',
        entry_time=pd.to_datetime("2023-01-02 10:00:00"),
        asset="ETH/EUR",
        direction='short',
        entry_price=1500.0,
        sl_price=1520.0,
        tp_price=1460.0,
        position_value_quote=1500.0,
        position_size_asset=1.0,
        order_type='market' # Toegevoegd verplicht veld
    )

# --- Test Cases ---

def test_portfolio_fulfills_tradable_contract(empty_portfolio: Portfolio):
    assert isinstance(empty_portfolio, Tradable)

def test_portfolio_initialization(empty_portfolio: Portfolio):
    assert empty_portfolio.balance == 10000.0
    assert empty_portfolio.initial_capital == 10000.0
    assert not empty_portfolio.active_trades
    assert len(empty_portfolio.closed_trades) == 0

def test_open_trade_success(empty_portfolio: Portfolio, sample_directive: ExecutionDirective):
    empty_portfolio.open_trade(sample_directive)
    assert len(empty_portfolio.active_trades) == 1
    active_trade_data = empty_portfolio.active_trades[sample_directive.correlation_id]
    assert active_trade_data['direction'] == 'long'
    assert active_trade_data['entry_price'] == 20000.0
    assert active_trade_data['position_size_asset'] == 0.05

def test_open_multiple_trades_on_different_assets(empty_portfolio: Portfolio, sample_directive: ExecutionDirective):
    eth_directive = sample_directive.model_copy(update={
        'correlation_id': uuid.uuid4(),
        'signal_type': 'TEST_SIGNAL_ETH_LONG',
        'entry_time': pd.to_datetime("2023-01-01 11:00:00"),
        'asset': "ETH/EUR",
        'entry_price': 1500.0,
        'sl_price': 1480.0,
        'tp_price': 1550.0,
        'position_value_quote': 500.0,
        'position_size_asset': 0.33
    })
    empty_portfolio.open_trade(sample_directive)
    empty_portfolio.open_trade(eth_directive)
    
    active_trades_dict = empty_portfolio.active_trades
    assert len(active_trades_dict) == 2
    assert sample_directive.correlation_id in active_trades_dict
    assert eth_directive.correlation_id in active_trades_dict

def test_process_candle_closes_long_trade_on_stop_loss(empty_portfolio: Portfolio, sample_directive: ExecutionDirective):
    empty_portfolio.open_trade(sample_directive)
    assert empty_portfolio.active_trade_count == 1

    candle_timestamp = pd.to_datetime("2023-01-01 11:00:00")
    killer_candle = pd.Series({
        "open": 19900.0, "high": 19950.0,
        "low": 19800.0, "close": 19850.0
    }, name=candle_timestamp)

    empty_portfolio.process_candle(killer_candle)

    assert empty_portfolio.active_trade_count == 0
    assert len(empty_portfolio.closed_trades) == 1

    closed_trade = empty_portfolio.closed_trades[0]
    assert closed_trade.exit_price == 19800.0
    assert closed_trade.pnl_quote < 0

def test_process_candle_closes_long_trade_on_take_profit(empty_portfolio: Portfolio, sample_directive: ExecutionDirective):
    empty_portfolio.open_trade(sample_directive)
    assert empty_portfolio.active_trade_count == 1

    profit_candle_timestamp = pd.to_datetime("2023-01-01 12:00:00")
    profit_candle = pd.Series({
        "open": 20200.0, "high": 20400.0,
        "low": 20150.0, "close": 20350.0
    }, name=profit_candle_timestamp)

    empty_portfolio.process_candle(profit_candle)

    assert empty_portfolio.active_trade_count == 0
    assert len(empty_portfolio.closed_trades) == 1

    closed_trade = empty_portfolio.closed_trades[0]
    assert closed_trade.exit_price == 20400.0
    assert closed_trade.pnl_quote > 0

def test_process_candle_closes_short_trade_on_stop_loss(empty_portfolio: Portfolio, sample_short_directive: ExecutionDirective):
    empty_portfolio.open_trade(sample_short_directive)
    assert empty_portfolio.active_trade_count == 1

    killer_candle_timestamp = pd.to_datetime("2023-01-02 11:00:00")
    killer_candle = pd.Series({
        "open": 1510.0, "high": 1520.0,
        "low": 1505.0, "close": 1515.0
    }, name=killer_candle_timestamp)

    empty_portfolio.process_candle(killer_candle)

    assert empty_portfolio.active_trade_count == 0
    assert len(empty_portfolio.closed_trades) == 1

    closed_trade = empty_portfolio.closed_trades[0]
    assert closed_trade.exit_price == 1520.0
    assert closed_trade.pnl_quote < 0

def test_process_candle_closes_short_trade_on_take_profit(empty_portfolio: Portfolio, sample_short_directive: ExecutionDirective):
    empty_portfolio.open_trade(sample_short_directive)
    assert empty_portfolio.active_trade_count == 1

    profit_candle_timestamp = pd.to_datetime("2023-01-02 12:00:00")
    profit_candle = pd.Series({
        "open": 1470.0, "high": 1475.0,
        "low": 1460.0, "close": 1465.0
    }, name=profit_candle_timestamp)

    empty_portfolio.process_candle(profit_candle)

    assert empty_portfolio.active_trade_count == 0
    assert len(empty_portfolio.closed_trades) == 1

    closed_trade = empty_portfolio.closed_trades[0]
    assert closed_trade.exit_price == 1460.0
    assert closed_trade.pnl_quote > 0

--- END FILE: tests/backend/core/test_portfolio.py ---

--- START FILE: tests/backend/core/test_strategy_engine.py ---
# tests/backend/core/test_strategy_engine.py
"""Unit tests for the StrategyEngine."""

import uuid
import pandas as pd
from pytest_mock import MockerFixture

from backend.dtos import (
    Signal, EntrySignal, RiskDefinedSignal, TradePlan, RoutedTradePlan,
    TradingContext, EngineCycleResult, ExecutionDirective, CriticalEvent
)
from backend.core.interfaces import Clock
from backend.core.strategy_engine import StrategyEngine
from backend.core.directive_flattener import DirectiveFlattener

def test_strategy_engine_yields_correct_result(mocker: MockerFixture):
    """
    Tests that the StrategyEngine correctly processes the full 9-phase pipeline
    and yields a final, complete EngineCycleResult.
    """
    # --- Arrange (De Voorbereiding) ---
    mock_clock = mocker.MagicMock(spec=Clock)
    test_time = pd.Timestamp("2023-01-01 10:00:00", tz='UTC')
    mock_clock.tick.return_value = [(test_time, pd.Series())]
    corr_id = uuid.uuid4()

    # 1. Bouw de volledige, geneste DTO-keten op
    signal_dto = Signal(correlation_id=corr_id, timestamp=test_time, asset="BTC/EUR", direction="long", signal_type="test_signal")
    entry_signal_dto = EntrySignal(correlation_id=corr_id, signal=signal_dto, entry_price=100.0)
    risk_defined_dto = RiskDefinedSignal(correlation_id=corr_id, entry_signal=entry_signal_dto, sl_price=95.0, tp_price=110.0)
    trade_plan_dto = TradePlan(correlation_id=corr_id, risk_defined_signal=risk_defined_dto, position_value_quote=10000.0, position_size_asset=1.0)
    routed_plan_dto = RoutedTradePlan(correlation_id=corr_id, trade_plan=trade_plan_dto, order_type='limit', limit_price=100.0)
    
    expected_directive = DirectiveFlattener().flatten(routed_plan_dto)

    # 2. Mocks voor elke worker, nu geconfigureerd voor de .process() methode
    # --- DE FIX: Gebruik overal .process in de mocks ---
    mock_signal_generator = mocker.MagicMock(process=mocker.Mock(return_value=[signal_dto]))
    mock_signal_refiner = mocker.MagicMock(process=mocker.Mock(return_value=signal_dto))
    mock_entry_planner = mocker.MagicMock(process=mocker.Mock(return_value=entry_signal_dto))
    mock_exit_planner = mocker.MagicMock(process=mocker.Mock(return_value=risk_defined_dto))
    mock_size_planner = mocker.MagicMock(process=mocker.Mock(return_value=trade_plan_dto))
    mock_order_router = mocker.MagicMock(process=mocker.Mock(return_value=routed_plan_dto))
    mock_event_detector = mocker.MagicMock(process=mocker.Mock(return_value=[]))

    active_workers = {
        'signal_generator': [mock_signal_generator],
        'signal_refiner': [mock_signal_refiner],
        'entry_planner': mock_entry_planner,
        'exit_planner': mock_exit_planner,
        'size_planner': mock_size_planner,
        'order_router': [mock_order_router],
        'critical_event_detector': [mock_event_detector]
    }

    # --- Act (De Actie) ---
    engine = StrategyEngine(active_workers=active_workers)
    cycle_results = list(engine.run(
        trading_context=mocker.MagicMock(spec=TradingContext),
        clock=mock_clock
    ))

    # --- Assert (De Controle) ---
    assert len(cycle_results) == 1
    result = cycle_results[0]
    
    assert isinstance(result, EngineCycleResult)
    assert len(result.execution_directives) == 1
    assert len(result.critical_events) == 0
    assert result.execution_directives[0] == expected_directive

    # Valideer dat de correcte methodes zijn aangeroepen
    mock_signal_generator.process.assert_called_once()
    mock_signal_refiner.process.assert_called_once_with(signal_dto, mocker.ANY)
    mock_entry_planner.process.assert_called_once_with(signal_dto, mocker.ANY)
    mock_exit_planner.process.assert_called_once_with(entry_signal_dto, mocker.ANY)
    mock_size_planner.process.assert_called_once_with(risk_defined_dto, mocker.ANY)
    mock_order_router.process.assert_called_once_with(trade_plan_dto, mocker.ANY)
    mock_event_detector.process.assert_called_once()

--- END FILE: tests/backend/core/test_strategy_engine.py ---

--- START FILE: tests/backend/data/test_data_loader.py ---
# tests/backend/data/test_data_loader.py
"""Unit tests for the DataLoader."""

import os
import re # <-- Importeer de 're' module
from pathlib import Path
import pandas as pd
import pytest
from pytest_mock import MockerFixture

from backend.data.loader import DataLoader

def test_data_loader_successfully_loads_csv(tmp_path: Path, mocker: MockerFixture):
    """
    Tests if the DataLoader correctly reads a valid CSV file, sets the index,
    and returns a DataFrame.
    """
    # Arrange
    csv_content = "timestamp,open,high,low,close,volume\n" \
                  "2023-01-01 10:00:00,100,105,99,102,1000\n" \
                  "2023-01-01 10:01:00,102,103,101,102,500"
    
    data_file = tmp_path / "test_data.csv"
    data_file.write_text(csv_content)
    
    mock_logger = mocker.MagicMock()

    # Act
    loader = DataLoader(file_path=str(data_file), logger=mock_logger)
    df = loader.load()

    # Assert
    assert isinstance(df, pd.DataFrame)
    assert len(df) == 2
    assert isinstance(df.index, pd.DatetimeIndex)
    assert df.index.name == "timestamp"
    mock_logger.info.assert_called_with('loader.load_success')

def test_data_loader_raises_error_for_nonexistent_file(mocker: MockerFixture):
    """
    Tests if the DataLoader raises a FileNotFoundError when the file does not exist.
    This test is now platform-independent.
    """
    # Arrange
    # Bouw het pad op een platform-onafhankelijke manier.
    non_existent_path = os.path.join("path", "that", "does", "not", "exist.csv")
    mock_logger = mocker.MagicMock()

    # CORRECTIE: "Escape" de pad-string zodat de regex-engine backslashes
    # als letterlijke tekens behandelt en niet als speciale codes.
    expected_error_pattern = re.escape(non_existent_path)

    # Act & Assert
    with pytest.raises(FileNotFoundError, match=expected_error_pattern):
        DataLoader(file_path=non_existent_path, logger=mock_logger)

--- END FILE: tests/backend/data/test_data_loader.py ---

--- START FILE: tests/backend/data/__init__.py ---

--- END FILE: tests/backend/data/__init__.py ---

--- START FILE: tests/backend/environments/test_backtest_environment.py ---
# tests/backend/environments/test_backtest_environment.py
"""Unit tests for the BacktestEnvironment."""

import pandas as pd
from pytest_mock import MockerFixture

from backend.environments.backtest_environment import (
    BacktestEnvironment, CSVDataSource, SimulatedClock, BacktestExecutionHandler
)
from backend.core.interfaces import Tradable
from backend.config.schemas.app_schema import AppConfig
from backend.config.schemas.platform_schema import PlatformConfig, PlatformDataConfig
from backend.config.schemas.run_schema import RunBlueprint, RunDataConfig

def test_backtest_environment_initialization(mocker: MockerFixture):
    """
    Tests if the BacktestEnvironment correctly initializes its
    specialized sub-components.
    """
    # Arrange
    mock_df = pd.DataFrame({'close': [1, 2, 3]})
    mocker.patch("backend.data.loader.DataLoader.load", return_value=mock_df)
    mocker.patch("backend.data.loader.DataLoader.__init__", return_value=None)

    # --- DE FIX: Bouw een correcte, geneste mock AppConfig ---
    mock_app_config = mocker.MagicMock(spec=AppConfig)
    mock_app_config.platform = mocker.MagicMock(spec=PlatformConfig)
    mock_app_config.run = mocker.MagicMock(spec=RunBlueprint)

    # Definieer de geneste data-objecten
    mock_app_config.platform.data = mocker.MagicMock(spec=PlatformDataConfig)
    mock_app_config.run.data = mocker.MagicMock(spec=RunDataConfig)

    # Wijs de waarden toe op de juiste, geneste locatie
    mock_app_config.platform.data.source_dir = "mock_data_dir"
    mock_app_config.run.data.trading_pair = "BTC/EUR"
    mock_app_config.run.data.timeframe = "1h"

    mock_portfolio = mocker.MagicMock(spec=Tradable)

    # Act
    environment = BacktestEnvironment(
        app_config=mock_app_config,
        tradable=mock_portfolio
    )

    # Assert
    assert isinstance(environment.source, CSVDataSource)
    assert isinstance(environment.clock, SimulatedClock)
    assert isinstance(environment.handler, BacktestExecutionHandler)

--- END FILE: tests/backend/environments/test_backtest_environment.py ---

--- START FILE: tests/backend/environments/__init__.py ---

--- END FILE: tests/backend/environments/__init__.py ---

--- START FILE: tests/services/test_strategy_operator.py ---
# tests/services/test_strategy_operator.py
"""
Unit tests for the refactored StrategyOperator service.
"""
from pytest_mock import MockerFixture

# De klasse die we gaan testen
from services.strategy_operator import StrategyOperator

# De klassen die we gaan mocken
from backend.config.schemas.app_schema import AppConfig

def test_strategy_operator_run_orchestration(mocker: MockerFixture):
    """
    Tests if the main `run` method correctly calls the private helper
    methods in the correct order, confirming its role as a pure orchestrator.
    """
    # --- Arrange ---
    # Mock the private helper methods that contain the actual logic
    mock_prepare_components = mocker.patch(
        'services.strategy_operator.StrategyOperator._prepare_components'
    )
    mock_prepare_data = mocker.patch('services.strategy_operator.StrategyOperator._prepare_data')
    mock_run_cycle = mocker.patch(
        'services.strategy_operator.StrategyOperator._run_operational_cycle'
    )

    # Create dummy config and logger for instantiation
    mock_app_config = mocker.MagicMock(spec=AppConfig)
    mock_logger = mocker.MagicMock()

    # --- Act ---
    operator = StrategyOperator(app_config=mock_app_config, logger=mock_logger)
    operator.run()

    # --- Assert ---
    # Verify that the main orchestration methods were called exactly once
    mock_prepare_components.assert_called_once()
    mock_prepare_data.assert_called_once()
    mock_run_cycle.assert_called_once()

--- END FILE: tests/services/test_strategy_operator.py ---

--- START FILE: tools/bootstrap_v2.py ---
# bootstrap_v2.py
"""
This script generates the complete directory and file skeleton for the S1mpleTrader V2 architecture.

It creates all necessary directories and populates them with initial files,
including boilerplate content like file headers and class definitions, adhering
to the project's coding standards.

@layer: Tool
@dependencies:
    - os
    - pathlib
@responsibilities:
    - Creates the main directory structure for the V2 application.
    - Generates placeholder files with correct headers and initial content.
    - Establishes a clean, consistent starting point for V2 development.
@inputs: None
@outputs: A complete directory structure on the filesystem.
"""

import os
from pathlib import Path

# --- Configuration ---
ROOT_DIR = Path("S1mpleTrader_V2")

# The full directory and file structure based on our architecture design
STRUCTURE = {
    "config": {
        "runs": {"mss_fvg_strategy.yaml": "# V2 Strategy Blueprint: MSS with FVG Entry"},
        "optimizations": {"optimize_atr_params.yaml": "# V2 Optimization Blueprint: Tune ATR Exit Parameters"},
        "variants": {"robustness_test.yaml": "# V2 Variant Test: Test strategy across multiple markets"},
        "overrides": {"use_eth_pair.yaml": "# V2 Override: Switch trading pair to ETH/EUR"},
        "index.yaml": "# Central index mapping short names to blueprint file paths",
        "platform.yaml": "# Global platform settings: portfolio, logging, etc.",
    },
    "plugins": {
        "regime_filters": {
            "adx_trend_filter": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: adx_trend_filter\ntype: regime_filter\n...",
                "worker.py": "AdxTrendFilter",
                "schema.py": "AdxTrendFilterParams",
                "tests": {"test_worker.py": "TestAdxTrendFilter"},
            }
        },
        "structural_context": {
            "market_structure_detector": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: market_structure_detector\ntype: structural_context\n...",
                "worker.py": "MarketStructureDetector",
                "schema.py": "MarketStructureDetectorParams",
                "tests": {"test_worker.py": "TestMarketStructureDetector"},
            }
        },
        "signal_generators": {
            "fvg_entry_detector": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: fvg_entry_detector\ntype: signal_generator\n...",
                "worker.py": "FvgEntryDetector",
                "schema.py": "FvgEntryDetectorParams",
                "tests": {"test_worker.py": "TestFvgEntryDetector"},
            }
        },
        "signal_refiners": {
            "volume_spike_refiner": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: volume_spike_refiner\ntype: signal_refiner\n...",
                "worker.py": "VolumeSpikeRefiner",
                "schema.py": "VolumeSpikeRefinerParams",
                "tests": {"test_worker.py": "TestVolumeSpikeRefiner"},
            }
        },
        "trade_constructors": {
            "liquidity_target_exit": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: liquidity_target_exit\ntype: trade_constructor\n...", # This would likely be an exit planner
                "worker.py": "LiquidityTargetExitPlanner",
                "schema.py": "LiquidityTargetExitParams",
                "tests": {"test_worker.py": "TestLiquidityTargetExitPlanner"},
            }
        },
        "portfolio_overlays": {
            "max_drawdown_overlay": {
                "__init__.py": None,
                "plugin_manifest.yaml": "name: max_drawdown_overlay\ntype: portfolio_overlay\n...",
                "worker.py": "MaxDrawdownOverlay",
                "schema.py": "MaxDrawdownOverlayParams",
                "tests": {"test_worker.py": "TestMaxDrawdownOverlay"},
            }
        },
    },
    "backend": {
        "config": {"schemas": {"__init__.py": None, "app_schema.py": "AppConfig", "blueprint_schema.py": "BlueprintConfig"}},
        "assembly": {
            "__init__.py": None,
            "plugin_registry.py": "PluginRegistry",
            "worker_builder.py": "WorkerBuilder",
            "context_pipeline_runner.py": "ContextPipelineRunner",
        },
        "core": {
            "__init__.py": None,
            "portfolio.py": "Portfolio",
            "execution.py": "ExecutionHandler",
            "performance_analyzer.py": "PerformanceAnalyzer",
            "interfaces.py": "# Contains abstract base classes like Tradable",
            "constants.py": "# Application-wide constants",
        },
        "environments": {
            "__init__.py": None,
            "base_environment.py": "ExecutionEnvironment",
            "backtest_environment.py": "BacktestEnvironment",
            "paper_environment.py": "PaperTradeEnvironment",
            "live_environment.py": "LiveTradeEnvironment",
        },
        "dtos": {
            "__init__.py": None,
            "signal.py": "# Signal DTO dataclass",
            "trade.py": "# Trade DTO dataclass",
            "closed_trade.py": "# ClosedTrade DTO dataclass",
            "backtest_result.py": "# BacktestResult DTO dataclass",
        },
        "utils": {
            "__init__.py": None,
            "app_logger.py": "LogEnricher",
            "translator.py": "Translator",
            "data_utils.py": "# Utility functions for data manipulation",
        },
    },
    "services": {
        "__init__.py": None,
        "strategy_orchestrator.py": "StrategyOrchestrator",
        "optimization_service.py": "OptimizationService",
        "variant_test_service.py": "VariantTestService",
        "parallel_run_service.py": "ParallelRunService",
        "api_services": {
            "__init__.py": None,
            "plugin_query_service.py": "PluginQueryService",
            "visualization_service.py": "VisualizationService",
        },
    },
    "frontends": {
        "web": {
            "api": {
                "__init__.py": None,
                "main.py": "# FastAPI application entry point",
                "routers": {
                    "__init__.py": None,
                    "plugins_router.py": "# API endpoints for plugins",
                    "backtest_router.py": "# API endpoints for running backtests",
                },
            },
            "ui": {
                "src": {"components": {}, "services": {}, "App.tsx": "// Main React/TypeScript component"},
                "package.json": '{\n  "name": "s1mpletrader-ui",\n  "version": "0.1.0"\n}',
            },
        },
        "cli": {
            "presenters": {"optimization_presenter.py": "OptimizationPresenter"},
            "reporters": {"cli_reporter.py": "CliReporter"},
        },
    },
    "locales": {"en.yaml": "app:\n  start: \"S1mpleTrader is starting...\"", "nl.yaml": "app:\n  start: \"S1mpleTrader wordt gestart...\""},
    "tools": {"generate_structure.py": None, "plugin_creator.py": "# A helper script to bootstrap a new plugin directory"},
    "source_data": {"BTC_EUR_15m.csv": "timestamp,open,high,low,close,volume\n..."},
    "results": {
        "20250924_213000_mss_fvg_strategy": {
            "run_config.yaml": None,
            "result_trades.csv": None,
            "result_metrics.yaml": None,
            "run.log.json": None,
        }
    },
    "run_web.py": "# Entrypoint: Starts the Web UI and API",
    "run_supervisor.py": "# Entrypoint: Starts the live trading supervisor",
    "run_backtest_cli.py": "# Entrypoint: For automated (headless) runs",
    "pyproject.toml": '[tool.poetry]\nname = "s1mpletrader-v2"\nversion = "2.0.0"\ndescription = ""\nauthors = ["Your Name <you@example.com>"]',
}

def create_py_content(file_path_str: str, class_name: str) -> str:
    """Generates standard Python file content based on coding standards."""
    return f'# {file_path_str}\n"""\nDocstring for {os.path.basename(file_path_str)}.\n\n@layer: TODO\n@dependencies: TODO\n@responsibilities: TODO\n"""\n\nclass {class_name}:\n    """Docstring for {class_name}."""\n    pass\n'

def create_file_content(file_path: Path, content_instruction: str) -> str:
    """Creates the appropriate boilerplate content for a given file type."""
    file_path_str = str(file_path.relative_to(ROOT_DIR)).replace("\\", "/")
    
    if content_instruction and file_path.suffix == ".py":
        if content_instruction.startswith("#"): # It's a comment, not a class name
             return f'# {file_path_str}\n"""\n{content_instruction[2:]}\n"""\n'
        return create_py_content(file_path_str, content_instruction)
    
    if file_path.name == "__init__.py":
        return "" # Empty init file
        
    if content_instruction and not content_instruction.startswith("#"):
        return content_instruction
    
    return f"# Placeholder for {file_path_str}\n"


def build_structure(current_path: Path, structure_dict: dict):
    """Recursively builds the directory and file structure."""
    current_path.mkdir(exist_ok=True)
    for name, content in structure_dict.items():
        new_path = current_path / name
        if isinstance(content, dict):
            build_structure(new_path, content)
        else:
            print(f"Creating file: {new_path}")
            file_content = create_file_content(new_path, content)
            with open(new_path, "w", encoding="utf-8") as f:
                f.write(file_content)

if __name__ == "__main__":
    if ROOT_DIR.exists():
        print(f"Directory '{ROOT_DIR}' already exists. Please remove it first to start fresh.")
    else:
        print(f"--- 🚀 Bootstrapping S1mpleTrader V2 Structure in '{ROOT_DIR}' ---")
        build_structure(ROOT_DIR, STRUCTURE)
        print("\n--- ✅ Structure created successfully! ---")

--- END FILE: tools/bootstrap_v2.py ---

--- START FILE: tools/generate_structure.py ---
# tools/generate_structure.py
"""
Generates a text file representing the project's directory and file structure.

This script scans the project from the root directory, respects the rules
in the .gitignore file, and outputs a clean, indented tree structure to a
specified text file.

@layer: Tool
"""

# 1. Standard Library Imports
import os
import fnmatch
from pathlib import Path

# --- CONFIGURATION ---
PROJECT_ROOT = Path(__file__).resolve().parent.parent
OUTPUT_PATH = PROJECT_ROOT / "docs" / "folder_file_structure.txt"
GITIGNORE_PATH = PROJECT_ROOT / ".gitignore"

# Default patterns to always ignore, even if not in .gitignore
DEFAULT_IGNORE = {".git", ".vscode", "*.pyc", "*__pycache__*", ".DS_Store"}


def read_gitignore() -> set:
    """
    Reads and parses the .gitignore file.

    Returns:
        set: A set of patterns to be ignored.
    """
    if not GITIGNORE_PATH.is_file():
        print("Warning: .gitignore file not found at project root.")
        return set()

    with open(GITIGNORE_PATH, 'r', encoding='utf-8') as f:
        patterns = {
            line.strip() for line in f
            if line.strip() and not line.startswith('#')
        }
    return patterns


def should_ignore(path: Path, ignore_patterns: set) -> bool:
    """
    Checks if a path should be ignored using a simplified interpretation
    of .gitignore-style patterns.

    @inputs:
        path (Path): The path object relative to the project root.
        ignore_patterns (set): A set of patterns from .gitignore and defaults.

    @outputs:
        bool: True if the path should be ignored, False otherwise.
    """
    for pattern in ignore_patterns:
        # Handle directory-only patterns (e.g., 'build/', '__pycache__/')
        if pattern.endswith('/'):
            if pattern.rstrip('/') in path.parts:
                return True
        # Handle file/general patterns (e.g., '*.pyc', '.DS_Store')
        elif fnmatch.fnmatch(path.name, pattern):
            return True
    return False


def generate_structure(directory: Path, ignore_patterns: set, prefix: str = "") -> str:
    """
    Recursively generates the directory structure string.
    """
    structure = ""
    # Create a sorted list of items to process
    try:
        items = sorted(list(directory.iterdir()), key=lambda p: (p.is_file(), p.name.lower()))
    except FileNotFoundError:
        return "" # Directory might have been deleted mid-run

    # Create a list of non-ignored items to correctly determine the last element
    valid_items = [p for p in items if not should_ignore(p.relative_to(PROJECT_ROOT), ignore_patterns)]

    for i, path in enumerate(valid_items):
        is_last = (i == len(valid_items) - 1)
        connector = "└── " if is_last else "├── "
        structure += f"{prefix}{connector}{path.name}\n"

        if path.is_dir():
            extension = "    " if is_last else "│   "
            structure += generate_structure(
                path, ignore_patterns, prefix + extension
            )

    return structure


def main():
    """Main function to generate and save the structure file."""
    print("Generating project structure...")

    ignore_patterns = DEFAULT_IGNORE.union(read_gitignore())
    project_name = PROJECT_ROOT.name
    tree_string = generate_structure(PROJECT_ROOT, ignore_patterns)
    full_output = f"{project_name}/\n{tree_string}"

    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        f.write(full_output)

    print(f"✅ Project structure saved to: {OUTPUT_PATH}")


if __name__ == "__main__":
    main()
--- END FILE: tools/generate_structure.py ---

--- START FILE: tools/plugin_creator.py ---
# tools/plugin_creator.py
"""
A helper script to bootstrap a new plugin directory
"""

--- END FILE: tools/plugin_creator.py ---

--- START FILE: tools/__init__.py ---

--- END FILE: tools/__init__.py ---

